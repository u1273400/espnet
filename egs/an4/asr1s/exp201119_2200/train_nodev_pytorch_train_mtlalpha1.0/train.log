# asr_train.py --config conf/train_mtlalpha1.0.yaml --ngpu 1 --backend pytorch --outdir exp/train_nodev_pytorch_train_mtlalpha1.0/results --tensorboard-dir tensorboard/train_nodev_pytorch_train_mtlalpha1.0 --debugmode 1 --dict data/lang_1char/train_nodev_units.txt --debugdir exp/train_nodev_pytorch_train_mtlalpha1.0 --minibatches 0 --verbose 2 --resume --train-json dump/train_nodev/deltafalse/data.json --valid-json dump/train_dev/deltafalse/data.json 
# Started at Thu Nov 19 21:50:13 GMT 2020
#
/home/john/anaconda3/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.
Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.
  from numba.decorators import jit as optional_jit
/home/john/anaconda3/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.
Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.
  from numba.decorators import jit as optional_jit
2020-11-19 21:50:14,741 (asr_train:582) INFO: ngpu: 1
2020-11-19 21:50:14,741 (asr_train:585) INFO: python path = (None)
2020-11-19 21:50:14,741 (asr_train:588) INFO: random seed = 1
2020-11-19 21:50:14,741 (asr_train:604) INFO: backend = pytorch
2020-11-19 21:50:14,964 (deterministic_utils:26) INFO: torch type check is disabled
2020-11-19 21:50:14,995 (asr:416) INFO: stream1: input dims : 63
2020-11-19 21:50:14,995 (asr:417) INFO: #output dims: 30
2020-11-19 21:50:14,995 (asr:426) INFO: Pure CTC mode
2020-11-19 21:50:14,996 (nets_utils:423) INFO: subsample: 1 2 2 1 1
2020-11-19 21:50:14,996 (e2e_asr:279) INFO: prescatter idim=63 
2020-11-19 21:50:15,054 (encoders:294) INFO: BLSTM with every-layer projection for encoder
2020-11-19 21:50:15,531 (asr:445) INFO:  Total parameter of the model = 8074951
2020-11-19 21:50:15,532 (asr:461) INFO: writing a model config file to exp/train_nodev_pytorch_train_mtlalpha1.0/results/model.json
2020-11-19 21:50:15,532 (asr:471) INFO: ARGS: accum_grad: 1
2020-11-19 21:50:15,532 (asr:471) INFO: ARGS: aconv_chans: 10
2020-11-19 21:50:15,532 (asr:471) INFO: ARGS: aconv_filts: 100
2020-11-19 21:50:15,532 (asr:471) INFO: ARGS: adim: 320
2020-11-19 21:50:15,532 (asr:471) INFO: ARGS: aheads: 4
2020-11-19 21:50:15,532 (asr:471) INFO: ARGS: apply_uttmvn: True
2020-11-19 21:50:15,532 (asr:471) INFO: ARGS: atype: location
2020-11-19 21:50:15,532 (asr:471) INFO: ARGS: awin: 5
2020-11-19 21:50:15,532 (asr:471) INFO: ARGS: backend: pytorch
2020-11-19 21:50:15,532 (asr:471) INFO: ARGS: badim: 320
2020-11-19 21:50:15,532 (asr:471) INFO: ARGS: batch_bins: 0
2020-11-19 21:50:15,532 (asr:471) INFO: ARGS: batch_count: auto
2020-11-19 21:50:15,532 (asr:471) INFO: ARGS: batch_frames_in: 0
2020-11-19 21:50:15,532 (asr:471) INFO: ARGS: batch_frames_inout: 0
2020-11-19 21:50:15,532 (asr:471) INFO: ARGS: batch_frames_out: 0
2020-11-19 21:50:15,532 (asr:471) INFO: ARGS: batch_size: 30
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: bdropout_rate: 0.0
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: beam_size: 4
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: blayers: 2
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: bnmask: 2
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: bprojs: 300
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: btype: blstmp
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: bunits: 300
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: char_list: ['<blank>', '<unk>', '<space>', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '<eos>']
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: config: conf/train_mtlalpha1.0.yaml
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: config2: None
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: config3: None
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: context_residual: False
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: criterion: acc
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: ctc_type: warpctc
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: ctc_weight: 0.3
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: debugdir: exp/train_nodev_pytorch_train_mtlalpha1.0
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: debugmode: 1
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: dec_init: None
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: dec_init_mods: ['att.', ' dec.']
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: dict: data/lang_1char/train_nodev_units.txt
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: dlayers: 1
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: dropout_rate: 0.0
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: dropout_rate_decoder: 0.0
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: dtype: lstm
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: dunits: 300
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: early_stop_criterion: validation/main/acc
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: elayers: 4
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: enc_init: None
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: enc_init_mods: ['enc.enc.']
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: epochs: 3
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: eprojs: 320
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: eps: 1e-08
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: eps_decay: 0.01
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: etype: blstmp
2020-11-19 21:50:15,533 (asr:471) INFO: ARGS: eunits: 320
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: fbank_fmax: None
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: fbank_fmin: 0.0
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: fbank_fs: 16000
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: freeze_mods: None
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: grad_clip: 5
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: grad_noise: False
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: lm_weight: 0.1
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: lsm_type: 
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: lsm_weight: 0.0
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: maxlen_in: 800
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: maxlen_out: 150
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: maxlenratio: 0.0
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: minibatches: 0
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: minlenratio: 0.0
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: model_module: espnet.nets.pytorch_backend.e2e_asr:E2E
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: mtlalpha: 1.0
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: n_iter_processes: 0
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: n_mels: 63
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: nbest: 1
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: ngpu: 1
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: num_encs: 1
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: num_save_attention: 3
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: num_spkrs: 1
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: opt: adadelta
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: outdir: exp/train_nodev_pytorch_train_mtlalpha1.0/results
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: patience: 3
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: penalty: 0.0
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: preprocess_conf: None
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: ref_channel: -1
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: report_cer: False
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: report_interval_iters: 100
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: report_wer: False
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: resume: None
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: rnnlm: None
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: rnnlm_conf: None
2020-11-19 21:50:15,534 (asr:471) INFO: ARGS: sampling_probability: 0.0
2020-11-19 21:50:15,535 (asr:471) INFO: ARGS: save_interval_iters: 0
2020-11-19 21:50:15,535 (asr:471) INFO: ARGS: seed: 1
2020-11-19 21:50:15,535 (asr:471) INFO: ARGS: sortagrad: 0
2020-11-19 21:50:15,535 (asr:471) INFO: ARGS: stats_file: None
2020-11-19 21:50:15,535 (asr:471) INFO: ARGS: subsample: 1_2_2_1_1
2020-11-19 21:50:15,535 (asr:471) INFO: ARGS: sym_blank: <blank>
2020-11-19 21:50:15,535 (asr:471) INFO: ARGS: sym_space: <space>
2020-11-19 21:50:15,535 (asr:471) INFO: ARGS: tensorboard_dir: tensorboard/train_nodev_pytorch_train_mtlalpha1.0
2020-11-19 21:50:15,535 (asr:471) INFO: ARGS: threshold: 0.0001
2020-11-19 21:50:15,535 (asr:471) INFO: ARGS: train_dtype: float32
2020-11-19 21:50:15,535 (asr:471) INFO: ARGS: train_json: dump/train_nodev/deltafalse/data.json
2020-11-19 21:50:15,535 (asr:471) INFO: ARGS: use_beamformer: True
2020-11-19 21:50:15,535 (asr:471) INFO: ARGS: use_dnn_mask_for_wpe: False
2020-11-19 21:50:15,535 (asr:471) INFO: ARGS: use_frontend: False
2020-11-19 21:50:15,535 (asr:471) INFO: ARGS: use_wpe: False
2020-11-19 21:50:15,535 (asr:471) INFO: ARGS: uttmvn_norm_means: True
2020-11-19 21:50:15,535 (asr:471) INFO: ARGS: uttmvn_norm_vars: False
2020-11-19 21:50:15,535 (asr:471) INFO: ARGS: valid_json: dump/train_dev/deltafalse/data.json
2020-11-19 21:50:15,535 (asr:471) INFO: ARGS: verbose: 2
2020-11-19 21:50:15,535 (asr:471) INFO: ARGS: wdropout_rate: 0.0
2020-11-19 21:50:15,535 (asr:471) INFO: ARGS: weight_decay: 0.0
2020-11-19 21:50:15,535 (asr:471) INFO: ARGS: wlayers: 2
2020-11-19 21:50:15,535 (asr:471) INFO: ARGS: wpe_delay: 3
2020-11-19 21:50:15,535 (asr:471) INFO: ARGS: wpe_taps: 5
2020-11-19 21:50:15,535 (asr:471) INFO: ARGS: wprojs: 300
2020-11-19 21:50:15,535 (asr:471) INFO: ARGS: wtype: blstmp
2020-11-19 21:50:15,535 (asr:471) INFO: ARGS: wunits: 300
2020-11-19 21:50:19,189 (batchfy:433) INFO: count is auto detected as seq
2020-11-19 21:50:19,189 (batchfy:457) INFO: # utts: 848
2020-11-19 21:50:19,190 (batchfy:502) INFO: # minibatches: 38
2020-11-19 21:50:19,190 (batchfy:433) INFO: count is auto detected as seq
2020-11-19 21:50:19,190 (batchfy:457) INFO: # utts: 100
2020-11-19 21:50:19,190 (batchfy:502) INFO: # minibatches: 5
2020-11-19 21:50:19,194 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (350, 63)
2020-11-19 21:50:19,194 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (350, 63)
2020-11-19 21:50:19,194 (asr:288) INFO: ilens in custom converter = 30 [350 350 350 350 350 350 350 350 350 350 350 350 350 350 325 325 325 325
 325 325 325 325 325 325 325 325 325 325 325 325]
2020-11-19 21:50:19,197 (nets_utils:52) INFO: padded = torch.Size([30, 350, 63]) 
2020-11-19 21:50:19,199 (nets_utils:52) INFO: padded = torch.Size([30, 18]) 
2020-11-19 21:50:19,201 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350,
        325, 325, 325, 325, 325, 325, 325, 325, 325, 325, 325, 325, 325, 325,
        325, 325], device='cuda:0') tensor([350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350,
        325, 325, 325, 325, 325, 325, 325, 325, 325, 325, 325, 325, 325, 325,
        325, 325], device='cuda:0')
2020-11-19 21:50:19,250 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 82, 82, 82, 82,
        82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82])
2020-11-19 21:50:19,253 (ctc:92) INFO: CTC input lengths:  tensor([88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 82, 82, 82, 82,        82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82], dtype=torch.int32)
2020-11-19 21:50:19,254 (ctc:97) INFO: CTC output lengths: tensor([ 5,  7,  6, 12, 11, 15, 11, 11,  9, 15, 17, 11,  5, 11,  4, 10,  6, 11,         8,  5, 18,  5, 10,  5, 10,  3,  7, 15, 14,  2], dtype=torch.int32)
2020-11-19 21:50:19,259 (ctc:119) INFO: ctc loss:244.5847625732422
2020-11-19 21:50:19,355 (e2e_asr:56) INFO: mtl loss:244.5847625732422
2020-11-19 21:50:19,431 (asr:234) INFO: grad norm=92.24160504610279
2020-11-19 21:50:19,443 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (550, 63)
2020-11-19 21:50:19,444 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (550, 63)
2020-11-19 21:50:19,444 (asr:288) INFO: ilens in custom converter = 30 [550 550 550 550 550 550 550 550 550 550 550 550 550 525 525 525 525 525
 525 525 525 525 525 525 525 525 525 525 525 525]
2020-11-19 21:50:19,449 (nets_utils:52) INFO: padded = torch.Size([30, 550, 63]) 
2020-11-19 21:50:19,450 (nets_utils:52) INFO: padded = torch.Size([30, 34]) 
2020-11-19 21:50:19,453 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 525,
        525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525,
        525, 525], device='cuda:0') tensor([550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 525,
        525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525,
        525, 525], device='cuda:0')
2020-11-19 21:50:19,530 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132])
2020-11-19 21:50:19,533 (ctc:92) INFO: CTC input lengths:  tensor([138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 132,        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,        132, 132], dtype=torch.int32)
2020-11-19 21:50:19,533 (ctc:97) INFO: CTC output lengths: tensor([29, 34, 21, 16, 30, 11, 12, 21, 11, 22,  9, 21, 26, 11, 22, 21, 15, 32,        13, 19, 20, 33, 32, 26, 11, 19, 11, 21, 13, 20], dtype=torch.int32)
2020-11-19 21:50:19,535 (ctc:119) INFO: ctc loss:321.1516418457031
2020-11-19 21:50:19,669 (e2e_asr:56) INFO: mtl loss:321.1516418457031
2020-11-19 21:50:19,781 (asr:234) INFO: grad norm=324.9152515853384
2020-11-19 21:50:19,788 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 8 (200, 63)
2020-11-19 21:50:19,789 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 8 (200, 63)
2020-11-19 21:50:19,789 (asr:288) INFO: ilens in custom converter = 8 [200 200 200 200 200 200 200 175]
2020-11-19 21:50:19,789 (nets_utils:52) INFO: padded = torch.Size([8, 200, 63]) 
2020-11-19 21:50:19,789 (nets_utils:52) INFO: padded = torch.Size([8, 4]) 
2020-11-19 21:50:19,791 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([8]) torch.Size([8]) hlens,ilens=tensor([200, 200, 200, 200, 200, 200, 200, 175], device='cuda:0') tensor([200, 200, 200, 200, 200, 200, 200, 175], device='cuda:0')
2020-11-19 21:50:19,809 (e2e_asr:368) INFO: encoder ilens=torch.Size([8]) tensor([50, 50, 50, 50, 50, 50, 50, 44])
2020-11-19 21:50:19,810 (ctc:92) INFO: CTC input lengths:  tensor([50, 50, 50, 50, 50, 50, 50, 44], dtype=torch.int32)
2020-11-19 21:50:19,811 (ctc:97) INFO: CTC output lengths: tensor([2, 2, 4, 2, 3, 3, 4, 4], dtype=torch.int32)
2020-11-19 21:50:19,812 (ctc:119) INFO: ctc loss:65.37305450439453
2020-11-19 21:50:19,824 (e2e_asr:56) INFO: mtl loss:65.37305450439453
2020-11-19 21:50:19,852 (asr:234) INFO: grad norm=217.67381626385998
2020-11-19 21:50:19,861 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (225, 63)
2020-11-19 21:50:19,861 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (225, 63)
2020-11-19 21:50:19,861 (asr:288) INFO: ilens in custom converter = 30 [225 225 225 225 225 225 225 225 225 225 225 225 225 225 225 225 225 200
 200 200 200 200 200 200 200 200 200 200 200 200]
2020-11-19 21:50:19,863 (nets_utils:52) INFO: padded = torch.Size([30, 225, 63]) 
2020-11-19 21:50:19,864 (nets_utils:52) INFO: padded = torch.Size([30, 6]) 
2020-11-19 21:50:19,866 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225,
        225, 225, 225, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,
        200, 200], device='cuda:0') tensor([225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225,
        225, 225, 225, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,
        200, 200], device='cuda:0')
2020-11-19 21:50:19,896 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 50,
        50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50])
2020-11-19 21:50:19,899 (ctc:92) INFO: CTC input lengths:  tensor([57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 50,        50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50], dtype=torch.int32)
2020-11-19 21:50:19,899 (ctc:97) INFO: CTC output lengths: tensor([4, 6, 6, 4, 4, 4, 3, 4, 2, 2, 4, 4, 3, 6, 6, 5, 2, 2, 2, 2, 2, 2, 2, 2,        4, 4, 6, 2, 2, 4], dtype=torch.int32)
2020-11-19 21:50:19,900 (ctc:119) INFO: ctc loss:15.49235725402832
2020-11-19 21:50:19,952 (e2e_asr:56) INFO: mtl loss:15.49235725402832
2020-11-19 21:50:19,998 (asr:234) INFO: grad norm=39.46996527448096
2020-11-19 21:50:20,008 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (475, 63)
2020-11-19 21:50:20,008 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (475, 63)
2020-11-19 21:50:20,008 (asr:288) INFO: ilens in custom converter = 30 [475 450 450 450 450 450 450 450 450 450 450 450 450 450 450 450 450 450
 450 450 450 450 450 450 450 425 425 425 425 425]
2020-11-19 21:50:20,011 (nets_utils:52) INFO: padded = torch.Size([30, 475, 63]) 
2020-11-19 21:50:20,012 (nets_utils:52) INFO: padded = torch.Size([30, 23]) 
2020-11-19 21:50:20,015 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([475, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450,
        450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 425, 425, 425,
        425, 425], device='cuda:0') tensor([475, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450,
        450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 425, 425, 425,
        425, 425], device='cuda:0')
2020-11-19 21:50:20,076 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([119, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113,
        113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 107, 107, 107,
        107, 107])
2020-11-19 21:50:20,079 (ctc:92) INFO: CTC input lengths:  tensor([119, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113,        113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 107, 107, 107,        107, 107], dtype=torch.int32)
2020-11-19 21:50:20,079 (ctc:97) INFO: CTC output lengths: tensor([21, 13, 22, 21, 22,  9, 22, 22, 10, 22, 20, 22, 21, 22, 11, 20, 16, 22,        15, 17, 22, 22, 10, 20,  7, 13, 23, 21,  9, 22], dtype=torch.int32)
2020-11-19 21:50:20,081 (ctc:119) INFO: ctc loss:121.57249450683594
2020-11-19 21:50:20,197 (e2e_asr:56) INFO: mtl loss:121.57249450683594
2020-11-19 21:50:20,289 (asr:234) INFO: grad norm=278.5123394419424
2020-11-19 21:50:20,298 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (250, 63)
2020-11-19 21:50:20,298 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (250, 63)
2020-11-19 21:50:20,298 (asr:288) INFO: ilens in custom converter = 30 [250 250 250 250 250 250 250 250 250 250 250 250 250 250 250 250 250 250
 250 250 250 250 250 250 225 225 225 225 225 225]
2020-11-19 21:50:20,300 (nets_utils:52) INFO: padded = torch.Size([30, 250, 63]) 
2020-11-19 21:50:20,301 (nets_utils:52) INFO: padded = torch.Size([30, 11]) 
2020-11-19 21:50:20,303 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250,
        250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 225, 225, 225, 225,
        225, 225], device='cuda:0') tensor([250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250,
        250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 225, 225, 225, 225,
        225, 225], device='cuda:0')
2020-11-19 21:50:20,336 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63,
        63, 63, 63, 63, 63, 63, 57, 57, 57, 57, 57, 57])
2020-11-19 21:50:20,339 (ctc:92) INFO: CTC input lengths:  tensor([63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63,        63, 63, 63, 63, 63, 63, 57, 57, 57, 57, 57, 57], dtype=torch.int32)
2020-11-19 21:50:20,339 (ctc:97) INFO: CTC output lengths: tensor([ 5,  6,  5,  3,  6,  2,  2,  5,  3,  4,  3,  4,  5,  6,  5,  3,  3,  4,         3,  4,  3,  3, 11,  5,  6,  2,  2,  4,  5,  2], dtype=torch.int32)
2020-11-19 21:50:20,340 (ctc:119) INFO: ctc loss:14.923879623413086
2020-11-19 21:50:20,398 (e2e_asr:56) INFO: mtl loss:14.923879623413086
2020-11-19 21:50:20,449 (asr:234) INFO: grad norm=17.568124675686118
2020-11-19 21:50:20,458 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1125, 63)
2020-11-19 21:50:20,458 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1125, 63)
2020-11-19 21:50:20,458 (asr:288) INFO: ilens in custom converter = 15 [1125 1125 1100 1100 1100 1100 1100 1100 1100 1100 1100 1100 1075 1075
 1075]
2020-11-19 21:50:20,462 (nets_utils:52) INFO: padded = torch.Size([15, 1125, 63]) 
2020-11-19 21:50:20,463 (nets_utils:52) INFO: padded = torch.Size([15, 52]) 
2020-11-19 21:50:20,465 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1125, 1125, 1100, 1100, 1100, 1100, 1100, 1100, 1100, 1100, 1100, 1100,
        1075, 1075, 1075], device='cuda:0') tensor([1125, 1125, 1100, 1100, 1100, 1100, 1100, 1100, 1100, 1100, 1100, 1100,
        1075, 1075, 1075], device='cuda:0')
2020-11-19 21:50:20,585 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([282, 282, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 269, 269,
        269])
2020-11-19 21:50:20,586 (ctc:92) INFO: CTC input lengths:  tensor([282, 282, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 269, 269,        269], dtype=torch.int32)
2020-11-19 21:50:20,587 (ctc:97) INFO: CTC output lengths: tensor([19, 19, 36, 21, 15, 17, 41, 23,  9, 17, 52, 25, 29, 13, 34],       dtype=torch.int32)
2020-11-19 21:50:20,591 (ctc:119) INFO: ctc loss:133.91001892089844
2020-11-19 21:50:20,721 (e2e_asr:56) INFO: mtl loss:133.91001892089844
2020-11-19 21:50:20,882 (asr:234) INFO: grad norm=365.8310040976955
2020-11-19 21:50:20,893 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (750, 63)
2020-11-19 21:50:20,893 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (750, 63)
2020-11-19 21:50:20,894 (asr:288) INFO: ilens in custom converter = 30 [750 750 750 750 750 750 750 725 725 725 725 725 725 725 725 725 725 725
 725 725 725 725 725 725 725 725 725 725 725 725]
2020-11-19 21:50:20,899 (nets_utils:52) INFO: padded = torch.Size([30, 750, 63]) 
2020-11-19 21:50:20,901 (nets_utils:52) INFO: padded = torch.Size([30, 45]) 
2020-11-19 21:50:20,904 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([750, 750, 750, 750, 750, 750, 750, 725, 725, 725, 725, 725, 725, 725,
        725, 725, 725, 725, 725, 725, 725, 725, 725, 725, 725, 725, 725, 725,
        725, 725], device='cuda:0') tensor([750, 750, 750, 750, 750, 750, 750, 725, 725, 725, 725, 725, 725, 725,
        725, 725, 725, 725, 725, 725, 725, 725, 725, 725, 725, 725, 725, 725,
        725, 725], device='cuda:0')
2020-11-19 21:50:20,999 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([188, 188, 188, 188, 188, 188, 188, 182, 182, 182, 182, 182, 182, 182,
        182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182,
        182, 182])
2020-11-19 21:50:21,003 (ctc:92) INFO: CTC input lengths:  tensor([188, 188, 188, 188, 188, 188, 188, 182, 182, 182, 182, 182, 182, 182,        182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182,        182, 182], dtype=torch.int32)
2020-11-19 21:50:21,003 (ctc:97) INFO: CTC output lengths: tensor([21, 19, 23, 17, 25, 26, 33,  9, 33, 17, 11, 19, 26, 11, 34,  9, 29, 29,        15, 17, 34, 21, 45, 32, 11, 31, 13, 13,  9, 22], dtype=torch.int32)
2020-11-19 21:50:21,006 (ctc:119) INFO: ctc loss:69.61611938476562
2020-11-19 21:50:21,187 (e2e_asr:56) INFO: mtl loss:69.61611938476562
2020-11-19 21:50:21,327 (asr:234) INFO: grad norm=55.77065698721262
2020-11-19 21:50:21,338 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (775, 63)
2020-11-19 21:50:21,338 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (775, 63)
2020-11-19 21:50:21,339 (asr:288) INFO: ilens in custom converter = 30 [775 775 775 775 775 775 775 775 775 775 775 775 775 775 775 775 775 775
 775 775 775 775 775 775 775 750 750 750 750 750]
2020-11-19 21:50:21,343 (nets_utils:52) INFO: padded = torch.Size([30, 775, 63]) 
2020-11-19 21:50:21,345 (nets_utils:52) INFO: padded = torch.Size([30, 39]) 
2020-11-19 21:50:21,349 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775,
        775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 750, 750, 750,
        750, 750], device='cuda:0') tensor([775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775,
        775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 750, 750, 750,
        750, 750], device='cuda:0')
2020-11-19 21:50:21,447 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194,
        194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 188, 188, 188,
        188, 188])
2020-11-19 21:50:21,450 (ctc:92) INFO: CTC input lengths:  tensor([194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194,        194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 188, 188, 188,        188, 188], dtype=torch.int32)
2020-11-19 21:50:21,450 (ctc:97) INFO: CTC output lengths: tensor([26, 19, 11, 11, 13, 23, 15, 13,  5, 13, 25, 13,  9, 17, 25, 33, 25, 11,        22, 13, 28, 24, 15, 25, 15, 15, 28, 16, 39, 26], dtype=torch.int32)
2020-11-19 21:50:21,453 (ctc:119) INFO: ctc loss:71.40104675292969
2020-11-19 21:50:21,636 (e2e_asr:56) INFO: mtl loss:71.40104675292969
2020-11-19 21:50:21,780 (asr:234) INFO: grad norm=397.92129930049043
2020-11-19 21:50:21,789 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (825, 63)
2020-11-19 21:50:21,789 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (825, 63)
2020-11-19 21:50:21,790 (asr:288) INFO: ilens in custom converter = 15 [825 825 825 825 825 825 825 825 825 825 825 825 825 825 825]
2020-11-19 21:50:21,792 (nets_utils:52) INFO: padded = torch.Size([15, 825, 63]) 
2020-11-19 21:50:21,793 (nets_utils:52) INFO: padded = torch.Size([15, 45]) 
2020-11-19 21:50:21,795 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([825, 825, 825, 825, 825, 825, 825, 825, 825, 825, 825, 825, 825, 825,
        825], device='cuda:0') tensor([825, 825, 825, 825, 825, 825, 825, 825, 825, 825, 825, 825, 825, 825,
        825], device='cuda:0')
2020-11-19 21:50:21,885 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207,
        207])
2020-11-19 21:50:21,886 (ctc:92) INFO: CTC input lengths:  tensor([207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207,        207], dtype=torch.int32)
2020-11-19 21:50:21,887 (ctc:97) INFO: CTC output lengths: tensor([17, 45, 30, 18, 32, 38, 36, 44, 23, 19, 11, 32, 19, 21, 42],       dtype=torch.int32)
2020-11-19 21:50:21,890 (ctc:119) INFO: ctc loss:111.98097229003906
2020-11-19 21:50:21,989 (e2e_asr:56) INFO: mtl loss:111.98097229003906
2020-11-19 21:50:22,105 (asr:234) INFO: grad norm=304.8946177185179
2020-11-19 21:50:22,114 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (875, 63)
2020-11-19 21:50:22,114 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (875, 63)
2020-11-19 21:50:22,115 (asr:288) INFO: ilens in custom converter = 15 [875 875 875 875 875 875 875 875 875 875 875 875 875 875 875]
2020-11-19 21:50:22,117 (nets_utils:52) INFO: padded = torch.Size([15, 875, 63]) 
2020-11-19 21:50:22,118 (nets_utils:52) INFO: padded = torch.Size([15, 48]) 
2020-11-19 21:50:22,120 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([875, 875, 875, 875, 875, 875, 875, 875, 875, 875, 875, 875, 875, 875,
        875], device='cuda:0') tensor([875, 875, 875, 875, 875, 875, 875, 875, 875, 875, 875, 875, 875, 875,
        875], device='cuda:0')
2020-11-19 21:50:22,213 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219,
        219])
2020-11-19 21:50:22,215 (ctc:92) INFO: CTC input lengths:  tensor([219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219,        219], dtype=torch.int32)
2020-11-19 21:50:22,216 (ctc:97) INFO: CTC output lengths: tensor([48, 33, 39, 18, 29, 19, 28, 19, 23, 22, 19, 17, 23, 23, 33],       dtype=torch.int32)
2020-11-19 21:50:22,219 (ctc:119) INFO: ctc loss:91.95527648925781
2020-11-19 21:50:22,326 (e2e_asr:56) INFO: mtl loss:91.95527648925781
2020-11-19 21:50:22,448 (asr:234) INFO: grad norm=345.1258526566271
2020-11-19 21:50:22,457 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1050, 63)
2020-11-19 21:50:22,457 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1050, 63)
2020-11-19 21:50:22,457 (asr:288) INFO: ilens in custom converter = 15 [1050 1050 1050 1050 1050 1050 1050 1050 1050 1050 1050 1050 1050 1050
 1050]
2020-11-19 21:50:22,460 (nets_utils:52) INFO: padded = torch.Size([15, 1050, 63]) 
2020-11-19 21:50:22,462 (nets_utils:52) INFO: padded = torch.Size([15, 50]) 
2020-11-19 21:50:22,464 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050,
        1050, 1050, 1050], device='cuda:0') tensor([1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050,
        1050, 1050, 1050], device='cuda:0')
2020-11-19 21:50:22,572 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([263, 263, 263, 263, 263, 263, 263, 263, 263, 263, 263, 263, 263, 263,
        263])
2020-11-19 21:50:22,574 (ctc:92) INFO: CTC input lengths:  tensor([263, 263, 263, 263, 263, 263, 263, 263, 263, 263, 263, 263, 263, 263,        263], dtype=torch.int32)
2020-11-19 21:50:22,574 (ctc:97) INFO: CTC output lengths: tensor([21, 17, 31, 19, 11, 50, 21, 19, 29, 24, 34, 15, 26, 21, 50],       dtype=torch.int32)
2020-11-19 21:50:22,577 (ctc:119) INFO: ctc loss:90.2894287109375
2020-11-19 21:50:22,701 (e2e_asr:56) INFO: mtl loss:90.2894287109375
2020-11-19 21:50:22,845 (asr:234) INFO: grad norm=243.5276573108127
2020-11-19 21:50:22,854 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (800, 63)
2020-11-19 21:50:22,854 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (800, 63)
2020-11-19 21:50:22,854 (asr:288) INFO: ilens in custom converter = 15 [800 800 800 800 800 800 800 800 800 800 800 800 800 800 800]
2020-11-19 21:50:22,857 (nets_utils:52) INFO: padded = torch.Size([15, 800, 63]) 
2020-11-19 21:50:22,858 (nets_utils:52) INFO: padded = torch.Size([15, 38]) 
2020-11-19 21:50:22,860 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([800, 800, 800, 800, 800, 800, 800, 800, 800, 800, 800, 800, 800, 800,
        800], device='cuda:0') tensor([800, 800, 800, 800, 800, 800, 800, 800, 800, 800, 800, 800, 800, 800,
        800], device='cuda:0')
2020-11-19 21:50:22,946 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,
        200])
2020-11-19 21:50:22,948 (ctc:92) INFO: CTC input lengths:  tensor([200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,        200], dtype=torch.int32)
2020-11-19 21:50:22,948 (ctc:97) INFO: CTC output lengths: tensor([13, 29, 37, 20, 29, 18, 18, 36, 25, 22, 21, 19, 27, 13, 38],       dtype=torch.int32)
2020-11-19 21:50:22,951 (ctc:119) INFO: ctc loss:80.06026458740234
2020-11-19 21:50:23,045 (e2e_asr:56) INFO: mtl loss:80.06026458740234
2020-11-19 21:50:23,157 (asr:234) INFO: grad norm=264.7350068367029
2020-11-19 21:50:23,167 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1575, 63)
2020-11-19 21:50:23,167 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1575, 63)
2020-11-19 21:50:23,167 (asr:288) INFO: ilens in custom converter = 15 [1575 1575 1575 1575 1550 1550 1525 1525 1525 1525 1500 1500 1500 1475
 1450]
2020-11-19 21:50:23,172 (nets_utils:52) INFO: padded = torch.Size([15, 1575, 63]) 
2020-11-19 21:50:23,174 (nets_utils:52) INFO: padded = torch.Size([15, 57]) 
2020-11-19 21:50:23,176 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1575, 1575, 1575, 1575, 1550, 1550, 1525, 1525, 1525, 1525, 1500, 1500,
        1500, 1475, 1450], device='cuda:0') tensor([1575, 1575, 1575, 1575, 1550, 1550, 1525, 1525, 1525, 1525, 1500, 1500,
        1500, 1475, 1450], device='cuda:0')
2020-11-19 21:50:23,338 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([394, 394, 394, 394, 388, 388, 382, 382, 382, 382, 375, 375, 375, 369,
        363])
2020-11-19 21:50:23,340 (ctc:92) INFO: CTC input lengths:  tensor([394, 394, 394, 394, 388, 388, 382, 382, 382, 382, 375, 375, 375, 369,        363], dtype=torch.int32)
2020-11-19 21:50:23,340 (ctc:97) INFO: CTC output lengths: tensor([30, 15, 19, 49, 29, 42, 19, 57, 19, 23, 34, 29, 19, 44, 44],       dtype=torch.int32)
2020-11-19 21:50:23,346 (ctc:119) INFO: ctc loss:102.928466796875
2020-11-19 21:50:23,527 (e2e_asr:56) INFO: mtl loss:102.928466796875
2020-11-19 21:50:23,764 (asr:234) INFO: grad norm=260.8364843588423
2020-11-19 21:50:23,774 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (575, 63)
2020-11-19 21:50:23,774 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (575, 63)
2020-11-19 21:50:23,774 (asr:288) INFO: ilens in custom converter = 30 [575 575 575 550 550 550 550 550 550 550 550 550 550 550 550 550 550 550
 550 550 550 550 550 550 550 550 550 550 550 550]
2020-11-19 21:50:23,777 (nets_utils:52) INFO: padded = torch.Size([30, 575, 63]) 
2020-11-19 21:50:23,778 (nets_utils:52) INFO: padded = torch.Size([30, 35]) 
2020-11-19 21:50:23,781 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([575, 575, 575, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550,
        550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550,
        550, 550], device='cuda:0') tensor([575, 575, 575, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550,
        550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550,
        550, 550], device='cuda:0')
2020-11-19 21:50:23,854 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([144, 144, 144, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
        138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
        138, 138])
2020-11-19 21:50:23,857 (ctc:92) INFO: CTC input lengths:  tensor([144, 144, 144, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,        138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,        138, 138], dtype=torch.int32)
2020-11-19 21:50:23,857 (ctc:97) INFO: CTC output lengths: tensor([17, 19, 20, 33, 22, 30, 21,  7, 19, 10, 11,  9, 19,  9, 20, 14, 29, 23,        11,  9, 11, 11, 22, 14, 12, 11, 29, 15, 35, 35], dtype=torch.int32)
2020-11-19 21:50:23,859 (ctc:119) INFO: ctc loss:58.76669692993164
2020-11-19 21:50:24,002 (e2e_asr:56) INFO: mtl loss:58.76669692993164
2020-11-19 21:50:24,110 (asr:234) INFO: grad norm=153.765878905561
2020-11-19 21:50:24,120 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (675, 63)
2020-11-19 21:50:24,121 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (675, 63)
2020-11-19 21:50:24,121 (asr:288) INFO: ilens in custom converter = 30 [675 675 675 675 675 675 675 675 675 675 675 675 675 675 675 675 675 675
 675 675 675 675 675 675 675 650 650 650 650 650]
2020-11-19 21:50:24,125 (nets_utils:52) INFO: padded = torch.Size([30, 675, 63]) 
2020-11-19 21:50:24,126 (nets_utils:52) INFO: padded = torch.Size([30, 46]) 
2020-11-19 21:50:24,129 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 675,
        675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 650, 650, 650,
        650, 650], device='cuda:0') tensor([675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 675,
        675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 650, 650, 650,
        650, 650], device='cuda:0')
2020-11-19 21:50:24,215 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169,
        169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 163, 163, 163,
        163, 163])
2020-11-19 21:50:24,218 (ctc:92) INFO: CTC input lengths:  tensor([169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169,        169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 163, 163, 163,        163, 163], dtype=torch.int32)
2020-11-19 21:50:24,218 (ctc:97) INFO: CTC output lengths: tensor([13, 13, 13, 12, 19, 17, 20, 13, 30, 30, 46, 17, 21, 13, 19, 15, 13, 24,        21, 19,  7, 17, 33,  9, 41, 18, 26, 26, 29, 22], dtype=torch.int32)
2020-11-19 21:50:24,221 (ctc:119) INFO: ctc loss:72.69862365722656
2020-11-19 21:50:24,386 (e2e_asr:56) INFO: mtl loss:72.69862365722656
2020-11-19 21:50:24,513 (asr:234) INFO: grad norm=184.633595183807
2020-11-19 21:50:24,523 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (600, 63)
2020-11-19 21:50:24,523 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (600, 63)
2020-11-19 21:50:24,524 (asr:288) INFO: ilens in custom converter = 30 [600 600 600 600 600 600 600 600 575 575 575 575 575 575 575 575 575 575
 575 575 575 575 575 575 575 575 575 575 575 575]
2020-11-19 21:50:24,527 (nets_utils:52) INFO: padded = torch.Size([30, 600, 63]) 
2020-11-19 21:50:24,528 (nets_utils:52) INFO: padded = torch.Size([30, 29]) 
2020-11-19 21:50:24,531 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([600, 600, 600, 600, 600, 600, 600, 600, 575, 575, 575, 575, 575, 575,
        575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575,
        575, 575], device='cuda:0') tensor([600, 600, 600, 600, 600, 600, 600, 600, 575, 575, 575, 575, 575, 575,
        575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575,
        575, 575], device='cuda:0')
2020-11-19 21:50:24,607 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([150, 150, 150, 150, 150, 150, 150, 150, 144, 144, 144, 144, 144, 144,
        144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
        144, 144])
2020-11-19 21:50:24,610 (ctc:92) INFO: CTC input lengths:  tensor([150, 150, 150, 150, 150, 150, 150, 150, 144, 144, 144, 144, 144, 144,        144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,        144, 144], dtype=torch.int32)
2020-11-19 21:50:24,611 (ctc:97) INFO: CTC output lengths: tensor([ 9, 22, 13,  9, 26,  9, 25, 17, 22, 22, 19, 21, 22, 29, 28, 22, 17, 11,        22, 23, 15, 27, 23, 24, 29, 19, 17, 22, 13, 11], dtype=torch.int32)
2020-11-19 21:50:24,613 (ctc:119) INFO: ctc loss:62.19187927246094
2020-11-19 21:50:24,758 (e2e_asr:56) INFO: mtl loss:62.19187927246094
2020-11-19 21:50:24,871 (asr:234) INFO: grad norm=157.40762314660327
2020-11-19 21:50:24,880 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1025, 63)
2020-11-19 21:50:24,881 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1025, 63)
2020-11-19 21:50:24,881 (asr:288) INFO: ilens in custom converter = 15 [1025 1025 1025 1025 1025 1025 1025 1025 1025 1025 1025 1025 1025 1025
 1025]
2020-11-19 21:50:24,884 (nets_utils:52) INFO: padded = torch.Size([15, 1025, 63]) 
2020-11-19 21:50:24,885 (nets_utils:52) INFO: padded = torch.Size([15, 38]) 
2020-11-19 21:50:24,888 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1025, 1025, 1025, 1025, 1025, 1025, 1025, 1025, 1025, 1025, 1025, 1025,
        1025, 1025, 1025], device='cuda:0') tensor([1025, 1025, 1025, 1025, 1025, 1025, 1025, 1025, 1025, 1025, 1025, 1025,
        1025, 1025, 1025], device='cuda:0')
2020-11-19 21:50:24,995 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([257, 257, 257, 257, 257, 257, 257, 257, 257, 257, 257, 257, 257, 257,
        257])
2020-11-19 21:50:24,997 (ctc:92) INFO: CTC input lengths:  tensor([257, 257, 257, 257, 257, 257, 257, 257, 257, 257, 257, 257, 257, 257,        257], dtype=torch.int32)
2020-11-19 21:50:24,997 (ctc:97) INFO: CTC output lengths: tensor([26, 24, 17, 29, 19, 35, 13, 21, 38, 15, 31, 33, 17, 24, 28],       dtype=torch.int32)
2020-11-19 21:50:25,000 (ctc:119) INFO: ctc loss:81.49150085449219
2020-11-19 21:50:25,118 (e2e_asr:56) INFO: mtl loss:81.49150085449219
2020-11-19 21:50:25,260 (asr:234) INFO: grad norm=202.21019775362777
2020-11-19 21:50:25,269 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1200, 63)
2020-11-19 21:50:25,269 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1200, 63)
2020-11-19 21:50:25,269 (asr:288) INFO: ilens in custom converter = 15 [1200 1200 1200 1175 1175 1175 1175 1175 1175 1150 1150 1150 1150 1150
 1125]
2020-11-19 21:50:25,272 (nets_utils:52) INFO: padded = torch.Size([15, 1200, 63]) 
2020-11-19 21:50:25,274 (nets_utils:52) INFO: padded = torch.Size([15, 46]) 
2020-11-19 21:50:25,276 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1200, 1200, 1200, 1175, 1175, 1175, 1175, 1175, 1175, 1150, 1150, 1150,
        1150, 1150, 1125], device='cuda:0') tensor([1200, 1200, 1200, 1175, 1175, 1175, 1175, 1175, 1175, 1150, 1150, 1150,
        1150, 1150, 1125], device='cuda:0')
2020-11-19 21:50:25,403 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([300, 300, 300, 294, 294, 294, 294, 294, 294, 288, 288, 288, 288, 288,
        282])
2020-11-19 21:50:25,405 (ctc:92) INFO: CTC input lengths:  tensor([300, 300, 300, 294, 294, 294, 294, 294, 294, 288, 288, 288, 288, 288,        282], dtype=torch.int32)
2020-11-19 21:50:25,405 (ctc:97) INFO: CTC output lengths: tensor([35, 19, 46, 17, 17,  9, 11, 25, 17, 28, 13, 28, 33, 27, 19],       dtype=torch.int32)
2020-11-19 21:50:25,409 (ctc:119) INFO: ctc loss:86.60867309570312
2020-11-19 21:50:25,546 (e2e_asr:56) INFO: mtl loss:86.60867309570312
2020-11-19 21:50:25,721 (asr:234) INFO: grad norm=432.50911205593343
2020-11-19 21:50:25,730 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (900, 63)
2020-11-19 21:50:25,730 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (900, 63)
2020-11-19 21:50:25,730 (asr:288) INFO: ilens in custom converter = 15 [900 900 900 900 900 900 900 900 900 900 900 900 900 875 875]
2020-11-19 21:50:25,733 (nets_utils:52) INFO: padded = torch.Size([15, 900, 63]) 
2020-11-19 21:50:25,734 (nets_utils:52) INFO: padded = torch.Size([15, 34]) 
2020-11-19 21:50:25,736 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([900, 900, 900, 900, 900, 900, 900, 900, 900, 900, 900, 900, 900, 875,
        875], device='cuda:0') tensor([900, 900, 900, 900, 900, 900, 900, 900, 900, 900, 900, 900, 900, 875,
        875], device='cuda:0')
2020-11-19 21:50:25,831 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 219,
        219])
2020-11-19 21:50:25,833 (ctc:92) INFO: CTC input lengths:  tensor([225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 219,        219], dtype=torch.int32)
2020-11-19 21:50:25,833 (ctc:97) INFO: CTC output lengths: tensor([23, 11, 27, 31, 15, 19, 20, 34, 13, 13, 32, 15, 17, 25, 24],       dtype=torch.int32)
2020-11-19 21:50:25,836 (ctc:119) INFO: ctc loss:69.5166244506836
2020-11-19 21:50:25,941 (e2e_asr:56) INFO: mtl loss:69.5166244506836
2020-11-19 21:50:26,070 (asr:234) INFO: grad norm=162.81385395927228
2020-11-19 21:50:26,081 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (625, 63)
2020-11-19 21:50:26,081 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (625, 63)
2020-11-19 21:50:26,081 (asr:288) INFO: ilens in custom converter = 30 [625 625 625 625 625 625 625 625 625 625 625 625 625 625 625 625 625 625
 625 625 625 625 625 625 625 625 625 625 625 625]
2020-11-19 21:50:26,084 (nets_utils:52) INFO: padded = torch.Size([30, 625, 63]) 
2020-11-19 21:50:26,086 (nets_utils:52) INFO: padded = torch.Size([30, 40]) 
2020-11-19 21:50:26,089 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625,
        625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625,
        625, 625], device='cuda:0') tensor([625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625,
        625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625,
        625, 625], device='cuda:0')
2020-11-19 21:50:26,170 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
        157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
        157, 157])
2020-11-19 21:50:26,173 (ctc:92) INFO: CTC input lengths:  tensor([157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,        157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,        157, 157], dtype=torch.int32)
2020-11-19 21:50:26,174 (ctc:97) INFO: CTC output lengths: tensor([20,  9, 29, 24, 11,  9, 30, 11,  9, 19, 24, 14, 11, 13,  7, 35,  9, 11,        17, 13,  5, 40, 32, 39, 21, 23, 25, 11, 20, 13], dtype=torch.int32)
2020-11-19 21:50:26,176 (ctc:119) INFO: ctc loss:61.02846145629883
2020-11-19 21:50:26,329 (e2e_asr:56) INFO: mtl loss:61.02846145629883
2020-11-19 21:50:26,445 (asr:234) INFO: grad norm=168.65332208423217
2020-11-19 21:50:26,454 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (325, 63)
2020-11-19 21:50:26,454 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (325, 63)
2020-11-19 21:50:26,454 (asr:288) INFO: ilens in custom converter = 30 [325 300 300 300 300 300 300 300 300 275 275 275 275 275 275 275 275 275
 275 275 275 275 275 275 250 250 250 250 250 250]
2020-11-19 21:50:26,456 (nets_utils:52) INFO: padded = torch.Size([30, 325, 63]) 
2020-11-19 21:50:26,457 (nets_utils:52) INFO: padded = torch.Size([30, 12]) 
2020-11-19 21:50:26,459 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([325, 300, 300, 300, 300, 300, 300, 300, 300, 275, 275, 275, 275, 275,
        275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 250, 250, 250, 250,
        250, 250], device='cuda:0') tensor([325, 300, 300, 300, 300, 300, 300, 300, 300, 275, 275, 275, 275, 275,
        275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 250, 250, 250, 250,
        250, 250], device='cuda:0')
2020-11-19 21:50:26,500 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([82, 75, 75, 75, 75, 75, 75, 75, 75, 69, 69, 69, 69, 69, 69, 69, 69, 69,
        69, 69, 69, 69, 69, 69, 63, 63, 63, 63, 63, 63])
2020-11-19 21:50:26,503 (ctc:92) INFO: CTC input lengths:  tensor([82, 75, 75, 75, 75, 75, 75, 75, 75, 69, 69, 69, 69, 69, 69, 69, 69, 69,        69, 69, 69, 69, 69, 69, 63, 63, 63, 63, 63, 63], dtype=torch.int32)
2020-11-19 21:50:26,503 (ctc:97) INFO: CTC output lengths: tensor([ 9,  4,  5,  3,  5, 10,  4, 12,  6, 12,  6,  4, 10,  3,  7,  4,  6,  4,         5,  6,  6,  5,  3,  9,  3,  4,  6,  4,  3,  6], dtype=torch.int32)
2020-11-19 21:50:26,505 (ctc:119) INFO: ctc loss:20.353248596191406
2020-11-19 21:50:26,580 (e2e_asr:56) INFO: mtl loss:20.353248596191406
2020-11-19 21:50:26,646 (asr:234) INFO: grad norm=29.875478410876408
2020-11-19 21:50:26,656 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (925, 63)
2020-11-19 21:50:26,656 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (925, 63)
2020-11-19 21:50:26,656 (asr:288) INFO: ilens in custom converter = 15 [925 925 925 925 925 925 925 925 925 925 925 925 925 925 900]
2020-11-19 21:50:26,658 (nets_utils:52) INFO: padded = torch.Size([15, 925, 63]) 
2020-11-19 21:50:26,660 (nets_utils:52) INFO: padded = torch.Size([15, 35]) 
2020-11-19 21:50:26,662 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([925, 925, 925, 925, 925, 925, 925, 925, 925, 925, 925, 925, 925, 925,
        900], device='cuda:0') tensor([925, 925, 925, 925, 925, 925, 925, 925, 925, 925, 925, 925, 925, 925,
        900], device='cuda:0')
2020-11-19 21:50:26,760 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232,
        225])
2020-11-19 21:50:26,762 (ctc:92) INFO: CTC input lengths:  tensor([232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232,        225], dtype=torch.int32)
2020-11-19 21:50:26,763 (ctc:97) INFO: CTC output lengths: tensor([35, 17, 34, 19, 19, 34, 26, 15, 15, 15, 22, 33, 18, 28, 32],       dtype=torch.int32)
2020-11-19 21:50:26,766 (ctc:119) INFO: ctc loss:82.25881958007812
2020-11-19 21:50:26,873 (e2e_asr:56) INFO: mtl loss:82.25881958007812
2020-11-19 21:50:27,008 (asr:234) INFO: grad norm=257.82651106314097
2020-11-19 21:50:27,017 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1000, 63)
2020-11-19 21:50:27,017 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1000, 63)
2020-11-19 21:50:27,018 (asr:288) INFO: ilens in custom converter = 15 [1000  975  975  975  975  975  975  975  975  975  975  975  975  975
  975]
2020-11-19 21:50:27,020 (nets_utils:52) INFO: padded = torch.Size([15, 1000, 63]) 
2020-11-19 21:50:27,022 (nets_utils:52) INFO: padded = torch.Size([15, 46]) 
2020-11-19 21:50:27,024 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1000,  975,  975,  975,  975,  975,  975,  975,  975,  975,  975,  975,
         975,  975,  975], device='cuda:0') tensor([1000,  975,  975,  975,  975,  975,  975,  975,  975,  975,  975,  975,
         975,  975,  975], device='cuda:0')
2020-11-19 21:50:27,128 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([250, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244,
        244])
2020-11-19 21:50:27,130 (ctc:92) INFO: CTC input lengths:  tensor([250, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244,        244], dtype=torch.int32)
2020-11-19 21:50:27,130 (ctc:97) INFO: CTC output lengths: tensor([19, 46, 15, 30, 22, 24, 19, 21, 15, 32, 33, 34, 24, 20, 19],       dtype=torch.int32)
2020-11-19 21:50:27,134 (ctc:119) INFO: ctc loss:81.01793670654297
2020-11-19 21:50:27,251 (e2e_asr:56) INFO: mtl loss:81.01793670654297
2020-11-19 21:50:27,394 (asr:234) INFO: grad norm=192.76592834340445
2020-11-19 21:50:27,404 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (425, 63)
2020-11-19 21:50:27,404 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (425, 63)
2020-11-19 21:50:27,404 (asr:288) INFO: ilens in custom converter = 30 [425 425 425 425 425 425 425 425 425 425 425 425 425 425 425 425 425 425
 425 400 400 400 400 400 400 400 400 400 400 400]
2020-11-19 21:50:27,406 (nets_utils:52) INFO: padded = torch.Size([30, 425, 63]) 
2020-11-19 21:50:27,407 (nets_utils:52) INFO: padded = torch.Size([30, 24]) 
2020-11-19 21:50:27,410 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([425, 425, 425, 425, 425, 425, 425, 425, 425, 425, 425, 425, 425, 425,
        425, 425, 425, 425, 425, 400, 400, 400, 400, 400, 400, 400, 400, 400,
        400, 400], device='cuda:0') tensor([425, 425, 425, 425, 425, 425, 425, 425, 425, 425, 425, 425, 425, 425,
        425, 425, 425, 425, 425, 400, 400, 400, 400, 400, 400, 400, 400, 400,
        400, 400], device='cuda:0')
2020-11-19 21:50:27,464 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
        107, 107, 107, 107, 107, 100, 100, 100, 100, 100, 100, 100, 100, 100,
        100, 100])
2020-11-19 21:50:27,467 (ctc:92) INFO: CTC input lengths:  tensor([107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,        107, 107, 107, 107, 107, 100, 100, 100, 100, 100, 100, 100, 100, 100,        100, 100], dtype=torch.int32)
2020-11-19 21:50:27,468 (ctc:97) INFO: CTC output lengths: tensor([16, 17, 15, 21, 19, 22, 22, 18, 22,  7, 22, 20,  5, 19, 14, 15, 10, 19,        19,  9, 20,  2, 15,  9, 17, 15, 17, 11, 24,  9], dtype=torch.int32)
2020-11-19 21:50:27,469 (ctc:119) INFO: ctc loss:48.315879821777344
2020-11-19 21:50:27,573 (e2e_asr:56) INFO: mtl loss:48.315879821777344
2020-11-19 21:50:27,656 (asr:234) INFO: grad norm=79.8050710016519
2020-11-19 21:50:27,666 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1450, 63)
2020-11-19 21:50:27,666 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1450, 63)
2020-11-19 21:50:27,666 (asr:288) INFO: ilens in custom converter = 15 [1450 1450 1425 1425 1400 1375 1375 1375 1375 1375 1350 1350 1350 1325
 1300]
2020-11-19 21:50:27,669 (nets_utils:52) INFO: padded = torch.Size([15, 1450, 63]) 
2020-11-19 21:50:27,671 (nets_utils:52) INFO: padded = torch.Size([15, 47]) 
2020-11-19 21:50:27,674 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1450, 1450, 1425, 1425, 1400, 1375, 1375, 1375, 1375, 1375, 1350, 1350,
        1350, 1325, 1300], device='cuda:0') tensor([1450, 1450, 1425, 1425, 1400, 1375, 1375, 1375, 1375, 1375, 1350, 1350,
        1350, 1325, 1300], device='cuda:0')
2020-11-19 21:50:27,825 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([363, 363, 357, 357, 350, 344, 344, 344, 344, 344, 338, 338, 338, 332,
        325])
2020-11-19 21:50:27,827 (ctc:92) INFO: CTC input lengths:  tensor([363, 363, 357, 357, 350, 344, 344, 344, 344, 344, 338, 338, 338, 332,        325], dtype=torch.int32)
2020-11-19 21:50:27,827 (ctc:97) INFO: CTC output lengths: tensor([37, 25, 19, 34, 17, 21, 36, 23, 19, 32, 47, 23, 19, 21, 19],       dtype=torch.int32)
2020-11-19 21:50:27,832 (ctc:119) INFO: ctc loss:77.08882141113281
2020-11-19 21:50:27,999 (e2e_asr:56) INFO: mtl loss:77.08882141113281
2020-11-19 21:50:28,221 (asr:234) INFO: grad norm=137.1468195570972
2020-11-19 21:50:28,231 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (975, 63)
2020-11-19 21:50:28,231 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (975, 63)
2020-11-19 21:50:28,231 (asr:288) INFO: ilens in custom converter = 15 [975 950 950 950 950 950 950 950 950 950 950 950 950 950 925]
2020-11-19 21:50:28,233 (nets_utils:52) INFO: padded = torch.Size([15, 975, 63]) 
2020-11-19 21:50:28,235 (nets_utils:52) INFO: padded = torch.Size([15, 51]) 
2020-11-19 21:50:28,237 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([975, 950, 950, 950, 950, 950, 950, 950, 950, 950, 950, 950, 950, 950,
        925], device='cuda:0') tensor([975, 950, 950, 950, 950, 950, 950, 950, 950, 950, 950, 950, 950, 950,
        925], device='cuda:0')
2020-11-19 21:50:28,339 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([244, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238,
        232])
2020-11-19 21:50:28,340 (ctc:92) INFO: CTC input lengths:  tensor([244, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238,        232], dtype=torch.int32)
2020-11-19 21:50:28,341 (ctc:97) INFO: CTC output lengths: tensor([46, 15, 50, 30, 51, 20, 25, 19, 47, 32, 17, 47, 19, 18, 49],       dtype=torch.int32)
2020-11-19 21:50:28,344 (ctc:119) INFO: ctc loss:97.81221008300781
2020-11-19 21:50:28,462 (e2e_asr:56) INFO: mtl loss:97.81221008300781
2020-11-19 21:50:28,605 (asr:234) INFO: grad norm=174.0726490743862
2020-11-19 21:50:28,615 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1300, 63)
2020-11-19 21:50:28,615 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1300, 63)
2020-11-19 21:50:28,615 (asr:288) INFO: ilens in custom converter = 15 [1300 1300 1275 1275 1275 1275 1250 1250 1250 1225 1225 1200 1200 1200
 1200]
2020-11-19 21:50:28,618 (nets_utils:52) INFO: padded = torch.Size([15, 1300, 63]) 
2020-11-19 21:50:28,620 (nets_utils:52) INFO: padded = torch.Size([15, 55]) 
2020-11-19 21:50:28,622 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1300, 1300, 1275, 1275, 1275, 1275, 1250, 1250, 1250, 1225, 1225, 1200,
        1200, 1200, 1200], device='cuda:0') tensor([1300, 1300, 1275, 1275, 1275, 1275, 1250, 1250, 1250, 1225, 1225, 1200,
        1200, 1200, 1200], device='cuda:0')
2020-11-19 21:50:28,757 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([325, 325, 319, 319, 319, 319, 313, 313, 313, 307, 307, 300, 300, 300,
        300])
2020-11-19 21:50:28,759 (ctc:92) INFO: CTC input lengths:  tensor([325, 325, 319, 319, 319, 319, 313, 313, 313, 307, 307, 300, 300, 300,        300], dtype=torch.int32)
2020-11-19 21:50:28,759 (ctc:97) INFO: CTC output lengths: tensor([17, 17, 19, 35, 19, 29, 15, 15, 34, 30, 33, 55, 48, 15, 17],       dtype=torch.int32)
2020-11-19 21:50:28,764 (ctc:119) INFO: ctc loss:81.7535171508789
2020-11-19 21:50:28,915 (e2e_asr:56) INFO: mtl loss:81.7535171508789
2020-11-19 21:50:29,105 (asr:234) INFO: grad norm=161.35047142485288
2020-11-19 21:50:29,115 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (525, 63)
2020-11-19 21:50:29,115 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (525, 63)
2020-11-19 21:50:29,115 (asr:288) INFO: ilens in custom converter = 30 [525 525 525 525 525 525 525 525 525 525 525 525 525 525 525 500 500 500
 500 500 500 500 500 500 500 500 500 500 500 500]
2020-11-19 21:50:29,118 (nets_utils:52) INFO: padded = torch.Size([30, 525, 63]) 
2020-11-19 21:50:29,120 (nets_utils:52) INFO: padded = torch.Size([30, 37]) 
2020-11-19 21:50:29,122 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525,
        525, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,
        500, 500], device='cuda:0') tensor([525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525,
        525, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,
        500, 500], device='cuda:0')
2020-11-19 21:50:29,192 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125,
        125, 125])
2020-11-19 21:50:29,195 (ctc:92) INFO: CTC input lengths:  tensor([132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,        132, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125,        125, 125], dtype=torch.int32)
2020-11-19 21:50:29,195 (ctc:97) INFO: CTC output lengths: tensor([30, 37, 11, 22, 22, 15,  7, 22,  9, 22, 15, 23,  9, 22, 21, 15,  9, 17,        19, 23,  9, 23, 22, 17, 14, 11, 21, 22, 11, 26], dtype=torch.int32)
2020-11-19 21:50:29,197 (ctc:119) INFO: ctc loss:55.69606399536133
2020-11-19 21:50:29,328 (e2e_asr:56) INFO: mtl loss:55.69606399536133
2020-11-19 21:50:29,429 (asr:234) INFO: grad norm=100.49922849669646
2020-11-19 21:50:29,440 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (725, 63)
2020-11-19 21:50:29,440 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (725, 63)
2020-11-19 21:50:29,440 (asr:288) INFO: ilens in custom converter = 30 [725 725 725 725 725 725 725 725 725 725 700 700 700 700 700 700 700 700
 700 700 700 700 700 700 700 700 700 700 675 675]
2020-11-19 21:50:29,444 (nets_utils:52) INFO: padded = torch.Size([30, 725, 63]) 
2020-11-19 21:50:29,446 (nets_utils:52) INFO: padded = torch.Size([30, 39]) 
2020-11-19 21:50:29,449 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([725, 725, 725, 725, 725, 725, 725, 725, 725, 725, 700, 700, 700, 700,
        700, 700, 700, 700, 700, 700, 700, 700, 700, 700, 700, 700, 700, 700,
        675, 675], device='cuda:0') tensor([725, 725, 725, 725, 725, 725, 725, 725, 725, 725, 700, 700, 700, 700,
        700, 700, 700, 700, 700, 700, 700, 700, 700, 700, 700, 700, 700, 700,
        675, 675], device='cuda:0')
2020-11-19 21:50:29,542 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 175, 175, 175, 175,
        175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175,
        169, 169])
2020-11-19 21:50:29,545 (ctc:92) INFO: CTC input lengths:  tensor([182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 175, 175, 175, 175,        175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175,        169, 169], dtype=torch.int32)
2020-11-19 21:50:29,546 (ctc:97) INFO: CTC output lengths: tensor([25, 20, 15, 19, 24, 11, 23, 21, 20, 30, 20, 11,  9, 13, 22, 19, 17, 17,        19, 34, 39, 11, 36, 19, 11, 18, 35, 19,  9, 11], dtype=torch.int32)
2020-11-19 21:50:29,548 (ctc:119) INFO: ctc loss:64.55738067626953
2020-11-19 21:50:29,722 (e2e_asr:56) INFO: mtl loss:64.55738067626953
2020-11-19 21:50:29,863 (asr:234) INFO: grad norm=136.9545712315636
2020-11-19 21:50:29,873 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (400, 63)
2020-11-19 21:50:29,873 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (400, 63)
2020-11-19 21:50:29,873 (asr:288) INFO: ilens in custom converter = 30 [400 400 400 400 400 400 400 400 375 375 375 375 375 375 375 375 375 375
 375 375 375 375 375 375 375 375 375 350 350 350]
2020-11-19 21:50:29,875 (nets_utils:52) INFO: padded = torch.Size([30, 400, 63]) 
2020-11-19 21:50:29,877 (nets_utils:52) INFO: padded = torch.Size([30, 22]) 
2020-11-19 21:50:29,879 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([400, 400, 400, 400, 400, 400, 400, 400, 375, 375, 375, 375, 375, 375,
        375, 375, 375, 375, 375, 375, 375, 375, 375, 375, 375, 375, 375, 350,
        350, 350], device='cuda:0') tensor([400, 400, 400, 400, 400, 400, 400, 400, 375, 375, 375, 375, 375, 375,
        375, 375, 375, 375, 375, 375, 375, 375, 375, 375, 375, 375, 375, 350,
        350, 350], device='cuda:0')
2020-11-19 21:50:29,930 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([100, 100, 100, 100, 100, 100, 100, 100,  94,  94,  94,  94,  94,  94,
         94,  94,  94,  94,  94,  94,  94,  94,  94,  94,  94,  94,  94,  88,
         88,  88])
2020-11-19 21:50:29,933 (ctc:92) INFO: CTC input lengths:  tensor([100, 100, 100, 100, 100, 100, 100, 100,  94,  94,  94,  94,  94,  94,         94,  94,  94,  94,  94,  94,  94,  94,  94,  94,  94,  94,  94,  88,         88,  88], dtype=torch.int32)
2020-11-19 21:50:29,934 (ctc:97) INFO: CTC output lengths: tensor([ 7, 18, 18,  9, 20, 22, 20,  7,  7, 13, 14, 12, 11,  7, 16,  7, 19, 17,        11,  7, 10,  9, 18, 16,  9, 13, 16, 13, 11, 17], dtype=torch.int32)
2020-11-19 21:50:29,935 (ctc:119) INFO: ctc loss:40.60697555541992
2020-11-19 21:50:30,032 (e2e_asr:56) INFO: mtl loss:40.60697555541992
2020-11-19 21:50:30,111 (asr:234) INFO: grad norm=84.09557971664935
2020-11-19 21:50:30,120 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (825, 63)
2020-11-19 21:50:30,121 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (825, 63)
2020-11-19 21:50:30,121 (asr:288) INFO: ilens in custom converter = 15 [825 825 825 825 825 825 825 825 800 800 800 800 800 800 800]
2020-11-19 21:50:30,123 (nets_utils:52) INFO: padded = torch.Size([15, 825, 63]) 
2020-11-19 21:50:30,124 (nets_utils:52) INFO: padded = torch.Size([15, 35]) 
2020-11-19 21:50:30,126 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([825, 825, 825, 825, 825, 825, 825, 825, 800, 800, 800, 800, 800, 800,
        800], device='cuda:0') tensor([825, 825, 825, 825, 825, 825, 825, 825, 800, 800, 800, 800, 800, 800,
        800], device='cuda:0')
2020-11-19 21:50:30,215 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([207, 207, 207, 207, 207, 207, 207, 207, 200, 200, 200, 200, 200, 200,
        200])
2020-11-19 21:50:30,217 (ctc:92) INFO: CTC input lengths:  tensor([207, 207, 207, 207, 207, 207, 207, 207, 200, 200, 200, 200, 200, 200,        200], dtype=torch.int32)
2020-11-19 21:50:30,217 (ctc:97) INFO: CTC output lengths: tensor([15, 18, 19, 21, 35, 23, 30, 19, 22, 32, 24, 13, 13, 24, 13],       dtype=torch.int32)
2020-11-19 21:50:30,220 (ctc:119) INFO: ctc loss:67.72266387939453
2020-11-19 21:50:30,319 (e2e_asr:56) INFO: mtl loss:67.72266387939453
2020-11-19 21:50:30,438 (asr:234) INFO: grad norm=144.41606088990096
2020-11-19 21:50:30,448 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1025, 63)
2020-11-19 21:50:30,448 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1025, 63)
2020-11-19 21:50:30,448 (asr:288) INFO: ilens in custom converter = 15 [1025 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000
 1000]
2020-11-19 21:50:30,451 (nets_utils:52) INFO: padded = torch.Size([15, 1025, 63]) 
2020-11-19 21:50:30,452 (nets_utils:52) INFO: padded = torch.Size([15, 51]) 
2020-11-19 21:50:30,454 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1025, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,
        1000, 1000, 1000], device='cuda:0') tensor([1025, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,
        1000, 1000, 1000], device='cuda:0')
2020-11-19 21:50:30,561 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([257, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250,
        250])
2020-11-19 21:50:30,563 (ctc:92) INFO: CTC input lengths:  tensor([257, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250,        250], dtype=torch.int32)
2020-11-19 21:50:30,563 (ctc:97) INFO: CTC output lengths: tensor([51, 19, 29, 28, 35, 21, 19, 47, 33, 24, 19, 32, 27, 19, 26],       dtype=torch.int32)
2020-11-19 21:50:30,567 (ctc:119) INFO: ctc loss:91.41880798339844
2020-11-19 21:50:30,691 (e2e_asr:56) INFO: mtl loss:91.41880798339844
2020-11-19 21:50:30,837 (asr:234) INFO: grad norm=241.05842685838007
2020-11-19 21:50:30,847 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (650, 63)
2020-11-19 21:50:30,847 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (650, 63)
2020-11-19 21:50:30,848 (asr:288) INFO: ilens in custom converter = 30 [650 650 650 650 650 650 650 650 650 650 650 650 650 650 650 650 650 650
 650 650 650 650 625 625 625 625 625 625 625 625]
2020-11-19 21:50:30,851 (nets_utils:52) INFO: padded = torch.Size([30, 650, 63]) 
2020-11-19 21:50:30,853 (nets_utils:52) INFO: padded = torch.Size([30, 36]) 
2020-11-19 21:50:30,856 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650,
        650, 650, 650, 650, 650, 650, 650, 650, 625, 625, 625, 625, 625, 625,
        625, 625], device='cuda:0') tensor([650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650,
        650, 650, 650, 650, 650, 650, 650, 650, 625, 625, 625, 625, 625, 625,
        625, 625], device='cuda:0')
2020-11-19 21:50:30,938 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163,
        163, 163, 163, 163, 163, 163, 163, 163, 157, 157, 157, 157, 157, 157,
        157, 157])
2020-11-19 21:50:30,941 (ctc:92) INFO: CTC input lengths:  tensor([163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163,        163, 163, 163, 163, 163, 163, 163, 163, 157, 157, 157, 157, 157, 157,        157, 157], dtype=torch.int32)
2020-11-19 21:50:30,941 (ctc:97) INFO: CTC output lengths: tensor([29, 26, 25, 13, 25, 36, 23, 33, 21, 13,  9, 28, 11, 19, 13,  9, 26, 11,        21, 26,  9, 11, 15, 32, 18, 11, 29, 24, 17, 12], dtype=torch.int32)
2020-11-19 21:50:30,944 (ctc:119) INFO: ctc loss:65.27810668945312
2020-11-19 21:50:31,101 (e2e_asr:56) INFO: mtl loss:65.27810668945312
2020-11-19 21:50:31,223 (asr:234) INFO: grad norm=136.1747869082741
2020-11-19 21:50:31,233 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (500, 63)
2020-11-19 21:50:31,233 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (500, 63)
2020-11-19 21:50:31,233 (asr:288) INFO: ilens in custom converter = 30 [500 500 500 500 500 500 500 500 500 500 500 500 500 500 475 475 475 475
 475 475 475 475 475 475 475 475 475 475 475 475]
2020-11-19 21:50:31,236 (nets_utils:52) INFO: padded = torch.Size([30, 500, 63]) 
2020-11-19 21:50:31,237 (nets_utils:52) INFO: padded = torch.Size([30, 28]) 
2020-11-19 21:50:31,240 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,
        475, 475, 475, 475, 475, 475, 475, 475, 475, 475, 475, 475, 475, 475,
        475, 475], device='cuda:0') tensor([500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,
        475, 475, 475, 475, 475, 475, 475, 475, 475, 475, 475, 475, 475, 475,
        475, 475], device='cuda:0')
2020-11-19 21:50:31,304 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125,
        119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119,
        119, 119])
2020-11-19 21:50:31,307 (ctc:92) INFO: CTC input lengths:  tensor([125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125,        119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119,        119, 119], dtype=torch.int32)
2020-11-19 21:50:31,308 (ctc:97) INFO: CTC output lengths: tensor([17, 12, 21, 20,  7, 17,  7, 11, 28, 15, 11, 13, 20, 27, 21,  9, 15,  9,        10, 13, 20, 22,  9, 17, 20, 24, 13,  9, 17,  9], dtype=torch.int32)
2020-11-19 21:50:31,309 (ctc:119) INFO: ctc loss:48.12180709838867
2020-11-19 21:50:31,432 (e2e_asr:56) INFO: mtl loss:48.12180709838867
2020-11-19 21:50:31,527 (asr:234) INFO: grad norm=109.26082504534284
2020-11-19 21:50:31,536 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (850, 63)
2020-11-19 21:50:31,536 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (850, 63)
2020-11-19 21:50:31,537 (asr:288) INFO: ilens in custom converter = 15 [850 850 850 850 850 850 850 850 850 850 850 850 850 825 825]
2020-11-19 21:50:31,539 (nets_utils:52) INFO: padded = torch.Size([15, 850, 63]) 
2020-11-19 21:50:31,540 (nets_utils:52) INFO: padded = torch.Size([15, 46]) 
2020-11-19 21:50:31,542 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([850, 850, 850, 850, 850, 850, 850, 850, 850, 850, 850, 850, 850, 825,
        825], device='cuda:0') tensor([850, 850, 850, 850, 850, 850, 850, 850, 850, 850, 850, 850, 850, 825,
        825], device='cuda:0')
2020-11-19 21:50:31,631 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 207,
        207])
2020-11-19 21:50:31,633 (ctc:92) INFO: CTC input lengths:  tensor([213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 207,        207], dtype=torch.int32)
2020-11-19 21:50:31,633 (ctc:97) INFO: CTC output lengths: tensor([11, 13, 38, 32, 18, 15, 32, 46, 23, 20,  9, 29, 14, 22, 23],       dtype=torch.int32)
2020-11-19 21:50:31,636 (ctc:119) INFO: ctc loss:73.87171936035156
2020-11-19 21:50:31,738 (e2e_asr:56) INFO: mtl loss:73.87171936035156
2020-11-19 21:50:31,860 (asr:234) INFO: grad norm=145.15562524360462
2020-11-19 21:50:31,869 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1075, 63)
2020-11-19 21:50:31,869 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1075, 63)
2020-11-19 21:50:31,870 (asr:288) INFO: ilens in custom converter = 15 [1075 1075 1075 1075 1075 1075 1075 1075 1075 1075 1075 1075 1050 1050
 1050]
2020-11-19 21:50:31,872 (nets_utils:52) INFO: padded = torch.Size([15, 1075, 63]) 
2020-11-19 21:50:31,874 (nets_utils:52) INFO: padded = torch.Size([15, 34]) 
2020-11-19 21:50:31,876 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075,
        1050, 1050, 1050], device='cuda:0') tensor([1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075,
        1050, 1050, 1050], device='cuda:0')
2020-11-19 21:50:31,989 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([269, 269, 269, 269, 269, 269, 269, 269, 269, 269, 269, 269, 263, 263,
        263])
2020-11-19 21:50:31,991 (ctc:92) INFO: CTC input lengths:  tensor([269, 269, 269, 269, 269, 269, 269, 269, 269, 269, 269, 269, 263, 263,        263], dtype=torch.int32)
2020-11-19 21:50:31,991 (ctc:97) INFO: CTC output lengths: tensor([34, 19, 17, 32, 17, 20, 13, 15, 26, 13, 19, 25, 21, 19, 17],       dtype=torch.int32)
2020-11-19 21:50:31,995 (ctc:119) INFO: ctc loss:75.22892761230469
2020-11-19 21:50:32,116 (e2e_asr:56) INFO: mtl loss:75.22892761230469
2020-11-19 21:50:32,268 (asr:234) INFO: grad norm=348.952334101287
2020-11-19 21:50:32,278 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (625, 63)
2020-11-19 21:50:32,279 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (625, 63)
2020-11-19 21:50:32,279 (asr:288) INFO: ilens in custom converter = 30 [625 600 600 600 600 600 600 600 600 600 600 600 600 600 600 600 600 600
 600 600 600 600 600 600 600 600 600 600 600 600]
2020-11-19 21:50:32,282 (nets_utils:52) INFO: padded = torch.Size([30, 625, 63]) 
2020-11-19 21:50:32,283 (nets_utils:52) INFO: padded = torch.Size([30, 36]) 
2020-11-19 21:50:32,286 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([625, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600,
        600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600,
        600, 600], device='cuda:0') tensor([625, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600,
        600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600,
        600, 600], device='cuda:0')
2020-11-19 21:50:32,367 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([157, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
        150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
        150, 150])
2020-11-19 21:50:32,370 (ctc:92) INFO: CTC input lengths:  tensor([157, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,        150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,        150, 150], dtype=torch.int32)
2020-11-19 21:50:32,370 (ctc:97) INFO: CTC output lengths: tensor([31, 19, 27, 11, 18, 19, 34,  7, 25, 20, 24, 21, 23, 22, 13, 36, 31, 13,        29, 20, 22, 32, 13, 16, 15, 19, 21, 23, 11, 20], dtype=torch.int32)
2020-11-19 21:50:32,372 (ctc:119) INFO: ctc loss:69.18898010253906
2020-11-19 21:50:32,524 (e2e_asr:56) INFO: mtl loss:69.18898010253906
2020-11-19 21:50:32,642 (asr:234) INFO: grad norm=150.98507654469154
2020-11-19 21:50:32,651 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 10 (1600, 63)
2020-11-19 21:50:32,651 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 10 (1600, 63)
2020-11-19 21:50:32,651 (asr:288) INFO: ilens in custom converter = 10 [1600 1325 1250 1225 1225 1175 1175 1125 1100 1075]
2020-11-19 21:50:32,653 (nets_utils:52) INFO: padded = torch.Size([10, 1600, 63]) 
2020-11-19 21:50:32,655 (nets_utils:52) INFO: padded = torch.Size([10, 46]) 
2020-11-19 21:50:32,657 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([10]) torch.Size([10]) hlens,ilens=tensor([1600, 1325, 1250, 1225, 1225, 1175, 1175, 1125, 1100, 1075],
       device='cuda:0') tensor([1600, 1325, 1250, 1225, 1225, 1175, 1175, 1125, 1100, 1075],
       device='cuda:0')
2020-11-19 21:50:32,795 (e2e_asr:368) INFO: encoder ilens=torch.Size([10]) tensor([400, 332, 313, 307, 307, 294, 294, 282, 275, 269])
2020-11-19 21:50:32,796 (ctc:92) INFO: CTC input lengths:  tensor([400, 332, 313, 307, 307, 294, 294, 282, 275, 269], dtype=torch.int32)
2020-11-19 21:50:32,796 (ctc:97) INFO: CTC output lengths: tensor([40, 23, 21, 19, 46, 25, 27, 19, 17, 34], dtype=torch.int32)
2020-11-19 21:50:32,801 (ctc:119) INFO: ctc loss:93.74956512451172
2020-11-19 21:50:32,924 (e2e_asr:56) INFO: mtl loss:93.74956512451172
2020-11-19 21:50:32,926 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1075, 63)
2020-11-19 21:50:32,926 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1075, 63)
2020-11-19 21:50:32,927 (asr:288) INFO: ilens in custom converter = 15 [1075 1075 1075 1025 1000  950  925  925  900  900  875  875  875  850
  850]
2020-11-19 21:50:32,929 (nets_utils:52) INFO: padded = torch.Size([15, 1075, 63]) 
2020-11-19 21:50:32,931 (nets_utils:52) INFO: padded = torch.Size([15, 39]) 
2020-11-19 21:50:32,933 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1075, 1075, 1075, 1025, 1000,  950,  925,  925,  900,  900,  875,  875,
         875,  850,  850], device='cuda:0') tensor([1075, 1075, 1075, 1025, 1000,  950,  925,  925,  900,  900,  875,  875,
         875,  850,  850], device='cuda:0')
2020-11-19 21:50:33,041 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([269, 269, 269, 257, 250, 238, 232, 232, 225, 225, 219, 219, 219, 213,
        213])
2020-11-19 21:50:33,043 (ctc:92) INFO: CTC input lengths:  tensor([269, 269, 269, 257, 250, 238, 232, 232, 225, 225, 219, 219, 219, 213,        213], dtype=torch.int32)
2020-11-19 21:50:33,043 (ctc:97) INFO: CTC output lengths: tensor([15, 19, 15, 19, 27, 26, 17, 19, 15, 23, 11, 39, 21, 11, 24],       dtype=torch.int32)
2020-11-19 21:50:33,046 (ctc:119) INFO: ctc loss:70.0871810913086
2020-11-19 21:50:33,169 (e2e_asr:56) INFO: mtl loss:70.0871810913086
2020-11-19 21:50:33,171 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (850, 63)
2020-11-19 21:50:33,171 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (850, 63)
2020-11-19 21:50:33,172 (asr:288) INFO: ilens in custom converter = 15 [850 825 825 825 775 775 775 775 750 750 750 725 725 725 725]
2020-11-19 21:50:33,174 (nets_utils:52) INFO: padded = torch.Size([15, 850, 63]) 
2020-11-19 21:50:33,175 (nets_utils:52) INFO: padded = torch.Size([15, 35]) 
2020-11-19 21:50:33,177 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([850, 825, 825, 825, 775, 775, 775, 775, 750, 750, 750, 725, 725, 725,
        725], device='cuda:0') tensor([850, 825, 825, 825, 775, 775, 775, 775, 750, 750, 750, 725, 725, 725,
        725], device='cuda:0')
2020-11-19 21:50:33,263 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([213, 207, 207, 207, 194, 194, 194, 194, 188, 188, 188, 182, 182, 182,
        182])
2020-11-19 21:50:33,265 (ctc:92) INFO: CTC input lengths:  tensor([213, 207, 207, 207, 194, 194, 194, 194, 188, 188, 188, 182, 182, 182,        182], dtype=torch.int32)
2020-11-19 21:50:33,265 (ctc:97) INFO: CTC output lengths: tensor([27, 15, 13, 19, 33, 21, 32, 30, 13, 35, 34, 15, 11, 27, 24],       dtype=torch.int32)
2020-11-19 21:50:33,268 (ctc:119) INFO: ctc loss:72.14510345458984
2020-11-19 21:50:33,368 (e2e_asr:56) INFO: mtl loss:72.14510345458984
2020-11-19 21:50:33,372 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (700, 63)
2020-11-19 21:50:33,372 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (700, 63)
2020-11-19 21:50:33,373 (asr:288) INFO: ilens in custom converter = 30 [700 700 700 675 675 675 675 650 650 625 625 600 600 600 600 575 575 575
 575 575 550 550 550 550 525 525 500 500 500 500]
2020-11-19 21:50:33,376 (nets_utils:52) INFO: padded = torch.Size([30, 700, 63]) 
2020-11-19 21:50:33,378 (nets_utils:52) INFO: padded = torch.Size([30, 43]) 
2020-11-19 21:50:33,381 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([700, 700, 700, 675, 675, 675, 675, 650, 650, 625, 625, 600, 600, 600,
        600, 575, 575, 575, 575, 575, 550, 550, 550, 550, 525, 525, 500, 500,
        500, 500], device='cuda:0') tensor([700, 700, 700, 675, 675, 675, 675, 650, 650, 625, 625, 600, 600, 600,
        600, 575, 575, 575, 575, 575, 550, 550, 550, 550, 525, 525, 500, 500,
        500, 500], device='cuda:0')
2020-11-19 21:50:33,466 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([175, 175, 175, 169, 169, 169, 169, 163, 163, 157, 157, 150, 150, 150,
        150, 144, 144, 144, 144, 144, 138, 138, 138, 138, 132, 132, 125, 125,
        125, 125])
2020-11-19 21:50:33,469 (ctc:92) INFO: CTC input lengths:  tensor([175, 175, 175, 169, 169, 169, 169, 163, 163, 157, 157, 150, 150, 150,        150, 144, 144, 144, 144, 144, 138, 138, 138, 138, 132, 132, 125, 125,        125, 125], dtype=torch.int32)
2020-11-19 21:50:33,469 (ctc:97) INFO: CTC output lengths: tensor([33, 17, 15, 34, 12, 21, 27, 13, 43, 33,  9, 11, 21, 13, 33, 19, 22,  7,        22, 15, 21, 26, 28, 23, 22, 31, 20, 20, 12, 25], dtype=torch.int32)
2020-11-19 21:50:33,472 (ctc:119) INFO: ctc loss:65.17852020263672
2020-11-19 21:50:33,642 (e2e_asr:56) INFO: mtl loss:65.17852020263672
2020-11-19 21:50:33,645 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (475, 63)
2020-11-19 21:50:33,645 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (475, 63)
2020-11-19 21:50:33,645 (asr:288) INFO: ilens in custom converter = 30 [475 450 450 450 450 425 425 425 400 400 400 375 375 375 375 375 325 325
 275 250 250 250 250 225 225 225 200 200 175 175]
2020-11-19 21:50:33,647 (nets_utils:52) INFO: padded = torch.Size([30, 475, 63]) 
2020-11-19 21:50:33,648 (nets_utils:52) INFO: padded = torch.Size([30, 32]) 
2020-11-19 21:50:33,651 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([475, 450, 450, 450, 450, 425, 425, 425, 400, 400, 400, 375, 375, 375,
        375, 375, 325, 325, 275, 250, 250, 250, 250, 225, 225, 225, 200, 200,
        175, 175], device='cuda:0') tensor([475, 450, 450, 450, 450, 425, 425, 425, 400, 400, 400, 375, 375, 375,
        375, 375, 325, 325, 275, 250, 250, 250, 250, 225, 225, 225, 200, 200,
        175, 175], device='cuda:0')
2020-11-19 21:50:33,708 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([119, 113, 113, 113, 113, 107, 107, 107, 100, 100, 100,  94,  94,  94,
         94,  94,  82,  82,  69,  63,  63,  63,  63,  57,  57,  57,  50,  50,
         44,  44])
2020-11-19 21:50:33,711 (ctc:92) INFO: CTC input lengths:  tensor([119, 113, 113, 113, 113, 107, 107, 107, 100, 100, 100,  94,  94,  94,         94,  94,  82,  82,  69,  63,  63,  63,  63,  57,  57,  57,  50,  50,         44,  44], dtype=torch.int32)
2020-11-19 21:50:33,711 (ctc:97) INFO: CTC output lengths: tensor([20, 16, 15, 19, 19, 18, 19, 32, 24, 17,  9, 10,  9, 11,  9, 21,  5, 16,        13,  3,  2, 12,  7,  3,  3,  4,  2,  2,  2,  4], dtype=torch.int32)
2020-11-19 21:50:33,713 (ctc:119) INFO: ctc loss:37.208213806152344
2020-11-19 21:50:33,831 (e2e_asr:56) INFO: mtl loss:37.208213806152344
/home/john/anaconda3/lib/python3.7/site-packages/chainer/training/triggers/early_stopping_trigger.py:102: UserWarning: validation/main/acc is not in observation
  warnings.warn('{} is not in observation'.format(self.monitor))
2020-11-19 21:50:34,597 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (850, 63)
2020-11-19 21:50:34,597 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (850, 63)
2020-11-19 21:50:34,598 (asr:288) INFO: ilens in custom converter = 15 [850 850 850 850 850 850 850 850 850 850 850 850 850 825 825]
2020-11-19 21:50:34,600 (nets_utils:52) INFO: padded = torch.Size([15, 850, 63]) 
2020-11-19 21:50:34,601 (nets_utils:52) INFO: padded = torch.Size([15, 46]) 
2020-11-19 21:50:34,603 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([850, 850, 850, 850, 850, 850, 850, 850, 850, 850, 850, 850, 850, 825,
        825], device='cuda:0') tensor([850, 850, 850, 850, 850, 850, 850, 850, 850, 850, 850, 850, 850, 825,
        825], device='cuda:0')
2020-11-19 21:50:34,692 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 207,
        207])
2020-11-19 21:50:34,694 (ctc:92) INFO: CTC input lengths:  tensor([213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 207,        207], dtype=torch.int32)
2020-11-19 21:50:34,694 (ctc:97) INFO: CTC output lengths: tensor([11, 13, 38, 32, 18, 15, 32, 46, 23, 20,  9, 29, 14, 22, 23],       dtype=torch.int32)
2020-11-19 21:50:34,697 (ctc:119) INFO: ctc loss:75.22822570800781
2020-11-19 21:50:34,801 (e2e_asr:56) INFO: mtl loss:75.22822570800781
2020-11-19 21:50:34,924 (asr:234) INFO: grad norm=208.27378325440674
2020-11-19 21:50:34,934 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (625, 63)
2020-11-19 21:50:34,934 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (625, 63)
2020-11-19 21:50:34,934 (asr:288) INFO: ilens in custom converter = 30 [625 600 600 600 600 600 600 600 600 600 600 600 600 600 600 600 600 600
 600 600 600 600 600 600 600 600 600 600 600 600]
2020-11-19 21:50:34,937 (nets_utils:52) INFO: padded = torch.Size([30, 625, 63]) 
2020-11-19 21:50:34,939 (nets_utils:52) INFO: padded = torch.Size([30, 36]) 
2020-11-19 21:50:34,942 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([625, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600,
        600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600,
        600, 600], device='cuda:0') tensor([625, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600,
        600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600,
        600, 600], device='cuda:0')
2020-11-19 21:50:35,021 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([157, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
        150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
        150, 150])
2020-11-19 21:50:35,024 (ctc:92) INFO: CTC input lengths:  tensor([157, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,        150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,        150, 150], dtype=torch.int32)
2020-11-19 21:50:35,024 (ctc:97) INFO: CTC output lengths: tensor([31, 19, 27, 11, 18, 19, 34,  7, 25, 20, 24, 21, 23, 22, 13, 36, 31, 13,        29, 20, 22, 32, 13, 16, 15, 19, 21, 23, 11, 20], dtype=torch.int32)
2020-11-19 21:50:35,026 (ctc:119) INFO: ctc loss:68.45964813232422
2020-11-19 21:50:35,182 (e2e_asr:56) INFO: mtl loss:68.45964813232422
2020-11-19 21:50:35,302 (asr:234) INFO: grad norm=147.95102418734587
2020-11-19 21:50:35,311 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (250, 63)
2020-11-19 21:50:35,311 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (250, 63)
2020-11-19 21:50:35,311 (asr:288) INFO: ilens in custom converter = 30 [250 250 250 250 250 250 250 250 250 250 250 250 250 250 250 250 250 250
 250 250 250 250 250 250 225 225 225 225 225 225]
2020-11-19 21:50:35,313 (nets_utils:52) INFO: padded = torch.Size([30, 250, 63]) 
2020-11-19 21:50:35,314 (nets_utils:52) INFO: padded = torch.Size([30, 11]) 
2020-11-19 21:50:35,316 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250,
        250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 225, 225, 225, 225,
        225, 225], device='cuda:0') tensor([250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250,
        250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 225, 225, 225, 225,
        225, 225], device='cuda:0')
2020-11-19 21:50:35,349 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63,
        63, 63, 63, 63, 63, 63, 57, 57, 57, 57, 57, 57])
2020-11-19 21:50:35,352 (ctc:92) INFO: CTC input lengths:  tensor([63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63,        63, 63, 63, 63, 63, 63, 57, 57, 57, 57, 57, 57], dtype=torch.int32)
2020-11-19 21:50:35,352 (ctc:97) INFO: CTC output lengths: tensor([ 5,  6,  5,  3,  6,  2,  2,  5,  3,  4,  3,  4,  5,  6,  5,  3,  3,  4,         3,  4,  3,  3, 11,  5,  6,  2,  2,  4,  5,  2], dtype=torch.int32)
2020-11-19 21:50:35,353 (ctc:119) INFO: ctc loss:20.987436294555664
2020-11-19 21:50:35,413 (e2e_asr:56) INFO: mtl loss:20.987436294555664
2020-11-19 21:50:35,463 (asr:234) INFO: grad norm=93.73017693460349
2020-11-19 21:50:35,472 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (800, 63)
2020-11-19 21:50:35,472 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (800, 63)
2020-11-19 21:50:35,472 (asr:288) INFO: ilens in custom converter = 15 [800 800 800 800 800 800 800 800 800 800 800 800 800 800 800]
2020-11-19 21:50:35,474 (nets_utils:52) INFO: padded = torch.Size([15, 800, 63]) 
2020-11-19 21:50:35,476 (nets_utils:52) INFO: padded = torch.Size([15, 38]) 
2020-11-19 21:50:35,478 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([800, 800, 800, 800, 800, 800, 800, 800, 800, 800, 800, 800, 800, 800,
        800], device='cuda:0') tensor([800, 800, 800, 800, 800, 800, 800, 800, 800, 800, 800, 800, 800, 800,
        800], device='cuda:0')
2020-11-19 21:50:35,562 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,
        200])
2020-11-19 21:50:35,564 (ctc:92) INFO: CTC input lengths:  tensor([200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,        200], dtype=torch.int32)
2020-11-19 21:50:35,564 (ctc:97) INFO: CTC output lengths: tensor([13, 29, 37, 20, 29, 18, 18, 36, 25, 22, 21, 19, 27, 13, 38],       dtype=torch.int32)
2020-11-19 21:50:35,566 (ctc:119) INFO: ctc loss:75.5046157836914
2020-11-19 21:50:35,661 (e2e_asr:56) INFO: mtl loss:75.5046157836914
2020-11-19 21:50:35,773 (asr:234) INFO: grad norm=151.08652414443014
2020-11-19 21:50:35,783 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (925, 63)
2020-11-19 21:50:35,783 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (925, 63)
2020-11-19 21:50:35,783 (asr:288) INFO: ilens in custom converter = 15 [925 925 925 925 925 925 925 925 925 925 925 925 925 925 900]
2020-11-19 21:50:35,786 (nets_utils:52) INFO: padded = torch.Size([15, 925, 63]) 
2020-11-19 21:50:35,787 (nets_utils:52) INFO: padded = torch.Size([15, 35]) 
2020-11-19 21:50:35,789 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([925, 925, 925, 925, 925, 925, 925, 925, 925, 925, 925, 925, 925, 925,
        900], device='cuda:0') tensor([925, 925, 925, 925, 925, 925, 925, 925, 925, 925, 925, 925, 925, 925,
        900], device='cuda:0')
2020-11-19 21:50:35,887 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232,
        225])
2020-11-19 21:50:35,889 (ctc:92) INFO: CTC input lengths:  tensor([232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232,        225], dtype=torch.int32)
2020-11-19 21:50:35,889 (ctc:97) INFO: CTC output lengths: tensor([35, 17, 34, 19, 19, 34, 26, 15, 15, 15, 22, 33, 18, 28, 32],       dtype=torch.int32)
2020-11-19 21:50:35,892 (ctc:119) INFO: ctc loss:77.26084899902344
2020-11-19 21:50:36,000 (e2e_asr:56) INFO: mtl loss:77.26084899902344
2020-11-19 21:50:36,133 (asr:234) INFO: grad norm=227.45994294039798
2020-11-19 21:50:36,143 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1025, 63)
2020-11-19 21:50:36,143 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1025, 63)
2020-11-19 21:50:36,143 (asr:288) INFO: ilens in custom converter = 15 [1025 1025 1025 1025 1025 1025 1025 1025 1025 1025 1025 1025 1025 1025
 1025]
2020-11-19 21:50:36,147 (nets_utils:52) INFO: padded = torch.Size([15, 1025, 63]) 
2020-11-19 21:50:36,148 (nets_utils:52) INFO: padded = torch.Size([15, 38]) 
2020-11-19 21:50:36,150 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1025, 1025, 1025, 1025, 1025, 1025, 1025, 1025, 1025, 1025, 1025, 1025,
        1025, 1025, 1025], device='cuda:0') tensor([1025, 1025, 1025, 1025, 1025, 1025, 1025, 1025, 1025, 1025, 1025, 1025,
        1025, 1025, 1025], device='cuda:0')
2020-11-19 21:50:36,258 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([257, 257, 257, 257, 257, 257, 257, 257, 257, 257, 257, 257, 257, 257,
        257])
2020-11-19 21:50:36,260 (ctc:92) INFO: CTC input lengths:  tensor([257, 257, 257, 257, 257, 257, 257, 257, 257, 257, 257, 257, 257, 257,        257], dtype=torch.int32)
2020-11-19 21:50:36,260 (ctc:97) INFO: CTC output lengths: tensor([26, 24, 17, 29, 19, 35, 13, 21, 38, 15, 31, 33, 17, 24, 28],       dtype=torch.int32)
2020-11-19 21:50:36,263 (ctc:119) INFO: ctc loss:73.86405944824219
2020-11-19 21:50:36,382 (e2e_asr:56) INFO: mtl loss:73.86405944824219
2020-11-19 21:50:36,525 (asr:234) INFO: grad norm=125.76089906010928
2020-11-19 21:50:36,535 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (825, 63)
2020-11-19 21:50:36,535 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (825, 63)
2020-11-19 21:50:36,535 (asr:288) INFO: ilens in custom converter = 15 [825 825 825 825 825 825 825 825 800 800 800 800 800 800 800]
2020-11-19 21:50:36,537 (nets_utils:52) INFO: padded = torch.Size([15, 825, 63]) 
2020-11-19 21:50:36,538 (nets_utils:52) INFO: padded = torch.Size([15, 35]) 
2020-11-19 21:50:36,540 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([825, 825, 825, 825, 825, 825, 825, 825, 800, 800, 800, 800, 800, 800,
        800], device='cuda:0') tensor([825, 825, 825, 825, 825, 825, 825, 825, 800, 800, 800, 800, 800, 800,
        800], device='cuda:0')
2020-11-19 21:50:36,628 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([207, 207, 207, 207, 207, 207, 207, 207, 200, 200, 200, 200, 200, 200,
        200])
2020-11-19 21:50:36,630 (ctc:92) INFO: CTC input lengths:  tensor([207, 207, 207, 207, 207, 207, 207, 207, 200, 200, 200, 200, 200, 200,        200], dtype=torch.int32)
2020-11-19 21:50:36,630 (ctc:97) INFO: CTC output lengths: tensor([15, 18, 19, 21, 35, 23, 30, 19, 22, 32, 24, 13, 13, 24, 13],       dtype=torch.int32)
2020-11-19 21:50:36,633 (ctc:119) INFO: ctc loss:68.69657897949219
2020-11-19 21:50:36,730 (e2e_asr:56) INFO: mtl loss:68.69657897949219
2020-11-19 21:50:36,848 (asr:234) INFO: grad norm=199.32385580718977
2020-11-19 21:50:36,858 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (500, 63)
2020-11-19 21:50:36,858 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (500, 63)
2020-11-19 21:50:36,858 (asr:288) INFO: ilens in custom converter = 30 [500 500 500 500 500 500 500 500 500 500 500 500 500 500 475 475 475 475
 475 475 475 475 475 475 475 475 475 475 475 475]
2020-11-19 21:50:36,860 (nets_utils:52) INFO: padded = torch.Size([30, 500, 63]) 
2020-11-19 21:50:36,862 (nets_utils:52) INFO: padded = torch.Size([30, 28]) 
2020-11-19 21:50:36,865 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,
        475, 475, 475, 475, 475, 475, 475, 475, 475, 475, 475, 475, 475, 475,
        475, 475], device='cuda:0') tensor([500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,
        475, 475, 475, 475, 475, 475, 475, 475, 475, 475, 475, 475, 475, 475,
        475, 475], device='cuda:0')
2020-11-19 21:50:36,928 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125,
        119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119,
        119, 119])
2020-11-19 21:50:36,931 (ctc:92) INFO: CTC input lengths:  tensor([125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125,        119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119,        119, 119], dtype=torch.int32)
2020-11-19 21:50:36,931 (ctc:97) INFO: CTC output lengths: tensor([17, 12, 21, 20,  7, 17,  7, 11, 28, 15, 11, 13, 20, 27, 21,  9, 15,  9,        10, 13, 20, 22,  9, 17, 20, 24, 13,  9, 17,  9], dtype=torch.int32)
2020-11-19 21:50:36,933 (ctc:119) INFO: ctc loss:48.501338958740234
2020-11-19 21:50:37,054 (e2e_asr:56) INFO: mtl loss:48.501338958740234
2020-11-19 21:50:37,148 (asr:234) INFO: grad norm=89.86442114805101
2020-11-19 21:50:37,158 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (475, 63)
2020-11-19 21:50:37,158 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (475, 63)
2020-11-19 21:50:37,158 (asr:288) INFO: ilens in custom converter = 30 [475 450 450 450 450 450 450 450 450 450 450 450 450 450 450 450 450 450
 450 450 450 450 450 450 450 425 425 425 425 425]
2020-11-19 21:50:37,160 (nets_utils:52) INFO: padded = torch.Size([30, 475, 63]) 
2020-11-19 21:50:37,162 (nets_utils:52) INFO: padded = torch.Size([30, 23]) 
2020-11-19 21:50:37,165 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([475, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450,
        450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 425, 425, 425,
        425, 425], device='cuda:0') tensor([475, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450,
        450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 425, 425, 425,
        425, 425], device='cuda:0')
2020-11-19 21:50:37,224 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([119, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113,
        113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 107, 107, 107,
        107, 107])
2020-11-19 21:50:37,227 (ctc:92) INFO: CTC input lengths:  tensor([119, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113,        113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 107, 107, 107,        107, 107], dtype=torch.int32)
2020-11-19 21:50:37,228 (ctc:97) INFO: CTC output lengths: tensor([21, 13, 22, 21, 22,  9, 22, 22, 10, 22, 20, 22, 21, 22, 11, 20, 16, 22,        15, 17, 22, 22, 10, 20,  7, 13, 23, 21,  9, 22], dtype=torch.int32)
2020-11-19 21:50:37,229 (ctc:119) INFO: ctc loss:51.0994987487793
2020-11-19 21:50:37,345 (e2e_asr:56) INFO: mtl loss:51.0994987487793
2020-11-19 21:50:37,438 (asr:234) INFO: grad norm=57.55834579711855
2020-11-19 21:50:37,447 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (975, 63)
2020-11-19 21:50:37,448 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (975, 63)
2020-11-19 21:50:37,448 (asr:288) INFO: ilens in custom converter = 15 [975 950 950 950 950 950 950 950 950 950 950 950 950 950 925]
2020-11-19 21:50:37,450 (nets_utils:52) INFO: padded = torch.Size([15, 975, 63]) 
2020-11-19 21:50:37,452 (nets_utils:52) INFO: padded = torch.Size([15, 51]) 
2020-11-19 21:50:37,454 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([975, 950, 950, 950, 950, 950, 950, 950, 950, 950, 950, 950, 950, 950,
        925], device='cuda:0') tensor([975, 950, 950, 950, 950, 950, 950, 950, 950, 950, 950, 950, 950, 950,
        925], device='cuda:0')
2020-11-19 21:50:37,555 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([244, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238,
        232])
2020-11-19 21:50:37,557 (ctc:92) INFO: CTC input lengths:  tensor([244, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238,        232], dtype=torch.int32)
2020-11-19 21:50:37,557 (ctc:97) INFO: CTC output lengths: tensor([46, 15, 50, 30, 51, 20, 25, 19, 47, 32, 17, 47, 19, 18, 49],       dtype=torch.int32)
2020-11-19 21:50:37,561 (ctc:119) INFO: ctc loss:105.09243774414062
2020-11-19 21:50:37,679 (e2e_asr:56) INFO: mtl loss:105.09243774414062
2020-11-19 21:50:37,821 (asr:234) INFO: grad norm=211.81006046397457
2020-11-19 21:50:37,830 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1050, 63)
2020-11-19 21:50:37,830 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1050, 63)
2020-11-19 21:50:37,830 (asr:288) INFO: ilens in custom converter = 15 [1050 1050 1050 1050 1050 1050 1050 1050 1050 1050 1050 1050 1050 1050
 1050]
2020-11-19 21:50:37,833 (nets_utils:52) INFO: padded = torch.Size([15, 1050, 63]) 
2020-11-19 21:50:37,834 (nets_utils:52) INFO: padded = torch.Size([15, 50]) 
2020-11-19 21:50:37,836 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050,
        1050, 1050, 1050], device='cuda:0') tensor([1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050,
        1050, 1050, 1050], device='cuda:0')
2020-11-19 21:50:37,948 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([263, 263, 263, 263, 263, 263, 263, 263, 263, 263, 263, 263, 263, 263,
        263])
2020-11-19 21:50:37,949 (ctc:92) INFO: CTC input lengths:  tensor([263, 263, 263, 263, 263, 263, 263, 263, 263, 263, 263, 263, 263, 263,        263], dtype=torch.int32)
2020-11-19 21:50:37,950 (ctc:97) INFO: CTC output lengths: tensor([21, 17, 31, 19, 11, 50, 21, 19, 29, 24, 34, 15, 26, 21, 50],       dtype=torch.int32)
2020-11-19 21:50:37,953 (ctc:119) INFO: ctc loss:86.56629180908203
2020-11-19 21:50:38,077 (e2e_asr:56) INFO: mtl loss:86.56629180908203
2020-11-19 21:50:38,221 (asr:234) INFO: grad norm=292.0708382471706
2020-11-19 21:50:38,231 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1300, 63)
2020-11-19 21:50:38,231 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1300, 63)
2020-11-19 21:50:38,231 (asr:288) INFO: ilens in custom converter = 15 [1300 1300 1275 1275 1275 1275 1250 1250 1250 1225 1225 1200 1200 1200
 1200]
2020-11-19 21:50:38,234 (nets_utils:52) INFO: padded = torch.Size([15, 1300, 63]) 
2020-11-19 21:50:38,236 (nets_utils:52) INFO: padded = torch.Size([15, 55]) 
2020-11-19 21:50:38,239 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1300, 1300, 1275, 1275, 1275, 1275, 1250, 1250, 1250, 1225, 1225, 1200,
        1200, 1200, 1200], device='cuda:0') tensor([1300, 1300, 1275, 1275, 1275, 1275, 1250, 1250, 1250, 1225, 1225, 1200,
        1200, 1200, 1200], device='cuda:0')
2020-11-19 21:50:38,372 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([325, 325, 319, 319, 319, 319, 313, 313, 313, 307, 307, 300, 300, 300,
        300])
2020-11-19 21:50:38,374 (ctc:92) INFO: CTC input lengths:  tensor([325, 325, 319, 319, 319, 319, 313, 313, 313, 307, 307, 300, 300, 300,        300], dtype=torch.int32)
2020-11-19 21:50:38,374 (ctc:97) INFO: CTC output lengths: tensor([17, 17, 19, 35, 19, 29, 15, 15, 34, 30, 33, 55, 48, 15, 17],       dtype=torch.int32)
2020-11-19 21:50:38,379 (ctc:119) INFO: ctc loss:77.72622680664062
2020-11-19 21:50:38,531 (e2e_asr:56) INFO: mtl loss:77.72622680664062
2020-11-19 21:50:38,722 (asr:234) INFO: grad norm=101.62074592436852
2020-11-19 21:50:38,732 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1000, 63)
2020-11-19 21:50:38,732 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1000, 63)
2020-11-19 21:50:38,732 (asr:288) INFO: ilens in custom converter = 15 [1000  975  975  975  975  975  975  975  975  975  975  975  975  975
  975]
2020-11-19 21:50:38,735 (nets_utils:52) INFO: padded = torch.Size([15, 1000, 63]) 
2020-11-19 21:50:38,736 (nets_utils:52) INFO: padded = torch.Size([15, 46]) 
2020-11-19 21:50:38,738 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1000,  975,  975,  975,  975,  975,  975,  975,  975,  975,  975,  975,
         975,  975,  975], device='cuda:0') tensor([1000,  975,  975,  975,  975,  975,  975,  975,  975,  975,  975,  975,
         975,  975,  975], device='cuda:0')
2020-11-19 21:50:38,843 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([250, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244,
        244])
2020-11-19 21:50:38,845 (ctc:92) INFO: CTC input lengths:  tensor([250, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244,        244], dtype=torch.int32)
2020-11-19 21:50:38,845 (ctc:97) INFO: CTC output lengths: tensor([19, 46, 15, 30, 22, 24, 19, 21, 15, 32, 33, 34, 24, 20, 19],       dtype=torch.int32)
2020-11-19 21:50:38,848 (ctc:119) INFO: ctc loss:80.25343322753906
2020-11-19 21:50:38,967 (e2e_asr:56) INFO: mtl loss:80.25343322753906
2020-11-19 21:50:39,109 (asr:234) INFO: grad norm=259.64133197220076
2020-11-19 21:50:39,119 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (425, 63)
2020-11-19 21:50:39,119 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (425, 63)
2020-11-19 21:50:39,119 (asr:288) INFO: ilens in custom converter = 30 [425 425 425 425 425 425 425 425 425 425 425 425 425 425 425 425 425 425
 425 400 400 400 400 400 400 400 400 400 400 400]
2020-11-19 21:50:39,121 (nets_utils:52) INFO: padded = torch.Size([30, 425, 63]) 
2020-11-19 21:50:39,123 (nets_utils:52) INFO: padded = torch.Size([30, 24]) 
2020-11-19 21:50:39,126 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([425, 425, 425, 425, 425, 425, 425, 425, 425, 425, 425, 425, 425, 425,
        425, 425, 425, 425, 425, 400, 400, 400, 400, 400, 400, 400, 400, 400,
        400, 400], device='cuda:0') tensor([425, 425, 425, 425, 425, 425, 425, 425, 425, 425, 425, 425, 425, 425,
        425, 425, 425, 425, 425, 400, 400, 400, 400, 400, 400, 400, 400, 400,
        400, 400], device='cuda:0')
2020-11-19 21:50:39,178 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
        107, 107, 107, 107, 107, 100, 100, 100, 100, 100, 100, 100, 100, 100,
        100, 100])
2020-11-19 21:50:39,181 (ctc:92) INFO: CTC input lengths:  tensor([107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,        107, 107, 107, 107, 107, 100, 100, 100, 100, 100, 100, 100, 100, 100,        100, 100], dtype=torch.int32)
2020-11-19 21:50:39,182 (ctc:97) INFO: CTC output lengths: tensor([16, 17, 15, 21, 19, 22, 22, 18, 22,  7, 22, 20,  5, 19, 14, 15, 10, 19,        19,  9, 20,  2, 15,  9, 17, 15, 17, 11, 24,  9], dtype=torch.int32)
2020-11-19 21:50:39,183 (ctc:119) INFO: ctc loss:49.92855453491211
2020-11-19 21:50:39,287 (e2e_asr:56) INFO: mtl loss:49.92855453491211
2020-11-19 21:50:39,369 (asr:234) INFO: grad norm=92.785472545026
2020-11-19 21:50:39,378 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (325, 63)
2020-11-19 21:50:39,378 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (325, 63)
2020-11-19 21:50:39,378 (asr:288) INFO: ilens in custom converter = 30 [325 300 300 300 300 300 300 300 300 275 275 275 275 275 275 275 275 275
 275 275 275 275 275 275 250 250 250 250 250 250]
2020-11-19 21:50:39,380 (nets_utils:52) INFO: padded = torch.Size([30, 325, 63]) 
2020-11-19 21:50:39,381 (nets_utils:52) INFO: padded = torch.Size([30, 12]) 
2020-11-19 21:50:39,384 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([325, 300, 300, 300, 300, 300, 300, 300, 300, 275, 275, 275, 275, 275,
        275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 250, 250, 250, 250,
        250, 250], device='cuda:0') tensor([325, 300, 300, 300, 300, 300, 300, 300, 300, 275, 275, 275, 275, 275,
        275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 250, 250, 250, 250,
        250, 250], device='cuda:0')
2020-11-19 21:50:39,424 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([82, 75, 75, 75, 75, 75, 75, 75, 75, 69, 69, 69, 69, 69, 69, 69, 69, 69,
        69, 69, 69, 69, 69, 69, 63, 63, 63, 63, 63, 63])
2020-11-19 21:50:39,427 (ctc:92) INFO: CTC input lengths:  tensor([82, 75, 75, 75, 75, 75, 75, 75, 75, 69, 69, 69, 69, 69, 69, 69, 69, 69,        69, 69, 69, 69, 69, 69, 63, 63, 63, 63, 63, 63], dtype=torch.int32)
2020-11-19 21:50:39,428 (ctc:97) INFO: CTC output lengths: tensor([ 9,  4,  5,  3,  5, 10,  4, 12,  6, 12,  6,  4, 10,  3,  7,  4,  6,  4,         5,  6,  6,  5,  3,  9,  3,  4,  6,  4,  3,  6], dtype=torch.int32)
2020-11-19 21:50:39,429 (ctc:119) INFO: ctc loss:25.05417251586914
2020-11-19 21:50:39,506 (e2e_asr:56) INFO: mtl loss:25.05417251586914
2020-11-19 21:50:39,572 (asr:234) INFO: grad norm=91.68625350439811
2020-11-19 21:50:39,582 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (600, 63)
2020-11-19 21:50:39,582 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (600, 63)
2020-11-19 21:50:39,582 (asr:288) INFO: ilens in custom converter = 30 [600 600 600 600 600 600 600 600 575 575 575 575 575 575 575 575 575 575
 575 575 575 575 575 575 575 575 575 575 575 575]
2020-11-19 21:50:39,585 (nets_utils:52) INFO: padded = torch.Size([30, 600, 63]) 
2020-11-19 21:50:39,587 (nets_utils:52) INFO: padded = torch.Size([30, 29]) 
2020-11-19 21:50:39,590 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([600, 600, 600, 600, 600, 600, 600, 600, 575, 575, 575, 575, 575, 575,
        575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575,
        575, 575], device='cuda:0') tensor([600, 600, 600, 600, 600, 600, 600, 600, 575, 575, 575, 575, 575, 575,
        575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575,
        575, 575], device='cuda:0')
2020-11-19 21:50:39,666 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([150, 150, 150, 150, 150, 150, 150, 150, 144, 144, 144, 144, 144, 144,
        144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
        144, 144])
2020-11-19 21:50:39,669 (ctc:92) INFO: CTC input lengths:  tensor([150, 150, 150, 150, 150, 150, 150, 150, 144, 144, 144, 144, 144, 144,        144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,        144, 144], dtype=torch.int32)
2020-11-19 21:50:39,669 (ctc:97) INFO: CTC output lengths: tensor([ 9, 22, 13,  9, 26,  9, 25, 17, 22, 22, 19, 21, 22, 29, 28, 22, 17, 11,        22, 23, 15, 27, 23, 24, 29, 19, 17, 22, 13, 11], dtype=torch.int32)
2020-11-19 21:50:39,671 (ctc:119) INFO: ctc loss:60.37299346923828
2020-11-19 21:50:39,815 (e2e_asr:56) INFO: mtl loss:60.37299346923828
2020-11-19 21:50:39,928 (asr:234) INFO: grad norm=107.17792111464844
2020-11-19 21:50:39,937 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (825, 63)
2020-11-19 21:50:39,937 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (825, 63)
2020-11-19 21:50:39,937 (asr:288) INFO: ilens in custom converter = 15 [825 825 825 825 825 825 825 825 825 825 825 825 825 825 825]
2020-11-19 21:50:39,940 (nets_utils:52) INFO: padded = torch.Size([15, 825, 63]) 
2020-11-19 21:50:39,941 (nets_utils:52) INFO: padded = torch.Size([15, 45]) 
2020-11-19 21:50:39,943 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([825, 825, 825, 825, 825, 825, 825, 825, 825, 825, 825, 825, 825, 825,
        825], device='cuda:0') tensor([825, 825, 825, 825, 825, 825, 825, 825, 825, 825, 825, 825, 825, 825,
        825], device='cuda:0')
2020-11-19 21:50:40,033 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207,
        207])
2020-11-19 21:50:40,035 (ctc:92) INFO: CTC input lengths:  tensor([207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207,        207], dtype=torch.int32)
2020-11-19 21:50:40,035 (ctc:97) INFO: CTC output lengths: tensor([17, 45, 30, 18, 32, 38, 36, 44, 23, 19, 11, 32, 19, 21, 42],       dtype=torch.int32)
2020-11-19 21:50:40,038 (ctc:119) INFO: ctc loss:85.64214324951172
2020-11-19 21:50:40,138 (e2e_asr:56) INFO: mtl loss:85.64214324951172
2020-11-19 21:50:40,254 (asr:234) INFO: grad norm=144.7665124806423
2020-11-19 21:50:40,264 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1025, 63)
2020-11-19 21:50:40,264 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1025, 63)
2020-11-19 21:50:40,264 (asr:288) INFO: ilens in custom converter = 15 [1025 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000
 1000]
2020-11-19 21:50:40,267 (nets_utils:52) INFO: padded = torch.Size([15, 1025, 63]) 
2020-11-19 21:50:40,268 (nets_utils:52) INFO: padded = torch.Size([15, 51]) 
2020-11-19 21:50:40,270 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1025, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,
        1000, 1000, 1000], device='cuda:0') tensor([1025, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,
        1000, 1000, 1000], device='cuda:0')
2020-11-19 21:50:40,379 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([257, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250,
        250])
2020-11-19 21:50:40,381 (ctc:92) INFO: CTC input lengths:  tensor([257, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250,        250], dtype=torch.int32)
2020-11-19 21:50:40,381 (ctc:97) INFO: CTC output lengths: tensor([51, 19, 29, 28, 35, 21, 19, 47, 33, 24, 19, 32, 27, 19, 26],       dtype=torch.int32)
2020-11-19 21:50:40,385 (ctc:119) INFO: ctc loss:88.28736877441406
2020-11-19 21:50:40,507 (e2e_asr:56) INFO: mtl loss:88.28736877441406
2020-11-19 21:50:40,653 (asr:234) INFO: grad norm=143.87474453972095
2020-11-19 21:50:40,662 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (400, 63)
2020-11-19 21:50:40,662 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (400, 63)
2020-11-19 21:50:40,663 (asr:288) INFO: ilens in custom converter = 30 [400 400 400 400 400 400 400 400 375 375 375 375 375 375 375 375 375 375
 375 375 375 375 375 375 375 375 375 350 350 350]
2020-11-19 21:50:40,665 (nets_utils:52) INFO: padded = torch.Size([30, 400, 63]) 
2020-11-19 21:50:40,666 (nets_utils:52) INFO: padded = torch.Size([30, 22]) 
2020-11-19 21:50:40,669 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([400, 400, 400, 400, 400, 400, 400, 400, 375, 375, 375, 375, 375, 375,
        375, 375, 375, 375, 375, 375, 375, 375, 375, 375, 375, 375, 375, 350,
        350, 350], device='cuda:0') tensor([400, 400, 400, 400, 400, 400, 400, 400, 375, 375, 375, 375, 375, 375,
        375, 375, 375, 375, 375, 375, 375, 375, 375, 375, 375, 375, 375, 350,
        350, 350], device='cuda:0')
2020-11-19 21:50:40,720 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([100, 100, 100, 100, 100, 100, 100, 100,  94,  94,  94,  94,  94,  94,
         94,  94,  94,  94,  94,  94,  94,  94,  94,  94,  94,  94,  94,  88,
         88,  88])
2020-11-19 21:50:40,723 (ctc:92) INFO: CTC input lengths:  tensor([100, 100, 100, 100, 100, 100, 100, 100,  94,  94,  94,  94,  94,  94,         94,  94,  94,  94,  94,  94,  94,  94,  94,  94,  94,  94,  94,  88,         88,  88], dtype=torch.int32)
2020-11-19 21:50:40,723 (ctc:97) INFO: CTC output lengths: tensor([ 7, 18, 18,  9, 20, 22, 20,  7,  7, 13, 14, 12, 11,  7, 16,  7, 19, 17,        11,  7, 10,  9, 18, 16,  9, 13, 16, 13, 11, 17], dtype=torch.int32)
2020-11-19 21:50:40,725 (ctc:119) INFO: ctc loss:40.43242645263672
2020-11-19 21:50:40,822 (e2e_asr:56) INFO: mtl loss:40.43242645263672
2020-11-19 21:50:40,902 (asr:234) INFO: grad norm=74.42131753620227
2020-11-19 21:50:40,912 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1575, 63)
2020-11-19 21:50:40,912 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1575, 63)
2020-11-19 21:50:40,912 (asr:288) INFO: ilens in custom converter = 15 [1575 1575 1575 1575 1550 1550 1525 1525 1525 1525 1500 1500 1500 1475
 1450]
2020-11-19 21:50:40,918 (nets_utils:52) INFO: padded = torch.Size([15, 1575, 63]) 
2020-11-19 21:50:40,920 (nets_utils:52) INFO: padded = torch.Size([15, 57]) 
2020-11-19 21:50:40,922 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1575, 1575, 1575, 1575, 1550, 1550, 1525, 1525, 1525, 1525, 1500, 1500,
        1500, 1475, 1450], device='cuda:0') tensor([1575, 1575, 1575, 1575, 1550, 1550, 1525, 1525, 1525, 1525, 1500, 1500,
        1500, 1475, 1450], device='cuda:0')
2020-11-19 21:50:41,086 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([394, 394, 394, 394, 388, 388, 382, 382, 382, 382, 375, 375, 375, 369,
        363])
2020-11-19 21:50:41,088 (ctc:92) INFO: CTC input lengths:  tensor([394, 394, 394, 394, 388, 388, 382, 382, 382, 382, 375, 375, 375, 369,        363], dtype=torch.int32)
2020-11-19 21:50:41,088 (ctc:97) INFO: CTC output lengths: tensor([30, 15, 19, 49, 29, 42, 19, 57, 19, 23, 34, 29, 19, 44, 44],       dtype=torch.int32)
2020-11-19 21:50:41,094 (ctc:119) INFO: ctc loss:90.14978790283203
2020-11-19 21:50:41,276 (e2e_asr:56) INFO: mtl loss:90.14978790283203
2020-11-19 21:50:41,513 (asr:234) INFO: grad norm=82.2714328764845
2020-11-19 21:50:41,522 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1125, 63)
2020-11-19 21:50:41,523 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1125, 63)
2020-11-19 21:50:41,523 (asr:288) INFO: ilens in custom converter = 15 [1125 1125 1100 1100 1100 1100 1100 1100 1100 1100 1100 1100 1075 1075
 1075]
2020-11-19 21:50:41,526 (nets_utils:52) INFO: padded = torch.Size([15, 1125, 63]) 
2020-11-19 21:50:41,527 (nets_utils:52) INFO: padded = torch.Size([15, 52]) 
2020-11-19 21:50:41,529 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1125, 1125, 1100, 1100, 1100, 1100, 1100, 1100, 1100, 1100, 1100, 1100,
        1075, 1075, 1075], device='cuda:0') tensor([1125, 1125, 1100, 1100, 1100, 1100, 1100, 1100, 1100, 1100, 1100, 1100,
        1075, 1075, 1075], device='cuda:0')
2020-11-19 21:50:41,648 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([282, 282, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 269, 269,
        269])
2020-11-19 21:50:41,650 (ctc:92) INFO: CTC input lengths:  tensor([282, 282, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 269, 269,        269], dtype=torch.int32)
2020-11-19 21:50:41,650 (ctc:97) INFO: CTC output lengths: tensor([19, 19, 36, 21, 15, 17, 41, 23,  9, 17, 52, 25, 29, 13, 34],       dtype=torch.int32)
2020-11-19 21:50:41,654 (ctc:119) INFO: ctc loss:81.55950164794922
2020-11-19 21:50:41,787 (e2e_asr:56) INFO: mtl loss:81.55950164794922
2020-11-19 21:50:41,949 (asr:234) INFO: grad norm=289.76768093675895
2020-11-19 21:50:41,959 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1450, 63)
2020-11-19 21:50:41,959 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1450, 63)
2020-11-19 21:50:41,959 (asr:288) INFO: ilens in custom converter = 15 [1450 1450 1425 1425 1400 1375 1375 1375 1375 1375 1350 1350 1350 1325
 1300]
2020-11-19 21:50:41,963 (nets_utils:52) INFO: padded = torch.Size([15, 1450, 63]) 
2020-11-19 21:50:41,965 (nets_utils:52) INFO: padded = torch.Size([15, 47]) 
2020-11-19 21:50:41,967 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1450, 1450, 1425, 1425, 1400, 1375, 1375, 1375, 1375, 1375, 1350, 1350,
        1350, 1325, 1300], device='cuda:0') tensor([1450, 1450, 1425, 1425, 1400, 1375, 1375, 1375, 1375, 1375, 1350, 1350,
        1350, 1325, 1300], device='cuda:0')
2020-11-19 21:50:42,116 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([363, 363, 357, 357, 350, 344, 344, 344, 344, 344, 338, 338, 338, 332,
        325])
2020-11-19 21:50:42,118 (ctc:92) INFO: CTC input lengths:  tensor([363, 363, 357, 357, 350, 344, 344, 344, 344, 344, 338, 338, 338, 332,        325], dtype=torch.int32)
2020-11-19 21:50:42,118 (ctc:97) INFO: CTC output lengths: tensor([37, 25, 19, 34, 17, 21, 36, 23, 19, 32, 47, 23, 19, 21, 19],       dtype=torch.int32)
2020-11-19 21:50:42,123 (ctc:119) INFO: ctc loss:71.12372589111328
2020-11-19 21:50:42,289 (e2e_asr:56) INFO: mtl loss:71.12372589111328
2020-11-19 21:50:42,508 (asr:234) INFO: grad norm=67.95643309754628
2020-11-19 21:50:42,519 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (750, 63)
2020-11-19 21:50:42,520 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (750, 63)
2020-11-19 21:50:42,520 (asr:288) INFO: ilens in custom converter = 30 [750 750 750 750 750 750 750 725 725 725 725 725 725 725 725 725 725 725
 725 725 725 725 725 725 725 725 725 725 725 725]
2020-11-19 21:50:42,524 (nets_utils:52) INFO: padded = torch.Size([30, 750, 63]) 
2020-11-19 21:50:42,526 (nets_utils:52) INFO: padded = torch.Size([30, 45]) 
2020-11-19 21:50:42,529 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([750, 750, 750, 750, 750, 750, 750, 725, 725, 725, 725, 725, 725, 725,
        725, 725, 725, 725, 725, 725, 725, 725, 725, 725, 725, 725, 725, 725,
        725, 725], device='cuda:0') tensor([750, 750, 750, 750, 750, 750, 750, 725, 725, 725, 725, 725, 725, 725,
        725, 725, 725, 725, 725, 725, 725, 725, 725, 725, 725, 725, 725, 725,
        725, 725], device='cuda:0')
2020-11-19 21:50:42,622 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([188, 188, 188, 188, 188, 188, 188, 182, 182, 182, 182, 182, 182, 182,
        182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182,
        182, 182])
2020-11-19 21:50:42,625 (ctc:92) INFO: CTC input lengths:  tensor([188, 188, 188, 188, 188, 188, 188, 182, 182, 182, 182, 182, 182, 182,        182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182,        182, 182], dtype=torch.int32)
2020-11-19 21:50:42,625 (ctc:97) INFO: CTC output lengths: tensor([21, 19, 23, 17, 25, 26, 33,  9, 33, 17, 11, 19, 26, 11, 34,  9, 29, 29,        15, 17, 34, 21, 45, 32, 11, 31, 13, 13,  9, 22], dtype=torch.int32)
2020-11-19 21:50:42,628 (ctc:119) INFO: ctc loss:67.95790100097656
2020-11-19 21:50:42,810 (e2e_asr:56) INFO: mtl loss:67.95790100097656
2020-11-19 21:50:42,950 (asr:234) INFO: grad norm=144.93156952426972
2020-11-19 21:50:42,959 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1200, 63)
2020-11-19 21:50:42,959 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1200, 63)
2020-11-19 21:50:42,959 (asr:288) INFO: ilens in custom converter = 15 [1200 1200 1200 1175 1175 1175 1175 1175 1175 1150 1150 1150 1150 1150
 1125]
2020-11-19 21:50:42,962 (nets_utils:52) INFO: padded = torch.Size([15, 1200, 63]) 
2020-11-19 21:50:42,964 (nets_utils:52) INFO: padded = torch.Size([15, 46]) 
2020-11-19 21:50:42,966 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1200, 1200, 1200, 1175, 1175, 1175, 1175, 1175, 1175, 1150, 1150, 1150,
        1150, 1150, 1125], device='cuda:0') tensor([1200, 1200, 1200, 1175, 1175, 1175, 1175, 1175, 1175, 1150, 1150, 1150,
        1150, 1150, 1125], device='cuda:0')
2020-11-19 21:50:43,093 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([300, 300, 300, 294, 294, 294, 294, 294, 294, 288, 288, 288, 288, 288,
        282])
2020-11-19 21:50:43,095 (ctc:92) INFO: CTC input lengths:  tensor([300, 300, 300, 294, 294, 294, 294, 294, 294, 288, 288, 288, 288, 288,        282], dtype=torch.int32)
2020-11-19 21:50:43,095 (ctc:97) INFO: CTC output lengths: tensor([35, 19, 46, 17, 17,  9, 11, 25, 17, 28, 13, 28, 33, 27, 19],       dtype=torch.int32)
2020-11-19 21:50:43,099 (ctc:119) INFO: ctc loss:64.88436126708984
2020-11-19 21:50:43,237 (e2e_asr:56) INFO: mtl loss:64.88436126708984
2020-11-19 21:50:43,412 (asr:234) INFO: grad norm=50.925295605391504
2020-11-19 21:50:43,424 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (775, 63)
2020-11-19 21:50:43,424 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (775, 63)
2020-11-19 21:50:43,424 (asr:288) INFO: ilens in custom converter = 30 [775 775 775 775 775 775 775 775 775 775 775 775 775 775 775 775 775 775
 775 775 775 775 775 775 775 750 750 750 750 750]
2020-11-19 21:50:43,428 (nets_utils:52) INFO: padded = torch.Size([30, 775, 63]) 
2020-11-19 21:50:43,430 (nets_utils:52) INFO: padded = torch.Size([30, 39]) 
2020-11-19 21:50:43,433 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775,
        775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 750, 750, 750,
        750, 750], device='cuda:0') tensor([775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775,
        775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 750, 750, 750,
        750, 750], device='cuda:0')
2020-11-19 21:50:43,533 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194,
        194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 188, 188, 188,
        188, 188])
2020-11-19 21:50:43,536 (ctc:92) INFO: CTC input lengths:  tensor([194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194,        194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 188, 188, 188,        188, 188], dtype=torch.int32)
2020-11-19 21:50:43,537 (ctc:97) INFO: CTC output lengths: tensor([26, 19, 11, 11, 13, 23, 15, 13,  5, 13, 25, 13,  9, 17, 25, 33, 25, 11,        22, 13, 28, 24, 15, 25, 15, 15, 28, 16, 39, 26], dtype=torch.int32)
2020-11-19 21:50:43,539 (ctc:119) INFO: ctc loss:60.92679977416992
2020-11-19 21:50:43,723 (e2e_asr:56) INFO: mtl loss:60.92679977416992
2020-11-19 21:50:43,869 (asr:234) INFO: grad norm=171.38021194022775
2020-11-19 21:50:43,876 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 8 (200, 63)
2020-11-19 21:50:43,876 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 8 (200, 63)
2020-11-19 21:50:43,876 (asr:288) INFO: ilens in custom converter = 8 [200 200 200 200 200 200 200 175]
2020-11-19 21:50:43,877 (nets_utils:52) INFO: padded = torch.Size([8, 200, 63]) 
2020-11-19 21:50:43,877 (nets_utils:52) INFO: padded = torch.Size([8, 4]) 
2020-11-19 21:50:43,878 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([8]) torch.Size([8]) hlens,ilens=tensor([200, 200, 200, 200, 200, 200, 200, 175], device='cuda:0') tensor([200, 200, 200, 200, 200, 200, 200, 175], device='cuda:0')
2020-11-19 21:50:43,896 (e2e_asr:368) INFO: encoder ilens=torch.Size([8]) tensor([50, 50, 50, 50, 50, 50, 50, 44])
2020-11-19 21:50:43,897 (ctc:92) INFO: CTC input lengths:  tensor([50, 50, 50, 50, 50, 50, 50, 44], dtype=torch.int32)
2020-11-19 21:50:43,897 (ctc:97) INFO: CTC output lengths: tensor([2, 2, 4, 2, 3, 3, 4, 4], dtype=torch.int32)
2020-11-19 21:50:43,898 (ctc:119) INFO: ctc loss:11.474401473999023
2020-11-19 21:50:43,910 (e2e_asr:56) INFO: mtl loss:11.474401473999023
2020-11-19 21:50:43,937 (asr:234) INFO: grad norm=13.408264483358058
2020-11-19 21:50:43,947 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (625, 63)
2020-11-19 21:50:43,947 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (625, 63)
2020-11-19 21:50:43,947 (asr:288) INFO: ilens in custom converter = 30 [625 625 625 625 625 625 625 625 625 625 625 625 625 625 625 625 625 625
 625 625 625 625 625 625 625 625 625 625 625 625]
2020-11-19 21:50:43,951 (nets_utils:52) INFO: padded = torch.Size([30, 625, 63]) 
2020-11-19 21:50:43,953 (nets_utils:52) INFO: padded = torch.Size([30, 40]) 
2020-11-19 21:50:43,956 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625,
        625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625,
        625, 625], device='cuda:0') tensor([625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625,
        625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625,
        625, 625], device='cuda:0')
2020-11-19 21:50:44,036 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
        157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
        157, 157])
2020-11-19 21:50:44,039 (ctc:92) INFO: CTC input lengths:  tensor([157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,        157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,        157, 157], dtype=torch.int32)
2020-11-19 21:50:44,039 (ctc:97) INFO: CTC output lengths: tensor([20,  9, 29, 24, 11,  9, 30, 11,  9, 19, 24, 14, 11, 13,  7, 35,  9, 11,        17, 13,  5, 40, 32, 39, 21, 23, 25, 11, 20, 13], dtype=torch.int32)
2020-11-19 21:50:44,042 (ctc:119) INFO: ctc loss:69.59580993652344
2020-11-19 21:50:44,194 (e2e_asr:56) INFO: mtl loss:69.59580993652344
2020-11-19 21:50:44,311 (asr:234) INFO: grad norm=152.97328218638788
2020-11-19 21:50:44,320 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1075, 63)
2020-11-19 21:50:44,320 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1075, 63)
2020-11-19 21:50:44,320 (asr:288) INFO: ilens in custom converter = 15 [1075 1075 1075 1075 1075 1075 1075 1075 1075 1075 1075 1075 1050 1050
 1050]
2020-11-19 21:50:44,323 (nets_utils:52) INFO: padded = torch.Size([15, 1075, 63]) 
2020-11-19 21:50:44,325 (nets_utils:52) INFO: padded = torch.Size([15, 34]) 
2020-11-19 21:50:44,327 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075,
        1050, 1050, 1050], device='cuda:0') tensor([1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075,
        1050, 1050, 1050], device='cuda:0')
2020-11-19 21:50:44,439 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([269, 269, 269, 269, 269, 269, 269, 269, 269, 269, 269, 269, 263, 263,
        263])
2020-11-19 21:50:44,440 (ctc:92) INFO: CTC input lengths:  tensor([269, 269, 269, 269, 269, 269, 269, 269, 269, 269, 269, 269, 263, 263,        263], dtype=torch.int32)
2020-11-19 21:50:44,441 (ctc:97) INFO: CTC output lengths: tensor([34, 19, 17, 32, 17, 20, 13, 15, 26, 13, 19, 25, 21, 19, 17],       dtype=torch.int32)
2020-11-19 21:50:44,444 (ctc:119) INFO: ctc loss:65.81363677978516
2020-11-19 21:50:44,565 (e2e_asr:56) INFO: mtl loss:65.81363677978516
2020-11-19 21:50:44,717 (asr:234) INFO: grad norm=165.2018491791692
2020-11-19 21:50:44,728 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (650, 63)
2020-11-19 21:50:44,728 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (650, 63)
2020-11-19 21:50:44,728 (asr:288) INFO: ilens in custom converter = 30 [650 650 650 650 650 650 650 650 650 650 650 650 650 650 650 650 650 650
 650 650 650 650 625 625 625 625 625 625 625 625]
2020-11-19 21:50:44,732 (nets_utils:52) INFO: padded = torch.Size([30, 650, 63]) 
2020-11-19 21:50:44,733 (nets_utils:52) INFO: padded = torch.Size([30, 36]) 
2020-11-19 21:50:44,737 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650,
        650, 650, 650, 650, 650, 650, 650, 650, 625, 625, 625, 625, 625, 625,
        625, 625], device='cuda:0') tensor([650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650,
        650, 650, 650, 650, 650, 650, 650, 650, 625, 625, 625, 625, 625, 625,
        625, 625], device='cuda:0')
2020-11-19 21:50:44,820 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163,
        163, 163, 163, 163, 163, 163, 163, 163, 157, 157, 157, 157, 157, 157,
        157, 157])
2020-11-19 21:50:44,823 (ctc:92) INFO: CTC input lengths:  tensor([163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163,        163, 163, 163, 163, 163, 163, 163, 163, 157, 157, 157, 157, 157, 157,        157, 157], dtype=torch.int32)
2020-11-19 21:50:44,824 (ctc:97) INFO: CTC output lengths: tensor([29, 26, 25, 13, 25, 36, 23, 33, 21, 13,  9, 28, 11, 19, 13,  9, 26, 11,        21, 26,  9, 11, 15, 32, 18, 11, 29, 24, 17, 12], dtype=torch.int32)
2020-11-19 21:50:44,826 (ctc:119) INFO: ctc loss:72.37582397460938
2020-11-19 21:50:44,985 (e2e_asr:56) INFO: mtl loss:72.37582397460938
2020-11-19 21:50:45,106 (asr:234) INFO: grad norm=165.89848604940465
2020-11-19 21:50:45,115 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (875, 63)
2020-11-19 21:50:45,115 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (875, 63)
2020-11-19 21:50:45,115 (asr:288) INFO: ilens in custom converter = 15 [875 875 875 875 875 875 875 875 875 875 875 875 875 875 875]
2020-11-19 21:50:45,118 (nets_utils:52) INFO: padded = torch.Size([15, 875, 63]) 
2020-11-19 21:50:45,119 (nets_utils:52) INFO: padded = torch.Size([15, 48]) 
2020-11-19 21:50:45,121 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([875, 875, 875, 875, 875, 875, 875, 875, 875, 875, 875, 875, 875, 875,
        875], device='cuda:0') tensor([875, 875, 875, 875, 875, 875, 875, 875, 875, 875, 875, 875, 875, 875,
        875], device='cuda:0')
2020-11-19 21:50:45,213 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219,
        219])
2020-11-19 21:50:45,215 (ctc:92) INFO: CTC input lengths:  tensor([219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219,        219], dtype=torch.int32)
2020-11-19 21:50:45,215 (ctc:97) INFO: CTC output lengths: tensor([48, 33, 39, 18, 29, 19, 28, 19, 23, 22, 19, 17, 23, 23, 33],       dtype=torch.int32)
2020-11-19 21:50:45,218 (ctc:119) INFO: ctc loss:74.67554473876953
2020-11-19 21:50:45,324 (e2e_asr:56) INFO: mtl loss:74.67554473876953
2020-11-19 21:50:45,446 (asr:234) INFO: grad norm=14.499112997770691
2020-11-19 21:50:45,456 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (550, 63)
2020-11-19 21:50:45,456 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (550, 63)
2020-11-19 21:50:45,457 (asr:288) INFO: ilens in custom converter = 30 [550 550 550 550 550 550 550 550 550 550 550 550 550 525 525 525 525 525
 525 525 525 525 525 525 525 525 525 525 525 525]
2020-11-19 21:50:45,459 (nets_utils:52) INFO: padded = torch.Size([30, 550, 63]) 
2020-11-19 21:50:45,461 (nets_utils:52) INFO: padded = torch.Size([30, 34]) 
2020-11-19 21:50:45,464 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 525,
        525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525,
        525, 525], device='cuda:0') tensor([550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 525,
        525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525,
        525, 525], device='cuda:0')
2020-11-19 21:50:45,533 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132])
2020-11-19 21:50:45,536 (ctc:92) INFO: CTC input lengths:  tensor([138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 132,        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,        132, 132], dtype=torch.int32)
2020-11-19 21:50:45,537 (ctc:97) INFO: CTC output lengths: tensor([29, 34, 21, 16, 30, 11, 12, 21, 11, 22,  9, 21, 26, 11, 22, 21, 15, 32,        13, 19, 20, 33, 32, 26, 11, 19, 11, 21, 13, 20], dtype=torch.int32)
2020-11-19 21:50:45,539 (ctc:119) INFO: ctc loss:60.39342498779297
2020-11-19 21:50:45,676 (e2e_asr:56) INFO: mtl loss:60.39342498779297
2020-11-19 21:50:45,779 (asr:234) INFO: grad norm=38.97927894077592
2020-11-19 21:50:45,789 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (575, 63)
2020-11-19 21:50:45,789 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (575, 63)
2020-11-19 21:50:45,789 (asr:288) INFO: ilens in custom converter = 30 [575 575 575 550 550 550 550 550 550 550 550 550 550 550 550 550 550 550
 550 550 550 550 550 550 550 550 550 550 550 550]
2020-11-19 21:50:45,792 (nets_utils:52) INFO: padded = torch.Size([30, 575, 63]) 
2020-11-19 21:50:45,794 (nets_utils:52) INFO: padded = torch.Size([30, 35]) 
2020-11-19 21:50:45,797 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([575, 575, 575, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550,
        550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550,
        550, 550], device='cuda:0') tensor([575, 575, 575, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550,
        550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550,
        550, 550], device='cuda:0')
2020-11-19 21:50:45,869 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([144, 144, 144, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
        138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
        138, 138])
2020-11-19 21:50:45,872 (ctc:92) INFO: CTC input lengths:  tensor([144, 144, 144, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,        138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,        138, 138], dtype=torch.int32)
2020-11-19 21:50:45,872 (ctc:97) INFO: CTC output lengths: tensor([17, 19, 20, 33, 22, 30, 21,  7, 19, 10, 11,  9, 19,  9, 20, 14, 29, 23,        11,  9, 11, 11, 22, 14, 12, 11, 29, 15, 35, 35], dtype=torch.int32)
2020-11-19 21:50:45,875 (ctc:119) INFO: ctc loss:62.71987533569336
2020-11-19 21:50:46,015 (e2e_asr:56) INFO: mtl loss:62.71987533569336
2020-11-19 21:50:46,122 (asr:234) INFO: grad norm=188.94327265269175
2020-11-19 21:50:46,132 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (525, 63)
2020-11-19 21:50:46,132 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (525, 63)
2020-11-19 21:50:46,133 (asr:288) INFO: ilens in custom converter = 30 [525 525 525 525 525 525 525 525 525 525 525 525 525 525 525 500 500 500
 500 500 500 500 500 500 500 500 500 500 500 500]
2020-11-19 21:50:46,135 (nets_utils:52) INFO: padded = torch.Size([30, 525, 63]) 
2020-11-19 21:50:46,137 (nets_utils:52) INFO: padded = torch.Size([30, 37]) 
2020-11-19 21:50:46,140 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525,
        525, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,
        500, 500], device='cuda:0') tensor([525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525,
        525, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,
        500, 500], device='cuda:0')
2020-11-19 21:50:46,207 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125,
        125, 125])
2020-11-19 21:50:46,210 (ctc:92) INFO: CTC input lengths:  tensor([132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,        132, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125,        125, 125], dtype=torch.int32)
2020-11-19 21:50:46,210 (ctc:97) INFO: CTC output lengths: tensor([30, 37, 11, 22, 22, 15,  7, 22,  9, 22, 15, 23,  9, 22, 21, 15,  9, 17,        19, 23,  9, 23, 22, 17, 14, 11, 21, 22, 11, 26], dtype=torch.int32)
2020-11-19 21:50:46,212 (ctc:119) INFO: ctc loss:52.97010040283203
2020-11-19 21:50:46,343 (e2e_asr:56) INFO: mtl loss:52.97010040283203
2020-11-19 21:50:46,443 (asr:234) INFO: grad norm=65.94477693952119
2020-11-19 21:50:46,453 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (350, 63)
2020-11-19 21:50:46,453 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (350, 63)
2020-11-19 21:50:46,453 (asr:288) INFO: ilens in custom converter = 30 [350 350 350 350 350 350 350 350 350 350 350 350 350 350 325 325 325 325
 325 325 325 325 325 325 325 325 325 325 325 325]
2020-11-19 21:50:46,455 (nets_utils:52) INFO: padded = torch.Size([30, 350, 63]) 
2020-11-19 21:50:46,456 (nets_utils:52) INFO: padded = torch.Size([30, 18]) 
2020-11-19 21:50:46,458 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350,
        325, 325, 325, 325, 325, 325, 325, 325, 325, 325, 325, 325, 325, 325,
        325, 325], device='cuda:0') tensor([350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350,
        325, 325, 325, 325, 325, 325, 325, 325, 325, 325, 325, 325, 325, 325,
        325, 325], device='cuda:0')
2020-11-19 21:50:46,503 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 82, 82, 82, 82,
        82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82])
2020-11-19 21:50:46,506 (ctc:92) INFO: CTC input lengths:  tensor([88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 82, 82, 82, 82,        82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82], dtype=torch.int32)
2020-11-19 21:50:46,507 (ctc:97) INFO: CTC output lengths: tensor([ 5,  7,  6, 12, 11, 15, 11, 11,  9, 15, 17, 11,  5, 11,  4, 10,  6, 11,         8,  5, 18,  5, 10,  5, 10,  3,  7, 15, 14,  2], dtype=torch.int32)
2020-11-19 21:50:46,508 (ctc:119) INFO: ctc loss:34.912803649902344
2020-11-19 21:50:46,593 (e2e_asr:56) INFO: mtl loss:34.912803649902344
2020-11-19 21:50:46,660 (asr:234) INFO: grad norm=120.73630718024505
2020-11-19 21:50:46,669 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (225, 63)
2020-11-19 21:50:46,669 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (225, 63)
2020-11-19 21:50:46,669 (asr:288) INFO: ilens in custom converter = 30 [225 225 225 225 225 225 225 225 225 225 225 225 225 225 225 225 225 200
 200 200 200 200 200 200 200 200 200 200 200 200]
2020-11-19 21:50:46,670 (nets_utils:52) INFO: padded = torch.Size([30, 225, 63]) 
2020-11-19 21:50:46,671 (nets_utils:52) INFO: padded = torch.Size([30, 6]) 
2020-11-19 21:50:46,674 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225,
        225, 225, 225, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,
        200, 200], device='cuda:0') tensor([225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225,
        225, 225, 225, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,
        200, 200], device='cuda:0')
2020-11-19 21:50:46,703 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 50,
        50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50])
2020-11-19 21:50:46,706 (ctc:92) INFO: CTC input lengths:  tensor([57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 50,        50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50], dtype=torch.int32)
2020-11-19 21:50:46,707 (ctc:97) INFO: CTC output lengths: tensor([4, 6, 6, 4, 4, 4, 3, 4, 2, 2, 4, 4, 3, 6, 6, 5, 2, 2, 2, 2, 2, 2, 2, 2,        4, 4, 6, 2, 2, 4], dtype=torch.int32)
2020-11-19 21:50:46,708 (ctc:119) INFO: ctc loss:13.533174514770508
2020-11-19 21:50:46,760 (e2e_asr:56) INFO: mtl loss:13.533174514770508
2020-11-19 21:50:46,806 (asr:234) INFO: grad norm=24.26473326303643
2020-11-19 21:50:46,817 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (675, 63)
2020-11-19 21:50:46,817 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (675, 63)
2020-11-19 21:50:46,817 (asr:288) INFO: ilens in custom converter = 30 [675 675 675 675 675 675 675 675 675 675 675 675 675 675 675 675 675 675
 675 675 675 675 675 675 675 650 650 650 650 650]
2020-11-19 21:50:46,821 (nets_utils:52) INFO: padded = torch.Size([30, 675, 63]) 
2020-11-19 21:50:46,823 (nets_utils:52) INFO: padded = torch.Size([30, 46]) 
2020-11-19 21:50:46,826 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 675,
        675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 650, 650, 650,
        650, 650], device='cuda:0') tensor([675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 675,
        675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 650, 650, 650,
        650, 650], device='cuda:0')
2020-11-19 21:50:46,910 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169,
        169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 163, 163, 163,
        163, 163])
2020-11-19 21:50:46,913 (ctc:92) INFO: CTC input lengths:  tensor([169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169,        169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 163, 163, 163,        163, 163], dtype=torch.int32)
2020-11-19 21:50:46,913 (ctc:97) INFO: CTC output lengths: tensor([13, 13, 13, 12, 19, 17, 20, 13, 30, 30, 46, 17, 21, 13, 19, 15, 13, 24,        21, 19,  7, 17, 33,  9, 41, 18, 26, 26, 29, 22], dtype=torch.int32)
2020-11-19 21:50:46,916 (ctc:119) INFO: ctc loss:76.05360412597656
2020-11-19 21:50:47,084 (e2e_asr:56) INFO: mtl loss:76.05360412597656
2020-11-19 21:50:47,212 (asr:234) INFO: grad norm=179.2187900395431
2020-11-19 21:50:47,223 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (725, 63)
2020-11-19 21:50:47,223 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (725, 63)
2020-11-19 21:50:47,223 (asr:288) INFO: ilens in custom converter = 30 [725 725 725 725 725 725 725 725 725 725 700 700 700 700 700 700 700 700
 700 700 700 700 700 700 700 700 700 700 675 675]
2020-11-19 21:50:47,227 (nets_utils:52) INFO: padded = torch.Size([30, 725, 63]) 
2020-11-19 21:50:47,229 (nets_utils:52) INFO: padded = torch.Size([30, 39]) 
2020-11-19 21:50:47,232 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([725, 725, 725, 725, 725, 725, 725, 725, 725, 725, 700, 700, 700, 700,
        700, 700, 700, 700, 700, 700, 700, 700, 700, 700, 700, 700, 700, 700,
        675, 675], device='cuda:0') tensor([725, 725, 725, 725, 725, 725, 725, 725, 725, 725, 700, 700, 700, 700,
        700, 700, 700, 700, 700, 700, 700, 700, 700, 700, 700, 700, 700, 700,
        675, 675], device='cuda:0')
2020-11-19 21:50:47,323 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 175, 175, 175, 175,
        175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175,
        169, 169])
2020-11-19 21:50:47,326 (ctc:92) INFO: CTC input lengths:  tensor([182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 175, 175, 175, 175,        175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175,        169, 169], dtype=torch.int32)
2020-11-19 21:50:47,326 (ctc:97) INFO: CTC output lengths: tensor([25, 20, 15, 19, 24, 11, 23, 21, 20, 30, 20, 11,  9, 13, 22, 19, 17, 17,        19, 34, 39, 11, 36, 19, 11, 18, 35, 19,  9, 11], dtype=torch.int32)
2020-11-19 21:50:47,329 (ctc:119) INFO: ctc loss:58.6761360168457
2020-11-19 21:50:47,503 (e2e_asr:56) INFO: mtl loss:58.6761360168457
2020-11-19 21:50:47,643 (asr:234) INFO: grad norm=28.836831207280962
2020-11-19 21:50:47,652 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (900, 63)
2020-11-19 21:50:47,652 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (900, 63)
2020-11-19 21:50:47,652 (asr:288) INFO: ilens in custom converter = 15 [900 900 900 900 900 900 900 900 900 900 900 900 900 875 875]
2020-11-19 21:50:47,655 (nets_utils:52) INFO: padded = torch.Size([15, 900, 63]) 
2020-11-19 21:50:47,656 (nets_utils:52) INFO: padded = torch.Size([15, 34]) 
2020-11-19 21:50:47,658 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([900, 900, 900, 900, 900, 900, 900, 900, 900, 900, 900, 900, 900, 875,
        875], device='cuda:0') tensor([900, 900, 900, 900, 900, 900, 900, 900, 900, 900, 900, 900, 900, 875,
        875], device='cuda:0')
2020-11-19 21:50:47,754 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 219,
        219])
2020-11-19 21:50:47,756 (ctc:92) INFO: CTC input lengths:  tensor([225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 219,        219], dtype=torch.int32)
2020-11-19 21:50:47,756 (ctc:97) INFO: CTC output lengths: tensor([23, 11, 27, 31, 15, 19, 20, 34, 13, 13, 32, 15, 17, 25, 24],       dtype=torch.int32)
2020-11-19 21:50:47,759 (ctc:119) INFO: ctc loss:65.80843353271484
2020-11-19 21:50:47,865 (e2e_asr:56) INFO: mtl loss:65.80843353271484
2020-11-19 21:50:47,995 (asr:234) INFO: grad norm=156.16771711465006
2020-11-19 21:50:48,004 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 10 (1600, 63)
2020-11-19 21:50:48,004 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 10 (1600, 63)
2020-11-19 21:50:48,005 (asr:288) INFO: ilens in custom converter = 10 [1600 1325 1250 1225 1225 1175 1175 1125 1100 1075]
2020-11-19 21:50:48,007 (nets_utils:52) INFO: padded = torch.Size([10, 1600, 63]) 
2020-11-19 21:50:48,008 (nets_utils:52) INFO: padded = torch.Size([10, 46]) 
2020-11-19 21:50:48,010 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([10]) torch.Size([10]) hlens,ilens=tensor([1600, 1325, 1250, 1225, 1225, 1175, 1175, 1125, 1100, 1075],
       device='cuda:0') tensor([1600, 1325, 1250, 1225, 1225, 1175, 1175, 1125, 1100, 1075],
       device='cuda:0')
2020-11-19 21:50:48,147 (e2e_asr:368) INFO: encoder ilens=torch.Size([10]) tensor([400, 332, 313, 307, 307, 294, 294, 282, 275, 269])
2020-11-19 21:50:48,148 (ctc:92) INFO: CTC input lengths:  tensor([400, 332, 313, 307, 307, 294, 294, 282, 275, 269], dtype=torch.int32)
2020-11-19 21:50:48,149 (ctc:97) INFO: CTC output lengths: tensor([40, 23, 21, 19, 46, 25, 27, 19, 17, 34], dtype=torch.int32)
2020-11-19 21:50:48,154 (ctc:119) INFO: ctc loss:78.02473449707031
2020-11-19 21:50:48,275 (e2e_asr:56) INFO: mtl loss:78.02473449707031
2020-11-19 21:50:48,278 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1075, 63)
2020-11-19 21:50:48,278 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1075, 63)
2020-11-19 21:50:48,278 (asr:288) INFO: ilens in custom converter = 15 [1075 1075 1075 1025 1000  950  925  925  900  900  875  875  875  850
  850]
2020-11-19 21:50:48,280 (nets_utils:52) INFO: padded = torch.Size([15, 1075, 63]) 
2020-11-19 21:50:48,282 (nets_utils:52) INFO: padded = torch.Size([15, 39]) 
2020-11-19 21:50:48,284 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1075, 1075, 1075, 1025, 1000,  950,  925,  925,  900,  900,  875,  875,
         875,  850,  850], device='cuda:0') tensor([1075, 1075, 1075, 1025, 1000,  950,  925,  925,  900,  900,  875,  875,
         875,  850,  850], device='cuda:0')
2020-11-19 21:50:48,393 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([269, 269, 269, 257, 250, 238, 232, 232, 225, 225, 219, 219, 219, 213,
        213])
2020-11-19 21:50:48,395 (ctc:92) INFO: CTC input lengths:  tensor([269, 269, 269, 257, 250, 238, 232, 232, 225, 225, 219, 219, 219, 213,        213], dtype=torch.int32)
2020-11-19 21:50:48,395 (ctc:97) INFO: CTC output lengths: tensor([15, 19, 15, 19, 27, 26, 17, 19, 15, 23, 11, 39, 21, 11, 24],       dtype=torch.int32)
2020-11-19 21:50:48,398 (ctc:119) INFO: ctc loss:56.602054595947266
2020-11-19 21:50:48,522 (e2e_asr:56) INFO: mtl loss:56.602054595947266
2020-11-19 21:50:48,524 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (850, 63)
2020-11-19 21:50:48,524 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (850, 63)
2020-11-19 21:50:48,525 (asr:288) INFO: ilens in custom converter = 15 [850 825 825 825 775 775 775 775 750 750 750 725 725 725 725]
2020-11-19 21:50:48,527 (nets_utils:52) INFO: padded = torch.Size([15, 850, 63]) 
2020-11-19 21:50:48,528 (nets_utils:52) INFO: padded = torch.Size([15, 35]) 
2020-11-19 21:50:48,530 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([850, 825, 825, 825, 775, 775, 775, 775, 750, 750, 750, 725, 725, 725,
        725], device='cuda:0') tensor([850, 825, 825, 825, 775, 775, 775, 775, 750, 750, 750, 725, 725, 725,
        725], device='cuda:0')
2020-11-19 21:50:48,618 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([213, 207, 207, 207, 194, 194, 194, 194, 188, 188, 188, 182, 182, 182,
        182])
2020-11-19 21:50:48,620 (ctc:92) INFO: CTC input lengths:  tensor([213, 207, 207, 207, 194, 194, 194, 194, 188, 188, 188, 182, 182, 182,        182], dtype=torch.int32)
2020-11-19 21:50:48,620 (ctc:97) INFO: CTC output lengths: tensor([27, 15, 13, 19, 33, 21, 32, 30, 13, 35, 34, 15, 11, 27, 24],       dtype=torch.int32)
2020-11-19 21:50:48,622 (ctc:119) INFO: ctc loss:72.15370178222656
2020-11-19 21:50:48,727 (e2e_asr:56) INFO: mtl loss:72.15370178222656
2020-11-19 21:50:48,731 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (700, 63)
2020-11-19 21:50:48,731 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (700, 63)
2020-11-19 21:50:48,731 (asr:288) INFO: ilens in custom converter = 30 [700 700 700 675 675 675 675 650 650 625 625 600 600 600 600 575 575 575
 575 575 550 550 550 550 525 525 500 500 500 500]
2020-11-19 21:50:48,734 (nets_utils:52) INFO: padded = torch.Size([30, 700, 63]) 
2020-11-19 21:50:48,736 (nets_utils:52) INFO: padded = torch.Size([30, 43]) 
2020-11-19 21:50:48,739 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([700, 700, 700, 675, 675, 675, 675, 650, 650, 625, 625, 600, 600, 600,
        600, 575, 575, 575, 575, 575, 550, 550, 550, 550, 525, 525, 500, 500,
        500, 500], device='cuda:0') tensor([700, 700, 700, 675, 675, 675, 675, 650, 650, 625, 625, 600, 600, 600,
        600, 575, 575, 575, 575, 575, 550, 550, 550, 550, 525, 525, 500, 500,
        500, 500], device='cuda:0')
2020-11-19 21:50:48,823 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([175, 175, 175, 169, 169, 169, 169, 163, 163, 157, 157, 150, 150, 150,
        150, 144, 144, 144, 144, 144, 138, 138, 138, 138, 132, 132, 125, 125,
        125, 125])
2020-11-19 21:50:48,826 (ctc:92) INFO: CTC input lengths:  tensor([175, 175, 175, 169, 169, 169, 169, 163, 163, 157, 157, 150, 150, 150,        150, 144, 144, 144, 144, 144, 138, 138, 138, 138, 132, 132, 125, 125,        125, 125], dtype=torch.int32)
2020-11-19 21:50:48,826 (ctc:97) INFO: CTC output lengths: tensor([33, 17, 15, 34, 12, 21, 27, 13, 43, 33,  9, 11, 21, 13, 33, 19, 22,  7,        22, 15, 21, 26, 28, 23, 22, 31, 20, 20, 12, 25], dtype=torch.int32)
2020-11-19 21:50:48,829 (ctc:119) INFO: ctc loss:70.27799987792969
2020-11-19 21:50:48,999 (e2e_asr:56) INFO: mtl loss:70.27799987792969
2020-11-19 21:50:49,001 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (475, 63)
2020-11-19 21:50:49,002 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (475, 63)
2020-11-19 21:50:49,002 (asr:288) INFO: ilens in custom converter = 30 [475 450 450 450 450 425 425 425 400 400 400 375 375 375 375 375 325 325
 275 250 250 250 250 225 225 225 200 200 175 175]
2020-11-19 21:50:49,004 (nets_utils:52) INFO: padded = torch.Size([30, 475, 63]) 
2020-11-19 21:50:49,005 (nets_utils:52) INFO: padded = torch.Size([30, 32]) 
2020-11-19 21:50:49,008 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([475, 450, 450, 450, 450, 425, 425, 425, 400, 400, 400, 375, 375, 375,
        375, 375, 325, 325, 275, 250, 250, 250, 250, 225, 225, 225, 200, 200,
        175, 175], device='cuda:0') tensor([475, 450, 450, 450, 450, 425, 425, 425, 400, 400, 400, 375, 375, 375,
        375, 375, 325, 325, 275, 250, 250, 250, 250, 225, 225, 225, 200, 200,
        175, 175], device='cuda:0')
2020-11-19 21:50:49,065 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([119, 113, 113, 113, 113, 107, 107, 107, 100, 100, 100,  94,  94,  94,
         94,  94,  82,  82,  69,  63,  63,  63,  63,  57,  57,  57,  50,  50,
         44,  44])
2020-11-19 21:50:49,068 (ctc:92) INFO: CTC input lengths:  tensor([119, 113, 113, 113, 113, 107, 107, 107, 100, 100, 100,  94,  94,  94,         94,  94,  82,  82,  69,  63,  63,  63,  63,  57,  57,  57,  50,  50,         44,  44], dtype=torch.int32)
2020-11-19 21:50:49,068 (ctc:97) INFO: CTC output lengths: tensor([20, 16, 15, 19, 19, 18, 19, 32, 24, 17,  9, 10,  9, 11,  9, 21,  5, 16,        13,  3,  2, 12,  7,  3,  3,  4,  2,  2,  2,  4], dtype=torch.int32)
2020-11-19 21:50:49,070 (ctc:119) INFO: ctc loss:38.29335021972656
2020-11-19 21:50:49,187 (e2e_asr:56) INFO: mtl loss:38.29335021972656
/home/john/anaconda3/lib/python3.7/site-packages/chainer/training/triggers/early_stopping_trigger.py:102: UserWarning: validation/main/acc is not in observation
  warnings.warn('{} is not in observation'.format(self.monitor))
2020-11-19 21:50:50,853 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1025, 63)
2020-11-19 21:50:50,853 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1025, 63)
2020-11-19 21:50:50,853 (asr:288) INFO: ilens in custom converter = 15 [1025 1025 1025 1025 1025 1025 1025 1025 1025 1025 1025 1025 1025 1025
 1025]
2020-11-19 21:50:50,856 (nets_utils:52) INFO: padded = torch.Size([15, 1025, 63]) 
2020-11-19 21:50:50,858 (nets_utils:52) INFO: padded = torch.Size([15, 38]) 
2020-11-19 21:50:50,860 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1025, 1025, 1025, 1025, 1025, 1025, 1025, 1025, 1025, 1025, 1025, 1025,
        1025, 1025, 1025], device='cuda:0') tensor([1025, 1025, 1025, 1025, 1025, 1025, 1025, 1025, 1025, 1025, 1025, 1025,
        1025, 1025, 1025], device='cuda:0')
2020-11-19 21:50:50,968 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([257, 257, 257, 257, 257, 257, 257, 257, 257, 257, 257, 257, 257, 257,
        257])
2020-11-19 21:50:50,970 (ctc:92) INFO: CTC input lengths:  tensor([257, 257, 257, 257, 257, 257, 257, 257, 257, 257, 257, 257, 257, 257,        257], dtype=torch.int32)
2020-11-19 21:50:50,970 (ctc:97) INFO: CTC output lengths: tensor([26, 24, 17, 29, 19, 35, 13, 21, 38, 15, 31, 33, 17, 24, 28],       dtype=torch.int32)
2020-11-19 21:50:50,974 (ctc:119) INFO: ctc loss:73.21766662597656
2020-11-19 21:50:51,094 (e2e_asr:56) INFO: mtl loss:73.21766662597656
2020-11-19 21:50:51,237 (asr:234) INFO: grad norm=107.6094232392028
2020-11-19 21:50:51,247 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1450, 63)
2020-11-19 21:50:51,247 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1450, 63)
2020-11-19 21:50:51,247 (asr:288) INFO: ilens in custom converter = 15 [1450 1450 1425 1425 1400 1375 1375 1375 1375 1375 1350 1350 1350 1325
 1300]
2020-11-19 21:50:51,251 (nets_utils:52) INFO: padded = torch.Size([15, 1450, 63]) 
2020-11-19 21:50:51,253 (nets_utils:52) INFO: padded = torch.Size([15, 47]) 
2020-11-19 21:50:51,256 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1450, 1450, 1425, 1425, 1400, 1375, 1375, 1375, 1375, 1375, 1350, 1350,
        1350, 1325, 1300], device='cuda:0') tensor([1450, 1450, 1425, 1425, 1400, 1375, 1375, 1375, 1375, 1375, 1350, 1350,
        1350, 1325, 1300], device='cuda:0')
2020-11-19 21:50:51,405 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([363, 363, 357, 357, 350, 344, 344, 344, 344, 344, 338, 338, 338, 332,
        325])
2020-11-19 21:50:51,407 (ctc:92) INFO: CTC input lengths:  tensor([363, 363, 357, 357, 350, 344, 344, 344, 344, 344, 338, 338, 338, 332,        325], dtype=torch.int32)
2020-11-19 21:50:51,407 (ctc:97) INFO: CTC output lengths: tensor([37, 25, 19, 34, 17, 21, 36, 23, 19, 32, 47, 23, 19, 21, 19],       dtype=torch.int32)
2020-11-19 21:50:51,412 (ctc:119) INFO: ctc loss:86.81937408447266
2020-11-19 21:50:51,577 (e2e_asr:56) INFO: mtl loss:86.81937408447266
2020-11-19 21:50:51,799 (asr:234) INFO: grad norm=318.621505754758
2020-11-19 21:50:51,808 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (250, 63)
2020-11-19 21:50:51,808 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (250, 63)
2020-11-19 21:50:51,808 (asr:288) INFO: ilens in custom converter = 30 [250 250 250 250 250 250 250 250 250 250 250 250 250 250 250 250 250 250
 250 250 250 250 250 250 225 225 225 225 225 225]
2020-11-19 21:50:51,809 (nets_utils:52) INFO: padded = torch.Size([30, 250, 63]) 
2020-11-19 21:50:51,810 (nets_utils:52) INFO: padded = torch.Size([30, 11]) 
2020-11-19 21:50:51,813 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250,
        250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 225, 225, 225, 225,
        225, 225], device='cuda:0') tensor([250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250,
        250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 225, 225, 225, 225,
        225, 225], device='cuda:0')
2020-11-19 21:50:51,845 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63,
        63, 63, 63, 63, 63, 63, 57, 57, 57, 57, 57, 57])
2020-11-19 21:50:51,848 (ctc:92) INFO: CTC input lengths:  tensor([63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63,        63, 63, 63, 63, 63, 63, 57, 57, 57, 57, 57, 57], dtype=torch.int32)
2020-11-19 21:50:51,849 (ctc:97) INFO: CTC output lengths: tensor([ 5,  6,  5,  3,  6,  2,  2,  5,  3,  4,  3,  4,  5,  6,  5,  3,  3,  4,         3,  4,  3,  3, 11,  5,  6,  2,  2,  4,  5,  2], dtype=torch.int32)
2020-11-19 21:50:51,850 (ctc:119) INFO: ctc loss:15.025212287902832
2020-11-19 21:50:51,909 (e2e_asr:56) INFO: mtl loss:15.025212287902832
2020-11-19 21:50:51,958 (asr:234) INFO: grad norm=14.146885368137392
2020-11-19 21:50:51,968 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (875, 63)
2020-11-19 21:50:51,968 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (875, 63)
2020-11-19 21:50:51,968 (asr:288) INFO: ilens in custom converter = 15 [875 875 875 875 875 875 875 875 875 875 875 875 875 875 875]
2020-11-19 21:50:51,970 (nets_utils:52) INFO: padded = torch.Size([15, 875, 63]) 
2020-11-19 21:50:51,972 (nets_utils:52) INFO: padded = torch.Size([15, 48]) 
2020-11-19 21:50:51,974 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([875, 875, 875, 875, 875, 875, 875, 875, 875, 875, 875, 875, 875, 875,
        875], device='cuda:0') tensor([875, 875, 875, 875, 875, 875, 875, 875, 875, 875, 875, 875, 875, 875,
        875], device='cuda:0')
2020-11-19 21:50:52,066 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219,
        219])
2020-11-19 21:50:52,068 (ctc:92) INFO: CTC input lengths:  tensor([219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219,        219], dtype=torch.int32)
2020-11-19 21:50:52,068 (ctc:97) INFO: CTC output lengths: tensor([48, 33, 39, 18, 29, 19, 28, 19, 23, 22, 19, 17, 23, 23, 33],       dtype=torch.int32)
2020-11-19 21:50:52,071 (ctc:119) INFO: ctc loss:81.01779174804688
2020-11-19 21:50:52,177 (e2e_asr:56) INFO: mtl loss:81.01779174804688
2020-11-19 21:50:52,299 (asr:234) INFO: grad norm=109.0305298445274
2020-11-19 21:50:52,308 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (825, 63)
2020-11-19 21:50:52,308 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (825, 63)
2020-11-19 21:50:52,308 (asr:288) INFO: ilens in custom converter = 15 [825 825 825 825 825 825 825 825 825 825 825 825 825 825 825]
2020-11-19 21:50:52,311 (nets_utils:52) INFO: padded = torch.Size([15, 825, 63]) 
2020-11-19 21:50:52,312 (nets_utils:52) INFO: padded = torch.Size([15, 45]) 
2020-11-19 21:50:52,314 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([825, 825, 825, 825, 825, 825, 825, 825, 825, 825, 825, 825, 825, 825,
        825], device='cuda:0') tensor([825, 825, 825, 825, 825, 825, 825, 825, 825, 825, 825, 825, 825, 825,
        825], device='cuda:0')
2020-11-19 21:50:52,401 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207,
        207])
2020-11-19 21:50:52,403 (ctc:92) INFO: CTC input lengths:  tensor([207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207,        207], dtype=torch.int32)
2020-11-19 21:50:52,403 (ctc:97) INFO: CTC output lengths: tensor([17, 45, 30, 18, 32, 38, 36, 44, 23, 19, 11, 32, 19, 21, 42],       dtype=torch.int32)
2020-11-19 21:50:52,406 (ctc:119) INFO: ctc loss:85.67501831054688
2020-11-19 21:50:52,508 (e2e_asr:56) INFO: mtl loss:85.67501831054688
2020-11-19 21:50:52,624 (asr:234) INFO: grad norm=115.97960690062884
2020-11-19 21:50:52,634 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1300, 63)
2020-11-19 21:50:52,634 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1300, 63)
2020-11-19 21:50:52,634 (asr:288) INFO: ilens in custom converter = 15 [1300 1300 1275 1275 1275 1275 1250 1250 1250 1225 1225 1200 1200 1200
 1200]
2020-11-19 21:50:52,637 (nets_utils:52) INFO: padded = torch.Size([15, 1300, 63]) 
2020-11-19 21:50:52,639 (nets_utils:52) INFO: padded = torch.Size([15, 55]) 
2020-11-19 21:50:52,641 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1300, 1300, 1275, 1275, 1275, 1275, 1250, 1250, 1250, 1225, 1225, 1200,
        1200, 1200, 1200], device='cuda:0') tensor([1300, 1300, 1275, 1275, 1275, 1275, 1250, 1250, 1250, 1225, 1225, 1200,
        1200, 1200, 1200], device='cuda:0')
2020-11-19 21:50:52,777 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([325, 325, 319, 319, 319, 319, 313, 313, 313, 307, 307, 300, 300, 300,
        300])
2020-11-19 21:50:52,779 (ctc:92) INFO: CTC input lengths:  tensor([325, 325, 319, 319, 319, 319, 313, 313, 313, 307, 307, 300, 300, 300,        300], dtype=torch.int32)
2020-11-19 21:50:52,779 (ctc:97) INFO: CTC output lengths: tensor([17, 17, 19, 35, 19, 29, 15, 15, 34, 30, 33, 55, 48, 15, 17],       dtype=torch.int32)
2020-11-19 21:50:52,784 (ctc:119) INFO: ctc loss:77.73788452148438
2020-11-19 21:50:52,935 (e2e_asr:56) INFO: mtl loss:77.73788452148438
2020-11-19 21:50:53,124 (asr:234) INFO: grad norm=89.86694357444588
2020-11-19 21:50:53,134 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1575, 63)
2020-11-19 21:50:53,135 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1575, 63)
2020-11-19 21:50:53,135 (asr:288) INFO: ilens in custom converter = 15 [1575 1575 1575 1575 1550 1550 1525 1525 1525 1525 1500 1500 1500 1475
 1450]
2020-11-19 21:50:53,139 (nets_utils:52) INFO: padded = torch.Size([15, 1575, 63]) 
2020-11-19 21:50:53,141 (nets_utils:52) INFO: padded = torch.Size([15, 57]) 
2020-11-19 21:50:53,144 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1575, 1575, 1575, 1575, 1550, 1550, 1525, 1525, 1525, 1525, 1500, 1500,
        1500, 1475, 1450], device='cuda:0') tensor([1575, 1575, 1575, 1575, 1550, 1550, 1525, 1525, 1525, 1525, 1500, 1500,
        1500, 1475, 1450], device='cuda:0')
2020-11-19 21:50:53,305 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([394, 394, 394, 394, 388, 388, 382, 382, 382, 382, 375, 375, 375, 369,
        363])
2020-11-19 21:50:53,307 (ctc:92) INFO: CTC input lengths:  tensor([394, 394, 394, 394, 388, 388, 382, 382, 382, 382, 375, 375, 375, 369,        363], dtype=torch.int32)
2020-11-19 21:50:53,307 (ctc:97) INFO: CTC output lengths: tensor([30, 15, 19, 49, 29, 42, 19, 57, 19, 23, 34, 29, 19, 44, 44],       dtype=torch.int32)
2020-11-19 21:50:53,313 (ctc:119) INFO: ctc loss:101.26652526855469
2020-11-19 21:50:53,497 (e2e_asr:56) INFO: mtl loss:101.26652526855469
2020-11-19 21:50:53,732 (asr:234) INFO: grad norm=314.42063176463546
2020-11-19 21:50:53,743 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (650, 63)
2020-11-19 21:50:53,743 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (650, 63)
2020-11-19 21:50:53,743 (asr:288) INFO: ilens in custom converter = 30 [650 650 650 650 650 650 650 650 650 650 650 650 650 650 650 650 650 650
 650 650 650 650 625 625 625 625 625 625 625 625]
2020-11-19 21:50:53,747 (nets_utils:52) INFO: padded = torch.Size([30, 650, 63]) 
2020-11-19 21:50:53,749 (nets_utils:52) INFO: padded = torch.Size([30, 36]) 
2020-11-19 21:50:53,752 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650,
        650, 650, 650, 650, 650, 650, 650, 650, 625, 625, 625, 625, 625, 625,
        625, 625], device='cuda:0') tensor([650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650,
        650, 650, 650, 650, 650, 650, 650, 650, 625, 625, 625, 625, 625, 625,
        625, 625], device='cuda:0')
2020-11-19 21:50:53,833 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163,
        163, 163, 163, 163, 163, 163, 163, 163, 157, 157, 157, 157, 157, 157,
        157, 157])
2020-11-19 21:50:53,836 (ctc:92) INFO: CTC input lengths:  tensor([163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163,        163, 163, 163, 163, 163, 163, 163, 163, 157, 157, 157, 157, 157, 157,        157, 157], dtype=torch.int32)
2020-11-19 21:50:53,836 (ctc:97) INFO: CTC output lengths: tensor([29, 26, 25, 13, 25, 36, 23, 33, 21, 13,  9, 28, 11, 19, 13,  9, 26, 11,        21, 26,  9, 11, 15, 32, 18, 11, 29, 24, 17, 12], dtype=torch.int32)
2020-11-19 21:50:53,839 (ctc:119) INFO: ctc loss:62.78321838378906
2020-11-19 21:50:54,000 (e2e_asr:56) INFO: mtl loss:62.78321838378906
2020-11-19 21:50:54,122 (asr:234) INFO: grad norm=105.13297782240349
2020-11-19 21:50:54,132 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (425, 63)
2020-11-19 21:50:54,132 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (425, 63)
2020-11-19 21:50:54,132 (asr:288) INFO: ilens in custom converter = 30 [425 425 425 425 425 425 425 425 425 425 425 425 425 425 425 425 425 425
 425 400 400 400 400 400 400 400 400 400 400 400]
2020-11-19 21:50:54,134 (nets_utils:52) INFO: padded = torch.Size([30, 425, 63]) 
2020-11-19 21:50:54,135 (nets_utils:52) INFO: padded = torch.Size([30, 24]) 
2020-11-19 21:50:54,138 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([425, 425, 425, 425, 425, 425, 425, 425, 425, 425, 425, 425, 425, 425,
        425, 425, 425, 425, 425, 400, 400, 400, 400, 400, 400, 400, 400, 400,
        400, 400], device='cuda:0') tensor([425, 425, 425, 425, 425, 425, 425, 425, 425, 425, 425, 425, 425, 425,
        425, 425, 425, 425, 425, 400, 400, 400, 400, 400, 400, 400, 400, 400,
        400, 400], device='cuda:0')
2020-11-19 21:50:54,192 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
        107, 107, 107, 107, 107, 100, 100, 100, 100, 100, 100, 100, 100, 100,
        100, 100])
2020-11-19 21:50:54,196 (ctc:92) INFO: CTC input lengths:  tensor([107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,        107, 107, 107, 107, 107, 100, 100, 100, 100, 100, 100, 100, 100, 100,        100, 100], dtype=torch.int32)
2020-11-19 21:50:54,196 (ctc:97) INFO: CTC output lengths: tensor([16, 17, 15, 21, 19, 22, 22, 18, 22,  7, 22, 20,  5, 19, 14, 15, 10, 19,        19,  9, 20,  2, 15,  9, 17, 15, 17, 11, 24,  9], dtype=torch.int32)
2020-11-19 21:50:54,197 (ctc:119) INFO: ctc loss:45.68830108642578
2020-11-19 21:50:54,303 (e2e_asr:56) INFO: mtl loss:45.68830108642578
2020-11-19 21:50:54,385 (asr:234) INFO: grad norm=34.98261886544627
2020-11-19 21:50:54,394 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1000, 63)
2020-11-19 21:50:54,394 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1000, 63)
2020-11-19 21:50:54,395 (asr:288) INFO: ilens in custom converter = 15 [1000  975  975  975  975  975  975  975  975  975  975  975  975  975
  975]
2020-11-19 21:50:54,397 (nets_utils:52) INFO: padded = torch.Size([15, 1000, 63]) 
2020-11-19 21:50:54,399 (nets_utils:52) INFO: padded = torch.Size([15, 46]) 
2020-11-19 21:50:54,401 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1000,  975,  975,  975,  975,  975,  975,  975,  975,  975,  975,  975,
         975,  975,  975], device='cuda:0') tensor([1000,  975,  975,  975,  975,  975,  975,  975,  975,  975,  975,  975,
         975,  975,  975], device='cuda:0')
2020-11-19 21:50:54,506 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([250, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244,
        244])
2020-11-19 21:50:54,507 (ctc:92) INFO: CTC input lengths:  tensor([250, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244,        244], dtype=torch.int32)
2020-11-19 21:50:54,508 (ctc:97) INFO: CTC output lengths: tensor([19, 46, 15, 30, 22, 24, 19, 21, 15, 32, 33, 34, 24, 20, 19],       dtype=torch.int32)
2020-11-19 21:50:54,511 (ctc:119) INFO: ctc loss:74.08580017089844
2020-11-19 21:50:54,630 (e2e_asr:56) INFO: mtl loss:74.08580017089844
2020-11-19 21:50:54,772 (asr:234) INFO: grad norm=88.3637335436603
2020-11-19 21:50:54,782 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1200, 63)
2020-11-19 21:50:54,782 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1200, 63)
2020-11-19 21:50:54,782 (asr:288) INFO: ilens in custom converter = 15 [1200 1200 1200 1175 1175 1175 1175 1175 1175 1150 1150 1150 1150 1150
 1125]
2020-11-19 21:50:54,785 (nets_utils:52) INFO: padded = torch.Size([15, 1200, 63]) 
2020-11-19 21:50:54,787 (nets_utils:52) INFO: padded = torch.Size([15, 46]) 
2020-11-19 21:50:54,789 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1200, 1200, 1200, 1175, 1175, 1175, 1175, 1175, 1175, 1150, 1150, 1150,
        1150, 1150, 1125], device='cuda:0') tensor([1200, 1200, 1200, 1175, 1175, 1175, 1175, 1175, 1175, 1150, 1150, 1150,
        1150, 1150, 1125], device='cuda:0')
2020-11-19 21:50:54,913 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([300, 300, 300, 294, 294, 294, 294, 294, 294, 288, 288, 288, 288, 288,
        282])
2020-11-19 21:50:54,915 (ctc:92) INFO: CTC input lengths:  tensor([300, 300, 300, 294, 294, 294, 294, 294, 294, 288, 288, 288, 288, 288,        282], dtype=torch.int32)
2020-11-19 21:50:54,915 (ctc:97) INFO: CTC output lengths: tensor([35, 19, 46, 17, 17,  9, 11, 25, 17, 28, 13, 28, 33, 27, 19],       dtype=torch.int32)
2020-11-19 21:50:54,919 (ctc:119) INFO: ctc loss:76.24303436279297
2020-11-19 21:50:55,057 (e2e_asr:56) INFO: mtl loss:76.24303436279297
2020-11-19 21:50:55,233 (asr:234) INFO: grad norm=255.76726065099143
2020-11-19 21:50:55,243 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (550, 63)
2020-11-19 21:50:55,243 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (550, 63)
2020-11-19 21:50:55,243 (asr:288) INFO: ilens in custom converter = 30 [550 550 550 550 550 550 550 550 550 550 550 550 550 525 525 525 525 525
 525 525 525 525 525 525 525 525 525 525 525 525]
2020-11-19 21:50:55,246 (nets_utils:52) INFO: padded = torch.Size([30, 550, 63]) 
2020-11-19 21:50:55,247 (nets_utils:52) INFO: padded = torch.Size([30, 34]) 
2020-11-19 21:50:55,250 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 525,
        525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525,
        525, 525], device='cuda:0') tensor([550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 525,
        525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525,
        525, 525], device='cuda:0')
2020-11-19 21:50:55,321 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132])
2020-11-19 21:50:55,324 (ctc:92) INFO: CTC input lengths:  tensor([138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 132,        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,        132, 132], dtype=torch.int32)
2020-11-19 21:50:55,325 (ctc:97) INFO: CTC output lengths: tensor([29, 34, 21, 16, 30, 11, 12, 21, 11, 22,  9, 21, 26, 11, 22, 21, 15, 32,        13, 19, 20, 33, 32, 26, 11, 19, 11, 21, 13, 20], dtype=torch.int32)
2020-11-19 21:50:55,327 (ctc:119) INFO: ctc loss:64.87815856933594
2020-11-19 21:50:55,462 (e2e_asr:56) INFO: mtl loss:64.87815856933594
2020-11-19 21:50:55,565 (asr:234) INFO: grad norm=117.05234677505254
2020-11-19 21:50:55,575 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (800, 63)
2020-11-19 21:50:55,575 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (800, 63)
2020-11-19 21:50:55,575 (asr:288) INFO: ilens in custom converter = 15 [800 800 800 800 800 800 800 800 800 800 800 800 800 800 800]
2020-11-19 21:50:55,577 (nets_utils:52) INFO: padded = torch.Size([15, 800, 63]) 
2020-11-19 21:50:55,578 (nets_utils:52) INFO: padded = torch.Size([15, 38]) 
2020-11-19 21:50:55,580 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([800, 800, 800, 800, 800, 800, 800, 800, 800, 800, 800, 800, 800, 800,
        800], device='cuda:0') tensor([800, 800, 800, 800, 800, 800, 800, 800, 800, 800, 800, 800, 800, 800,
        800], device='cuda:0')
2020-11-19 21:50:55,665 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,
        200])
2020-11-19 21:50:55,667 (ctc:92) INFO: CTC input lengths:  tensor([200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,        200], dtype=torch.int32)
2020-11-19 21:50:55,667 (ctc:97) INFO: CTC output lengths: tensor([13, 29, 37, 20, 29, 18, 18, 36, 25, 22, 21, 19, 27, 13, 38],       dtype=torch.int32)
2020-11-19 21:50:55,670 (ctc:119) INFO: ctc loss:70.9048843383789
2020-11-19 21:50:55,764 (e2e_asr:56) INFO: mtl loss:70.9048843383789
2020-11-19 21:50:55,875 (asr:234) INFO: grad norm=100.93804523963918
2020-11-19 21:50:55,884 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (900, 63)
2020-11-19 21:50:55,884 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (900, 63)
2020-11-19 21:50:55,884 (asr:288) INFO: ilens in custom converter = 15 [900 900 900 900 900 900 900 900 900 900 900 900 900 875 875]
2020-11-19 21:50:55,887 (nets_utils:52) INFO: padded = torch.Size([15, 900, 63]) 
2020-11-19 21:50:55,888 (nets_utils:52) INFO: padded = torch.Size([15, 34]) 
2020-11-19 21:50:55,890 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([900, 900, 900, 900, 900, 900, 900, 900, 900, 900, 900, 900, 900, 875,
        875], device='cuda:0') tensor([900, 900, 900, 900, 900, 900, 900, 900, 900, 900, 900, 900, 900, 875,
        875], device='cuda:0')
2020-11-19 21:50:55,984 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 219,
        219])
2020-11-19 21:50:55,986 (ctc:92) INFO: CTC input lengths:  tensor([225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 219,        219], dtype=torch.int32)
2020-11-19 21:50:55,986 (ctc:97) INFO: CTC output lengths: tensor([23, 11, 27, 31, 15, 19, 20, 34, 13, 13, 32, 15, 17, 25, 24],       dtype=torch.int32)
2020-11-19 21:50:55,989 (ctc:119) INFO: ctc loss:63.02261734008789
2020-11-19 21:50:56,093 (e2e_asr:56) INFO: mtl loss:63.02261734008789
2020-11-19 21:50:56,224 (asr:234) INFO: grad norm=80.42061052317595
2020-11-19 21:50:56,234 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (600, 63)
2020-11-19 21:50:56,234 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (600, 63)
2020-11-19 21:50:56,234 (asr:288) INFO: ilens in custom converter = 30 [600 600 600 600 600 600 600 600 575 575 575 575 575 575 575 575 575 575
 575 575 575 575 575 575 575 575 575 575 575 575]
2020-11-19 21:50:56,237 (nets_utils:52) INFO: padded = torch.Size([30, 600, 63]) 
2020-11-19 21:50:56,239 (nets_utils:52) INFO: padded = torch.Size([30, 29]) 
2020-11-19 21:50:56,242 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([600, 600, 600, 600, 600, 600, 600, 600, 575, 575, 575, 575, 575, 575,
        575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575,
        575, 575], device='cuda:0') tensor([600, 600, 600, 600, 600, 600, 600, 600, 575, 575, 575, 575, 575, 575,
        575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575,
        575, 575], device='cuda:0')
2020-11-19 21:50:56,318 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([150, 150, 150, 150, 150, 150, 150, 150, 144, 144, 144, 144, 144, 144,
        144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
        144, 144])
2020-11-19 21:50:56,321 (ctc:92) INFO: CTC input lengths:  tensor([150, 150, 150, 150, 150, 150, 150, 150, 144, 144, 144, 144, 144, 144,        144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,        144, 144], dtype=torch.int32)
2020-11-19 21:50:56,322 (ctc:97) INFO: CTC output lengths: tensor([ 9, 22, 13,  9, 26,  9, 25, 17, 22, 22, 19, 21, 22, 29, 28, 22, 17, 11,        22, 23, 15, 27, 23, 24, 29, 19, 17, 22, 13, 11], dtype=torch.int32)
2020-11-19 21:50:56,324 (ctc:119) INFO: ctc loss:56.78567123413086
2020-11-19 21:50:56,469 (e2e_asr:56) INFO: mtl loss:56.78567123413086
2020-11-19 21:50:56,581 (asr:234) INFO: grad norm=61.107308689643546
2020-11-19 21:50:56,590 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1025, 63)
2020-11-19 21:50:56,590 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1025, 63)
2020-11-19 21:50:56,591 (asr:288) INFO: ilens in custom converter = 15 [1025 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000
 1000]
2020-11-19 21:50:56,593 (nets_utils:52) INFO: padded = torch.Size([15, 1025, 63]) 
2020-11-19 21:50:56,595 (nets_utils:52) INFO: padded = torch.Size([15, 51]) 
2020-11-19 21:50:56,597 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1025, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,
        1000, 1000, 1000], device='cuda:0') tensor([1025, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,
        1000, 1000, 1000], device='cuda:0')
2020-11-19 21:50:56,704 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([257, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250,
        250])
2020-11-19 21:50:56,706 (ctc:92) INFO: CTC input lengths:  tensor([257, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250,        250], dtype=torch.int32)
2020-11-19 21:50:56,706 (ctc:97) INFO: CTC output lengths: tensor([51, 19, 29, 28, 35, 21, 19, 47, 33, 24, 19, 32, 27, 19, 26],       dtype=torch.int32)
2020-11-19 21:50:56,710 (ctc:119) INFO: ctc loss:88.04000091552734
2020-11-19 21:50:56,834 (e2e_asr:56) INFO: mtl loss:88.04000091552734
2020-11-19 21:50:56,980 (asr:234) INFO: grad norm=133.01309386561135
2020-11-19 21:50:56,989 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (825, 63)
2020-11-19 21:50:56,990 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (825, 63)
2020-11-19 21:50:56,990 (asr:288) INFO: ilens in custom converter = 15 [825 825 825 825 825 825 825 825 800 800 800 800 800 800 800]
2020-11-19 21:50:56,992 (nets_utils:52) INFO: padded = torch.Size([15, 825, 63]) 
2020-11-19 21:50:56,993 (nets_utils:52) INFO: padded = torch.Size([15, 35]) 
2020-11-19 21:50:56,995 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([825, 825, 825, 825, 825, 825, 825, 825, 800, 800, 800, 800, 800, 800,
        800], device='cuda:0') tensor([825, 825, 825, 825, 825, 825, 825, 825, 800, 800, 800, 800, 800, 800,
        800], device='cuda:0')
2020-11-19 21:50:57,083 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([207, 207, 207, 207, 207, 207, 207, 207, 200, 200, 200, 200, 200, 200,
        200])
2020-11-19 21:50:57,085 (ctc:92) INFO: CTC input lengths:  tensor([207, 207, 207, 207, 207, 207, 207, 207, 200, 200, 200, 200, 200, 200,        200], dtype=torch.int32)
2020-11-19 21:50:57,085 (ctc:97) INFO: CTC output lengths: tensor([15, 18, 19, 21, 35, 23, 30, 19, 22, 32, 24, 13, 13, 24, 13],       dtype=torch.int32)
2020-11-19 21:50:57,088 (ctc:119) INFO: ctc loss:65.25879669189453
2020-11-19 21:50:57,185 (e2e_asr:56) INFO: mtl loss:65.25879669189453
2020-11-19 21:50:57,302 (asr:234) INFO: grad norm=132.04655616615005
2020-11-19 21:50:57,313 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (750, 63)
2020-11-19 21:50:57,313 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (750, 63)
2020-11-19 21:50:57,314 (asr:288) INFO: ilens in custom converter = 30 [750 750 750 750 750 750 750 725 725 725 725 725 725 725 725 725 725 725
 725 725 725 725 725 725 725 725 725 725 725 725]
2020-11-19 21:50:57,318 (nets_utils:52) INFO: padded = torch.Size([30, 750, 63]) 
2020-11-19 21:50:57,320 (nets_utils:52) INFO: padded = torch.Size([30, 45]) 
2020-11-19 21:50:57,323 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([750, 750, 750, 750, 750, 750, 750, 725, 725, 725, 725, 725, 725, 725,
        725, 725, 725, 725, 725, 725, 725, 725, 725, 725, 725, 725, 725, 725,
        725, 725], device='cuda:0') tensor([750, 750, 750, 750, 750, 750, 750, 725, 725, 725, 725, 725, 725, 725,
        725, 725, 725, 725, 725, 725, 725, 725, 725, 725, 725, 725, 725, 725,
        725, 725], device='cuda:0')
2020-11-19 21:50:57,417 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([188, 188, 188, 188, 188, 188, 188, 182, 182, 182, 182, 182, 182, 182,
        182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182,
        182, 182])
2020-11-19 21:50:57,420 (ctc:92) INFO: CTC input lengths:  tensor([188, 188, 188, 188, 188, 188, 188, 182, 182, 182, 182, 182, 182, 182,        182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182,        182, 182], dtype=torch.int32)
2020-11-19 21:50:57,420 (ctc:97) INFO: CTC output lengths: tensor([21, 19, 23, 17, 25, 26, 33,  9, 33, 17, 11, 19, 26, 11, 34,  9, 29, 29,        15, 17, 34, 21, 45, 32, 11, 31, 13, 13,  9, 22], dtype=torch.int32)
2020-11-19 21:50:57,423 (ctc:119) INFO: ctc loss:66.8940658569336
2020-11-19 21:50:57,606 (e2e_asr:56) INFO: mtl loss:66.8940658569336
2020-11-19 21:50:57,747 (asr:234) INFO: grad norm=101.75760996942492
2020-11-19 21:50:57,758 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (675, 63)
2020-11-19 21:50:57,758 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (675, 63)
2020-11-19 21:50:57,758 (asr:288) INFO: ilens in custom converter = 30 [675 675 675 675 675 675 675 675 675 675 675 675 675 675 675 675 675 675
 675 675 675 675 675 675 675 650 650 650 650 650]
2020-11-19 21:50:57,762 (nets_utils:52) INFO: padded = torch.Size([30, 675, 63]) 
2020-11-19 21:50:57,764 (nets_utils:52) INFO: padded = torch.Size([30, 46]) 
2020-11-19 21:50:57,767 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 675,
        675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 650, 650, 650,
        650, 650], device='cuda:0') tensor([675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 675,
        675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 675, 650, 650, 650,
        650, 650], device='cuda:0')
2020-11-19 21:50:57,853 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169,
        169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 163, 163, 163,
        163, 163])
2020-11-19 21:50:57,856 (ctc:92) INFO: CTC input lengths:  tensor([169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169,        169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 163, 163, 163,        163, 163], dtype=torch.int32)
2020-11-19 21:50:57,856 (ctc:97) INFO: CTC output lengths: tensor([13, 13, 13, 12, 19, 17, 20, 13, 30, 30, 46, 17, 21, 13, 19, 15, 13, 24,        21, 19,  7, 17, 33,  9, 41, 18, 26, 26, 29, 22], dtype=torch.int32)
2020-11-19 21:50:57,859 (ctc:119) INFO: ctc loss:61.40884017944336
2020-11-19 21:50:58,024 (e2e_asr:56) INFO: mtl loss:61.40884017944336
2020-11-19 21:50:58,151 (asr:234) INFO: grad norm=86.97964708453404
2020-11-19 21:50:58,162 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (775, 63)
2020-11-19 21:50:58,162 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (775, 63)
2020-11-19 21:50:58,162 (asr:288) INFO: ilens in custom converter = 30 [775 775 775 775 775 775 775 775 775 775 775 775 775 775 775 775 775 775
 775 775 775 775 775 775 775 750 750 750 750 750]
2020-11-19 21:50:58,166 (nets_utils:52) INFO: padded = torch.Size([30, 775, 63]) 
2020-11-19 21:50:58,168 (nets_utils:52) INFO: padded = torch.Size([30, 39]) 
2020-11-19 21:50:58,172 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775,
        775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 750, 750, 750,
        750, 750], device='cuda:0') tensor([775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775,
        775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 750, 750, 750,
        750, 750], device='cuda:0')
2020-11-19 21:50:58,267 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194,
        194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 188, 188, 188,
        188, 188])
2020-11-19 21:50:58,271 (ctc:92) INFO: CTC input lengths:  tensor([194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194,        194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 188, 188, 188,        188, 188], dtype=torch.int32)
2020-11-19 21:50:58,271 (ctc:97) INFO: CTC output lengths: tensor([26, 19, 11, 11, 13, 23, 15, 13,  5, 13, 25, 13,  9, 17, 25, 33, 25, 11,        22, 13, 28, 24, 15, 25, 15, 15, 28, 16, 39, 26], dtype=torch.int32)
2020-11-19 21:50:58,274 (ctc:119) INFO: ctc loss:55.76348114013672
2020-11-19 21:50:58,457 (e2e_asr:56) INFO: mtl loss:55.76348114013672
2020-11-19 21:50:58,603 (asr:234) INFO: grad norm=67.41045622727279
2020-11-19 21:50:58,612 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (225, 63)
2020-11-19 21:50:58,612 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (225, 63)
2020-11-19 21:50:58,612 (asr:288) INFO: ilens in custom converter = 30 [225 225 225 225 225 225 225 225 225 225 225 225 225 225 225 225 225 200
 200 200 200 200 200 200 200 200 200 200 200 200]
2020-11-19 21:50:58,614 (nets_utils:52) INFO: padded = torch.Size([30, 225, 63]) 
2020-11-19 21:50:58,615 (nets_utils:52) INFO: padded = torch.Size([30, 6]) 
2020-11-19 21:50:58,617 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225,
        225, 225, 225, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,
        200, 200], device='cuda:0') tensor([225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225,
        225, 225, 225, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,
        200, 200], device='cuda:0')
2020-11-19 21:50:58,647 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 50,
        50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50])
2020-11-19 21:50:58,650 (ctc:92) INFO: CTC input lengths:  tensor([57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 50,        50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50], dtype=torch.int32)
2020-11-19 21:50:58,650 (ctc:97) INFO: CTC output lengths: tensor([4, 6, 6, 4, 4, 4, 3, 4, 2, 2, 4, 4, 3, 6, 6, 5, 2, 2, 2, 2, 2, 2, 2, 2,        4, 4, 6, 2, 2, 4], dtype=torch.int32)
2020-11-19 21:50:58,651 (ctc:119) INFO: ctc loss:17.15922737121582
2020-11-19 21:50:58,704 (e2e_asr:56) INFO: mtl loss:17.15922737121582
2020-11-19 21:50:58,751 (asr:234) INFO: grad norm=63.276332978176505
2020-11-19 21:50:58,760 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1050, 63)
2020-11-19 21:50:58,760 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1050, 63)
2020-11-19 21:50:58,760 (asr:288) INFO: ilens in custom converter = 15 [1050 1050 1050 1050 1050 1050 1050 1050 1050 1050 1050 1050 1050 1050
 1050]
2020-11-19 21:50:58,763 (nets_utils:52) INFO: padded = torch.Size([15, 1050, 63]) 
2020-11-19 21:50:58,764 (nets_utils:52) INFO: padded = torch.Size([15, 50]) 
2020-11-19 21:50:58,766 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050,
        1050, 1050, 1050], device='cuda:0') tensor([1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050,
        1050, 1050, 1050], device='cuda:0')
2020-11-19 21:50:58,877 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([263, 263, 263, 263, 263, 263, 263, 263, 263, 263, 263, 263, 263, 263,
        263])
2020-11-19 21:50:58,879 (ctc:92) INFO: CTC input lengths:  tensor([263, 263, 263, 263, 263, 263, 263, 263, 263, 263, 263, 263, 263, 263,        263], dtype=torch.int32)
2020-11-19 21:50:58,879 (ctc:97) INFO: CTC output lengths: tensor([21, 17, 31, 19, 11, 50, 21, 19, 29, 24, 34, 15, 26, 21, 50],       dtype=torch.int32)
2020-11-19 21:50:58,882 (ctc:119) INFO: ctc loss:74.58186340332031
2020-11-19 21:50:59,008 (e2e_asr:56) INFO: mtl loss:74.58186340332031
2020-11-19 21:50:59,153 (asr:234) INFO: grad norm=85.56846765256388
2020-11-19 21:50:59,164 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (725, 63)
2020-11-19 21:50:59,164 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (725, 63)
2020-11-19 21:50:59,164 (asr:288) INFO: ilens in custom converter = 30 [725 725 725 725 725 725 725 725 725 725 700 700 700 700 700 700 700 700
 700 700 700 700 700 700 700 700 700 700 675 675]
2020-11-19 21:50:59,168 (nets_utils:52) INFO: padded = torch.Size([30, 725, 63]) 
2020-11-19 21:50:59,170 (nets_utils:52) INFO: padded = torch.Size([30, 39]) 
2020-11-19 21:50:59,173 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([725, 725, 725, 725, 725, 725, 725, 725, 725, 725, 700, 700, 700, 700,
        700, 700, 700, 700, 700, 700, 700, 700, 700, 700, 700, 700, 700, 700,
        675, 675], device='cuda:0') tensor([725, 725, 725, 725, 725, 725, 725, 725, 725, 725, 700, 700, 700, 700,
        700, 700, 700, 700, 700, 700, 700, 700, 700, 700, 700, 700, 700, 700,
        675, 675], device='cuda:0')
2020-11-19 21:50:59,263 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 175, 175, 175, 175,
        175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175,
        169, 169])
2020-11-19 21:50:59,266 (ctc:92) INFO: CTC input lengths:  tensor([182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 175, 175, 175, 175,        175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175,        169, 169], dtype=torch.int32)
2020-11-19 21:50:59,267 (ctc:97) INFO: CTC output lengths: tensor([25, 20, 15, 19, 24, 11, 23, 21, 20, 30, 20, 11,  9, 13, 22, 19, 17, 17,        19, 34, 39, 11, 36, 19, 11, 18, 35, 19,  9, 11], dtype=torch.int32)
2020-11-19 21:50:59,269 (ctc:119) INFO: ctc loss:60.607093811035156
2020-11-19 21:50:59,444 (e2e_asr:56) INFO: mtl loss:60.607093811035156
2020-11-19 21:50:59,582 (asr:234) INFO: grad norm=107.05168389089373
2020-11-19 21:50:59,592 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (975, 63)
2020-11-19 21:50:59,592 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (975, 63)
2020-11-19 21:50:59,592 (asr:288) INFO: ilens in custom converter = 15 [975 950 950 950 950 950 950 950 950 950 950 950 950 950 925]
2020-11-19 21:50:59,595 (nets_utils:52) INFO: padded = torch.Size([15, 975, 63]) 
2020-11-19 21:50:59,596 (nets_utils:52) INFO: padded = torch.Size([15, 51]) 
2020-11-19 21:50:59,598 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([975, 950, 950, 950, 950, 950, 950, 950, 950, 950, 950, 950, 950, 950,
        925], device='cuda:0') tensor([975, 950, 950, 950, 950, 950, 950, 950, 950, 950, 950, 950, 950, 950,
        925], device='cuda:0')
2020-11-19 21:50:59,702 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([244, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238,
        232])
2020-11-19 21:50:59,703 (ctc:92) INFO: CTC input lengths:  tensor([244, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238,        232], dtype=torch.int32)
2020-11-19 21:50:59,704 (ctc:97) INFO: CTC output lengths: tensor([46, 15, 50, 30, 51, 20, 25, 19, 47, 32, 17, 47, 19, 18, 49],       dtype=torch.int32)
2020-11-19 21:50:59,707 (ctc:119) INFO: ctc loss:100.35295867919922
2020-11-19 21:50:59,825 (e2e_asr:56) INFO: mtl loss:100.35295867919922
2020-11-19 21:50:59,968 (asr:234) INFO: grad norm=165.10357127188365
epoch       iteration   main/loss   main/loss_ctc  main/loss_att  validation/main/loss  validation/main/loss_ctc  validation/main/loss_att  main/acc    validation/main/acc  main/cer_ctc  validation/main/cer_ctc  elapsed_time  eps       
[J2           100         72.0761     72.0761                       65.372                65.372                                                                               1.00331       0.975255                 40.7839       1e-08       
[J     total [###########################################.......] 87.72%
this epoch [###############################...................] 63.16%
       100 iter, 2 epoch / 3 epochs
       inf iters/sec. Estimated time to finish: 0:00:00.
[4A2020-11-19 21:50:59,978 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (850, 63)
2020-11-19 21:50:59,978 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (850, 63)
2020-11-19 21:50:59,979 (asr:288) INFO: ilens in custom converter = 15 [850 850 850 850 850 850 850 850 850 850 850 850 850 825 825]
2020-11-19 21:50:59,981 (nets_utils:52) INFO: padded = torch.Size([15, 850, 63]) 
2020-11-19 21:50:59,982 (nets_utils:52) INFO: padded = torch.Size([15, 46]) 
2020-11-19 21:50:59,984 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([850, 850, 850, 850, 850, 850, 850, 850, 850, 850, 850, 850, 850, 825,
        825], device='cuda:0') tensor([850, 850, 850, 850, 850, 850, 850, 850, 850, 850, 850, 850, 850, 825,
        825], device='cuda:0')
2020-11-19 21:51:00,075 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 207,
        207])
2020-11-19 21:51:00,076 (ctc:92) INFO: CTC input lengths:  tensor([213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 207,        207], dtype=torch.int32)
2020-11-19 21:51:00,077 (ctc:97) INFO: CTC output lengths: tensor([11, 13, 38, 32, 18, 15, 32, 46, 23, 20,  9, 29, 14, 22, 23],       dtype=torch.int32)
2020-11-19 21:51:00,080 (ctc:119) INFO: ctc loss:72.01882934570312
2020-11-19 21:51:00,181 (e2e_asr:56) INFO: mtl loss:72.01882934570312
2020-11-19 21:51:00,305 (asr:234) INFO: grad norm=137.60677183662213
2020-11-19 21:51:00,314 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1075, 63)
2020-11-19 21:51:00,314 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1075, 63)
2020-11-19 21:51:00,315 (asr:288) INFO: ilens in custom converter = 15 [1075 1075 1075 1075 1075 1075 1075 1075 1075 1075 1075 1075 1050 1050
 1050]
2020-11-19 21:51:00,317 (nets_utils:52) INFO: padded = torch.Size([15, 1075, 63]) 
2020-11-19 21:51:00,319 (nets_utils:52) INFO: padded = torch.Size([15, 34]) 
2020-11-19 21:51:00,321 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075,
        1050, 1050, 1050], device='cuda:0') tensor([1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075, 1075,
        1050, 1050, 1050], device='cuda:0')
2020-11-19 21:51:00,434 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([269, 269, 269, 269, 269, 269, 269, 269, 269, 269, 269, 269, 263, 263,
        263])
2020-11-19 21:51:00,436 (ctc:92) INFO: CTC input lengths:  tensor([269, 269, 269, 269, 269, 269, 269, 269, 269, 269, 269, 269, 263, 263,        263], dtype=torch.int32)
2020-11-19 21:51:00,436 (ctc:97) INFO: CTC output lengths: tensor([34, 19, 17, 32, 17, 20, 13, 15, 26, 13, 19, 25, 21, 19, 17],       dtype=torch.int32)
2020-11-19 21:51:00,439 (ctc:119) INFO: ctc loss:55.7755012512207
2020-11-19 21:51:00,561 (e2e_asr:56) INFO: mtl loss:55.7755012512207
2020-11-19 21:51:00,712 (asr:234) INFO: grad norm=36.11887973054369
2020-11-19 21:51:00,721 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (925, 63)
2020-11-19 21:51:00,721 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (925, 63)
2020-11-19 21:51:00,722 (asr:288) INFO: ilens in custom converter = 15 [925 925 925 925 925 925 925 925 925 925 925 925 925 925 900]
2020-11-19 21:51:00,724 (nets_utils:52) INFO: padded = torch.Size([15, 925, 63]) 
2020-11-19 21:51:00,725 (nets_utils:52) INFO: padded = torch.Size([15, 35]) 
2020-11-19 21:51:00,728 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([925, 925, 925, 925, 925, 925, 925, 925, 925, 925, 925, 925, 925, 925,
        900], device='cuda:0') tensor([925, 925, 925, 925, 925, 925, 925, 925, 925, 925, 925, 925, 925, 925,
        900], device='cuda:0')
2020-11-19 21:51:00,825 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232,
        225])
2020-11-19 21:51:00,827 (ctc:92) INFO: CTC input lengths:  tensor([232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232,        225], dtype=torch.int32)
2020-11-19 21:51:00,827 (ctc:97) INFO: CTC output lengths: tensor([35, 17, 34, 19, 19, 34, 26, 15, 15, 15, 22, 33, 18, 28, 32],       dtype=torch.int32)
2020-11-19 21:51:00,830 (ctc:119) INFO: ctc loss:71.84090423583984
2020-11-19 21:51:00,938 (e2e_asr:56) INFO: mtl loss:71.84090423583984
2020-11-19 21:51:01,071 (asr:234) INFO: grad norm=135.89749370667784
2020-11-19 21:51:01,081 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (350, 63)
2020-11-19 21:51:01,081 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (350, 63)
2020-11-19 21:51:01,081 (asr:288) INFO: ilens in custom converter = 30 [350 350 350 350 350 350 350 350 350 350 350 350 350 350 325 325 325 325
 325 325 325 325 325 325 325 325 325 325 325 325]
2020-11-19 21:51:01,083 (nets_utils:52) INFO: padded = torch.Size([30, 350, 63]) 
2020-11-19 21:51:01,084 (nets_utils:52) INFO: padded = torch.Size([30, 18]) 
2020-11-19 21:51:01,087 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350,
        325, 325, 325, 325, 325, 325, 325, 325, 325, 325, 325, 325, 325, 325,
        325, 325], device='cuda:0') tensor([350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350,
        325, 325, 325, 325, 325, 325, 325, 325, 325, 325, 325, 325, 325, 325,
        325, 325], device='cuda:0')
2020-11-19 21:51:01,132 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 82, 82, 82, 82,
        82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82])
2020-11-19 21:51:01,135 (ctc:92) INFO: CTC input lengths:  tensor([88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 82, 82, 82, 82,        82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82], dtype=torch.int32)
2020-11-19 21:51:01,135 (ctc:97) INFO: CTC output lengths: tensor([ 5,  7,  6, 12, 11, 15, 11, 11,  9, 15, 17, 11,  5, 11,  4, 10,  6, 11,         8,  5, 18,  5, 10,  5, 10,  3,  7, 15, 14,  2], dtype=torch.int32)
2020-11-19 21:51:01,136 (ctc:119) INFO: ctc loss:29.304983139038086
2020-11-19 21:51:01,221 (e2e_asr:56) INFO: mtl loss:29.304983139038086
2020-11-19 21:51:01,291 (asr:234) INFO: grad norm=30.48796909649373
2020-11-19 21:51:01,301 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (625, 63)
2020-11-19 21:51:01,301 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (625, 63)
2020-11-19 21:51:01,302 (asr:288) INFO: ilens in custom converter = 30 [625 600 600 600 600 600 600 600 600 600 600 600 600 600 600 600 600 600
 600 600 600 600 600 600 600 600 600 600 600 600]
2020-11-19 21:51:01,304 (nets_utils:52) INFO: padded = torch.Size([30, 625, 63]) 
2020-11-19 21:51:01,306 (nets_utils:52) INFO: padded = torch.Size([30, 36]) 
2020-11-19 21:51:01,309 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([625, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600,
        600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600,
        600, 600], device='cuda:0') tensor([625, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600,
        600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600, 600,
        600, 600], device='cuda:0')
2020-11-19 21:51:01,387 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([157, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
        150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
        150, 150])
2020-11-19 21:51:01,390 (ctc:92) INFO: CTC input lengths:  tensor([157, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,        150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,        150, 150], dtype=torch.int32)
2020-11-19 21:51:01,390 (ctc:97) INFO: CTC output lengths: tensor([31, 19, 27, 11, 18, 19, 34,  7, 25, 20, 24, 21, 23, 22, 13, 36, 31, 13,        29, 20, 22, 32, 13, 16, 15, 19, 21, 23, 11, 20], dtype=torch.int32)
2020-11-19 21:51:01,392 (ctc:119) INFO: ctc loss:61.328800201416016
2020-11-19 21:51:01,545 (e2e_asr:56) INFO: mtl loss:61.328800201416016
2020-11-19 21:51:01,664 (asr:234) INFO: grad norm=55.84323099514984
2020-11-19 21:51:01,671 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 8 (200, 63)
2020-11-19 21:51:01,671 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 8 (200, 63)
2020-11-19 21:51:01,671 (asr:288) INFO: ilens in custom converter = 8 [200 200 200 200 200 200 200 175]
2020-11-19 21:51:01,672 (nets_utils:52) INFO: padded = torch.Size([8, 200, 63]) 
2020-11-19 21:51:01,672 (nets_utils:52) INFO: padded = torch.Size([8, 4]) 
2020-11-19 21:51:01,673 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([8]) torch.Size([8]) hlens,ilens=tensor([200, 200, 200, 200, 200, 200, 200, 175], device='cuda:0') tensor([200, 200, 200, 200, 200, 200, 200, 175], device='cuda:0')
2020-11-19 21:51:01,691 (e2e_asr:368) INFO: encoder ilens=torch.Size([8]) tensor([50, 50, 50, 50, 50, 50, 50, 44])
2020-11-19 21:51:01,692 (ctc:92) INFO: CTC input lengths:  tensor([50, 50, 50, 50, 50, 50, 50, 44], dtype=torch.int32)
2020-11-19 21:51:01,692 (ctc:97) INFO: CTC output lengths: tensor([2, 2, 4, 2, 3, 3, 4, 4], dtype=torch.int32)
2020-11-19 21:51:01,693 (ctc:119) INFO: ctc loss:11.345399856567383
2020-11-19 21:51:01,706 (e2e_asr:56) INFO: mtl loss:11.345399856567383
2020-11-19 21:51:01,732 (asr:234) INFO: grad norm=12.722848130869112
2020-11-19 21:51:01,742 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (500, 63)
2020-11-19 21:51:01,742 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (500, 63)
2020-11-19 21:51:01,742 (asr:288) INFO: ilens in custom converter = 30 [500 500 500 500 500 500 500 500 500 500 500 500 500 500 475 475 475 475
 475 475 475 475 475 475 475 475 475 475 475 475]
2020-11-19 21:51:01,745 (nets_utils:52) INFO: padded = torch.Size([30, 500, 63]) 
2020-11-19 21:51:01,746 (nets_utils:52) INFO: padded = torch.Size([30, 28]) 
2020-11-19 21:51:01,749 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,
        475, 475, 475, 475, 475, 475, 475, 475, 475, 475, 475, 475, 475, 475,
        475, 475], device='cuda:0') tensor([500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,
        475, 475, 475, 475, 475, 475, 475, 475, 475, 475, 475, 475, 475, 475,
        475, 475], device='cuda:0')
2020-11-19 21:51:01,814 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125,
        119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119,
        119, 119])
2020-11-19 21:51:01,817 (ctc:92) INFO: CTC input lengths:  tensor([125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125,        119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119,        119, 119], dtype=torch.int32)
2020-11-19 21:51:01,818 (ctc:97) INFO: CTC output lengths: tensor([17, 12, 21, 20,  7, 17,  7, 11, 28, 15, 11, 13, 20, 27, 21,  9, 15,  9,        10, 13, 20, 22,  9, 17, 20, 24, 13,  9, 17,  9], dtype=torch.int32)
2020-11-19 21:51:01,819 (ctc:119) INFO: ctc loss:52.69369125366211
2020-11-19 21:51:01,940 (e2e_asr:56) INFO: mtl loss:52.69369125366211
2020-11-19 21:51:02,036 (asr:234) INFO: grad norm=108.28391620840164
2020-11-19 21:51:02,047 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (525, 63)
2020-11-19 21:51:02,047 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (525, 63)
2020-11-19 21:51:02,047 (asr:288) INFO: ilens in custom converter = 30 [525 525 525 525 525 525 525 525 525 525 525 525 525 525 525 500 500 500
 500 500 500 500 500 500 500 500 500 500 500 500]
2020-11-19 21:51:02,050 (nets_utils:52) INFO: padded = torch.Size([30, 525, 63]) 
2020-11-19 21:51:02,051 (nets_utils:52) INFO: padded = torch.Size([30, 37]) 
2020-11-19 21:51:02,054 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525,
        525, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,
        500, 500], device='cuda:0') tensor([525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525, 525,
        525, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,
        500, 500], device='cuda:0')
2020-11-19 21:51:02,120 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125,
        125, 125])
2020-11-19 21:51:02,123 (ctc:92) INFO: CTC input lengths:  tensor([132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,        132, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125,        125, 125], dtype=torch.int32)
2020-11-19 21:51:02,123 (ctc:97) INFO: CTC output lengths: tensor([30, 37, 11, 22, 22, 15,  7, 22,  9, 22, 15, 23,  9, 22, 21, 15,  9, 17,        19, 23,  9, 23, 22, 17, 14, 11, 21, 22, 11, 26], dtype=torch.int32)
2020-11-19 21:51:02,125 (ctc:119) INFO: ctc loss:52.53483963012695
2020-11-19 21:51:02,258 (e2e_asr:56) INFO: mtl loss:52.53483963012695
2020-11-19 21:51:02,359 (asr:234) INFO: grad norm=26.079475296249434
2020-11-19 21:51:02,368 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1125, 63)
2020-11-19 21:51:02,369 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1125, 63)
2020-11-19 21:51:02,369 (asr:288) INFO: ilens in custom converter = 15 [1125 1125 1100 1100 1100 1100 1100 1100 1100 1100 1100 1100 1075 1075
 1075]
2020-11-19 21:51:02,372 (nets_utils:52) INFO: padded = torch.Size([15, 1125, 63]) 
2020-11-19 21:51:02,373 (nets_utils:52) INFO: padded = torch.Size([15, 52]) 
2020-11-19 21:51:02,375 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1125, 1125, 1100, 1100, 1100, 1100, 1100, 1100, 1100, 1100, 1100, 1100,
        1075, 1075, 1075], device='cuda:0') tensor([1125, 1125, 1100, 1100, 1100, 1100, 1100, 1100, 1100, 1100, 1100, 1100,
        1075, 1075, 1075], device='cuda:0')
2020-11-19 21:51:02,494 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([282, 282, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 269, 269,
        269])
2020-11-19 21:51:02,496 (ctc:92) INFO: CTC input lengths:  tensor([282, 282, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 269, 269,        269], dtype=torch.int32)
2020-11-19 21:51:02,496 (ctc:97) INFO: CTC output lengths: tensor([19, 19, 36, 21, 15, 17, 41, 23,  9, 17, 52, 25, 29, 13, 34],       dtype=torch.int32)
2020-11-19 21:51:02,500 (ctc:119) INFO: ctc loss:85.68675994873047
2020-11-19 21:51:02,632 (e2e_asr:56) INFO: mtl loss:85.68675994873047
2020-11-19 21:51:02,795 (asr:234) INFO: grad norm=279.579008780415
2020-11-19 21:51:02,804 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (325, 63)
2020-11-19 21:51:02,804 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (325, 63)
2020-11-19 21:51:02,804 (asr:288) INFO: ilens in custom converter = 30 [325 300 300 300 300 300 300 300 300 275 275 275 275 275 275 275 275 275
 275 275 275 275 275 275 250 250 250 250 250 250]
2020-11-19 21:51:02,806 (nets_utils:52) INFO: padded = torch.Size([30, 325, 63]) 
2020-11-19 21:51:02,807 (nets_utils:52) INFO: padded = torch.Size([30, 12]) 
2020-11-19 21:51:02,810 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([325, 300, 300, 300, 300, 300, 300, 300, 300, 275, 275, 275, 275, 275,
        275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 250, 250, 250, 250,
        250, 250], device='cuda:0') tensor([325, 300, 300, 300, 300, 300, 300, 300, 300, 275, 275, 275, 275, 275,
        275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 250, 250, 250, 250,
        250, 250], device='cuda:0')
2020-11-19 21:51:02,851 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([82, 75, 75, 75, 75, 75, 75, 75, 75, 69, 69, 69, 69, 69, 69, 69, 69, 69,
        69, 69, 69, 69, 69, 69, 63, 63, 63, 63, 63, 63])
2020-11-19 21:51:02,854 (ctc:92) INFO: CTC input lengths:  tensor([82, 75, 75, 75, 75, 75, 75, 75, 75, 69, 69, 69, 69, 69, 69, 69, 69, 69,        69, 69, 69, 69, 69, 69, 63, 63, 63, 63, 63, 63], dtype=torch.int32)
2020-11-19 21:51:02,854 (ctc:97) INFO: CTC output lengths: tensor([ 9,  4,  5,  3,  5, 10,  4, 12,  6, 12,  6,  4, 10,  3,  7,  4,  6,  4,         5,  6,  6,  5,  3,  9,  3,  4,  6,  4,  3,  6], dtype=torch.int32)
2020-11-19 21:51:02,855 (ctc:119) INFO: ctc loss:19.421611785888672
2020-11-19 21:51:02,931 (e2e_asr:56) INFO: mtl loss:19.421611785888672
2020-11-19 21:51:02,998 (asr:234) INFO: grad norm=12.871367233540887
2020-11-19 21:51:03,008 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (475, 63)
2020-11-19 21:51:03,008 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (475, 63)
2020-11-19 21:51:03,008 (asr:288) INFO: ilens in custom converter = 30 [475 450 450 450 450 450 450 450 450 450 450 450 450 450 450 450 450 450
 450 450 450 450 450 450 450 425 425 425 425 425]
2020-11-19 21:51:03,010 (nets_utils:52) INFO: padded = torch.Size([30, 475, 63]) 
2020-11-19 21:51:03,012 (nets_utils:52) INFO: padded = torch.Size([30, 23]) 
2020-11-19 21:51:03,015 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([475, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450,
        450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 425, 425, 425,
        425, 425], device='cuda:0') tensor([475, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450,
        450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 425, 425, 425,
        425, 425], device='cuda:0')
2020-11-19 21:51:03,073 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([119, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113,
        113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 107, 107, 107,
        107, 107])
2020-11-19 21:51:03,076 (ctc:92) INFO: CTC input lengths:  tensor([119, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113,        113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 107, 107, 107,        107, 107], dtype=torch.int32)
2020-11-19 21:51:03,076 (ctc:97) INFO: CTC output lengths: tensor([21, 13, 22, 21, 22,  9, 22, 22, 10, 22, 20, 22, 21, 22, 11, 20, 16, 22,        15, 17, 22, 22, 10, 20,  7, 13, 23, 21,  9, 22], dtype=torch.int32)
2020-11-19 21:51:03,078 (ctc:119) INFO: ctc loss:53.35929489135742
2020-11-19 21:51:03,194 (e2e_asr:56) INFO: mtl loss:53.35929489135742
2020-11-19 21:51:03,287 (asr:234) INFO: grad norm=63.97973805710353
2020-11-19 21:51:03,297 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (575, 63)
2020-11-19 21:51:03,297 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (575, 63)
2020-11-19 21:51:03,297 (asr:288) INFO: ilens in custom converter = 30 [575 575 575 550 550 550 550 550 550 550 550 550 550 550 550 550 550 550
 550 550 550 550 550 550 550 550 550 550 550 550]
2020-11-19 21:51:03,300 (nets_utils:52) INFO: padded = torch.Size([30, 575, 63]) 
2020-11-19 21:51:03,302 (nets_utils:52) INFO: padded = torch.Size([30, 35]) 
2020-11-19 21:51:03,305 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([575, 575, 575, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550,
        550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550,
        550, 550], device='cuda:0') tensor([575, 575, 575, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550,
        550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550,
        550, 550], device='cuda:0')
2020-11-19 21:51:03,377 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([144, 144, 144, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
        138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
        138, 138])
2020-11-19 21:51:03,380 (ctc:92) INFO: CTC input lengths:  tensor([144, 144, 144, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,        138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,        138, 138], dtype=torch.int32)
2020-11-19 21:51:03,380 (ctc:97) INFO: CTC output lengths: tensor([17, 19, 20, 33, 22, 30, 21,  7, 19, 10, 11,  9, 19,  9, 20, 14, 29, 23,        11,  9, 11, 11, 22, 14, 12, 11, 29, 15, 35, 35], dtype=torch.int32)
2020-11-19 21:51:03,382 (ctc:119) INFO: ctc loss:59.09708786010742
2020-11-19 21:51:03,525 (e2e_asr:56) INFO: mtl loss:59.09708786010742
2020-11-19 21:51:03,632 (asr:234) INFO: grad norm=128.886900918977
2020-11-19 21:51:03,642 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (400, 63)
2020-11-19 21:51:03,642 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (400, 63)
2020-11-19 21:51:03,642 (asr:288) INFO: ilens in custom converter = 30 [400 400 400 400 400 400 400 400 375 375 375 375 375 375 375 375 375 375
 375 375 375 375 375 375 375 375 375 350 350 350]
2020-11-19 21:51:03,644 (nets_utils:52) INFO: padded = torch.Size([30, 400, 63]) 
2020-11-19 21:51:03,646 (nets_utils:52) INFO: padded = torch.Size([30, 22]) 
2020-11-19 21:51:03,648 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([400, 400, 400, 400, 400, 400, 400, 400, 375, 375, 375, 375, 375, 375,
        375, 375, 375, 375, 375, 375, 375, 375, 375, 375, 375, 375, 375, 350,
        350, 350], device='cuda:0') tensor([400, 400, 400, 400, 400, 400, 400, 400, 375, 375, 375, 375, 375, 375,
        375, 375, 375, 375, 375, 375, 375, 375, 375, 375, 375, 375, 375, 350,
        350, 350], device='cuda:0')
2020-11-19 21:51:03,699 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([100, 100, 100, 100, 100, 100, 100, 100,  94,  94,  94,  94,  94,  94,
         94,  94,  94,  94,  94,  94,  94,  94,  94,  94,  94,  94,  94,  88,
         88,  88])
2020-11-19 21:51:03,702 (ctc:92) INFO: CTC input lengths:  tensor([100, 100, 100, 100, 100, 100, 100, 100,  94,  94,  94,  94,  94,  94,         94,  94,  94,  94,  94,  94,  94,  94,  94,  94,  94,  94,  94,  88,         88,  88], dtype=torch.int32)
2020-11-19 21:51:03,703 (ctc:97) INFO: CTC output lengths: tensor([ 7, 18, 18,  9, 20, 22, 20,  7,  7, 13, 14, 12, 11,  7, 16,  7, 19, 17,        11,  7, 10,  9, 18, 16,  9, 13, 16, 13, 11, 17], dtype=torch.int32)
2020-11-19 21:51:03,704 (ctc:119) INFO: ctc loss:38.422908782958984
2020-11-19 21:51:03,801 (e2e_asr:56) INFO: mtl loss:38.422908782958984
2020-11-19 21:51:03,880 (asr:234) INFO: grad norm=41.971114702316186
2020-11-19 21:51:03,891 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (625, 63)
2020-11-19 21:51:03,891 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (625, 63)
2020-11-19 21:51:03,891 (asr:288) INFO: ilens in custom converter = 30 [625 625 625 625 625 625 625 625 625 625 625 625 625 625 625 625 625 625
 625 625 625 625 625 625 625 625 625 625 625 625]
2020-11-19 21:51:03,894 (nets_utils:52) INFO: padded = torch.Size([30, 625, 63]) 
2020-11-19 21:51:03,896 (nets_utils:52) INFO: padded = torch.Size([30, 40]) 
2020-11-19 21:51:03,899 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625,
        625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625,
        625, 625], device='cuda:0') tensor([625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625,
        625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625,
        625, 625], device='cuda:0')
2020-11-19 21:51:03,978 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
        157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
        157, 157])
2020-11-19 21:51:03,981 (ctc:92) INFO: CTC input lengths:  tensor([157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,        157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,        157, 157], dtype=torch.int32)
2020-11-19 21:51:03,982 (ctc:97) INFO: CTC output lengths: tensor([20,  9, 29, 24, 11,  9, 30, 11,  9, 19, 24, 14, 11, 13,  7, 35,  9, 11,        17, 13,  5, 40, 32, 39, 21, 23, 25, 11, 20, 13], dtype=torch.int32)
2020-11-19 21:51:03,984 (ctc:119) INFO: ctc loss:59.91683578491211
2020-11-19 21:51:04,137 (e2e_asr:56) INFO: mtl loss:59.91683578491211
2020-11-19 21:51:04,254 (asr:234) INFO: grad norm=131.79114854360463
2020-11-19 21:51:04,263 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 10 (1600, 63)
2020-11-19 21:51:04,263 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 10 (1600, 63)
2020-11-19 21:51:04,263 (asr:288) INFO: ilens in custom converter = 10 [1600 1325 1250 1225 1225 1175 1175 1125 1100 1075]
2020-11-19 21:51:04,265 (nets_utils:52) INFO: padded = torch.Size([10, 1600, 63]) 
2020-11-19 21:51:04,267 (nets_utils:52) INFO: padded = torch.Size([10, 46]) 
2020-11-19 21:51:04,269 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([10]) torch.Size([10]) hlens,ilens=tensor([1600, 1325, 1250, 1225, 1225, 1175, 1175, 1125, 1100, 1075],
       device='cuda:0') tensor([1600, 1325, 1250, 1225, 1225, 1175, 1175, 1125, 1100, 1075],
       device='cuda:0')
2020-11-19 21:51:04,406 (e2e_asr:368) INFO: encoder ilens=torch.Size([10]) tensor([400, 332, 313, 307, 307, 294, 294, 282, 275, 269])
2020-11-19 21:51:04,408 (ctc:92) INFO: CTC input lengths:  tensor([400, 332, 313, 307, 307, 294, 294, 282, 275, 269], dtype=torch.int32)
2020-11-19 21:51:04,408 (ctc:97) INFO: CTC output lengths: tensor([40, 23, 21, 19, 46, 25, 27, 19, 17, 34], dtype=torch.int32)
2020-11-19 21:51:04,413 (ctc:119) INFO: ctc loss:77.30323791503906
2020-11-19 21:51:04,535 (e2e_asr:56) INFO: mtl loss:77.30323791503906
2020-11-19 21:51:04,538 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (1075, 63)
2020-11-19 21:51:04,538 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (1075, 63)
2020-11-19 21:51:04,538 (asr:288) INFO: ilens in custom converter = 15 [1075 1075 1075 1025 1000  950  925  925  900  900  875  875  875  850
  850]
2020-11-19 21:51:04,541 (nets_utils:52) INFO: padded = torch.Size([15, 1075, 63]) 
2020-11-19 21:51:04,542 (nets_utils:52) INFO: padded = torch.Size([15, 39]) 
2020-11-19 21:51:04,545 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([1075, 1075, 1075, 1025, 1000,  950,  925,  925,  900,  900,  875,  875,
         875,  850,  850], device='cuda:0') tensor([1075, 1075, 1075, 1025, 1000,  950,  925,  925,  900,  900,  875,  875,
         875,  850,  850], device='cuda:0')
2020-11-19 21:51:04,653 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([269, 269, 269, 257, 250, 238, 232, 232, 225, 225, 219, 219, 219, 213,
        213])
2020-11-19 21:51:04,655 (ctc:92) INFO: CTC input lengths:  tensor([269, 269, 269, 257, 250, 238, 232, 232, 225, 225, 219, 219, 219, 213,        213], dtype=torch.int32)
2020-11-19 21:51:04,655 (ctc:97) INFO: CTC output lengths: tensor([15, 19, 15, 19, 27, 26, 17, 19, 15, 23, 11, 39, 21, 11, 24],       dtype=torch.int32)
2020-11-19 21:51:04,658 (ctc:119) INFO: ctc loss:56.18077850341797
2020-11-19 21:51:04,781 (e2e_asr:56) INFO: mtl loss:56.18077850341797
2020-11-19 21:51:04,783 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 15 (850, 63)
2020-11-19 21:51:04,783 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 15 (850, 63)
2020-11-19 21:51:04,783 (asr:288) INFO: ilens in custom converter = 15 [850 825 825 825 775 775 775 775 750 750 750 725 725 725 725]
2020-11-19 21:51:04,786 (nets_utils:52) INFO: padded = torch.Size([15, 850, 63]) 
2020-11-19 21:51:04,787 (nets_utils:52) INFO: padded = torch.Size([15, 35]) 
2020-11-19 21:51:04,789 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([15]) torch.Size([15]) hlens,ilens=tensor([850, 825, 825, 825, 775, 775, 775, 775, 750, 750, 750, 725, 725, 725,
        725], device='cuda:0') tensor([850, 825, 825, 825, 775, 775, 775, 775, 750, 750, 750, 725, 725, 725,
        725], device='cuda:0')
2020-11-19 21:51:04,877 (e2e_asr:368) INFO: encoder ilens=torch.Size([15]) tensor([213, 207, 207, 207, 194, 194, 194, 194, 188, 188, 188, 182, 182, 182,
        182])
2020-11-19 21:51:04,879 (ctc:92) INFO: CTC input lengths:  tensor([213, 207, 207, 207, 194, 194, 194, 194, 188, 188, 188, 182, 182, 182,        182], dtype=torch.int32)
2020-11-19 21:51:04,879 (ctc:97) INFO: CTC output lengths: tensor([27, 15, 13, 19, 33, 21, 32, 30, 13, 35, 34, 15, 11, 27, 24],       dtype=torch.int32)
2020-11-19 21:51:04,882 (ctc:119) INFO: ctc loss:68.58647155761719
2020-11-19 21:51:04,981 (e2e_asr:56) INFO: mtl loss:68.58647155761719
2020-11-19 21:51:04,985 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (700, 63)
2020-11-19 21:51:04,986 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (700, 63)
2020-11-19 21:51:04,986 (asr:288) INFO: ilens in custom converter = 30 [700 700 700 675 675 675 675 650 650 625 625 600 600 600 600 575 575 575
 575 575 550 550 550 550 525 525 500 500 500 500]
2020-11-19 21:51:04,989 (nets_utils:52) INFO: padded = torch.Size([30, 700, 63]) 
2020-11-19 21:51:04,991 (nets_utils:52) INFO: padded = torch.Size([30, 43]) 
2020-11-19 21:51:04,994 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([700, 700, 700, 675, 675, 675, 675, 650, 650, 625, 625, 600, 600, 600,
        600, 575, 575, 575, 575, 575, 550, 550, 550, 550, 525, 525, 500, 500,
        500, 500], device='cuda:0') tensor([700, 700, 700, 675, 675, 675, 675, 650, 650, 625, 625, 600, 600, 600,
        600, 575, 575, 575, 575, 575, 550, 550, 550, 550, 525, 525, 500, 500,
        500, 500], device='cuda:0')
2020-11-19 21:51:05,079 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([175, 175, 175, 169, 169, 169, 169, 163, 163, 157, 157, 150, 150, 150,
        150, 144, 144, 144, 144, 144, 138, 138, 138, 138, 132, 132, 125, 125,
        125, 125])
2020-11-19 21:51:05,082 (ctc:92) INFO: CTC input lengths:  tensor([175, 175, 175, 169, 169, 169, 169, 163, 163, 157, 157, 150, 150, 150,        150, 144, 144, 144, 144, 144, 138, 138, 138, 138, 132, 132, 125, 125,        125, 125], dtype=torch.int32)
2020-11-19 21:51:05,082 (ctc:97) INFO: CTC output lengths: tensor([33, 17, 15, 34, 12, 21, 27, 13, 43, 33,  9, 11, 21, 13, 33, 19, 22,  7,        22, 15, 21, 26, 28, 23, 22, 31, 20, 20, 12, 25], dtype=torch.int32)
2020-11-19 21:51:05,085 (ctc:119) INFO: ctc loss:65.32816314697266
2020-11-19 21:51:05,253 (e2e_asr:56) INFO: mtl loss:65.32816314697266
2020-11-19 21:51:05,256 (asr:279) INFO: xs, xs[0] lengths in custom converter before sub sampling = 30 (475, 63)
2020-11-19 21:51:05,256 (asr:287) INFO: xs, xs[0] in custom converter after sub sampling= 30 (475, 63)
2020-11-19 21:51:05,256 (asr:288) INFO: ilens in custom converter = 30 [475 450 450 450 450 425 425 425 400 400 400 375 375 375 375 375 325 325
 275 250 250 250 250 225 225 225 200 200 175 175]
2020-11-19 21:51:05,258 (nets_utils:52) INFO: padded = torch.Size([30, 475, 63]) 
2020-11-19 21:51:05,259 (nets_utils:52) INFO: padded = torch.Size([30, 32]) 
2020-11-19 21:51:05,262 (e2e_asr:363) INFO: preprocess hlens,ilens (shape)= torch.Size([30]) torch.Size([30]) hlens,ilens=tensor([475, 450, 450, 450, 450, 425, 425, 425, 400, 400, 400, 375, 375, 375,
        375, 375, 325, 325, 275, 250, 250, 250, 250, 225, 225, 225, 200, 200,
        175, 175], device='cuda:0') tensor([475, 450, 450, 450, 450, 425, 425, 425, 400, 400, 400, 375, 375, 375,
        375, 375, 325, 325, 275, 250, 250, 250, 250, 225, 225, 225, 200, 200,
        175, 175], device='cuda:0')
2020-11-19 21:51:05,320 (e2e_asr:368) INFO: encoder ilens=torch.Size([30]) tensor([119, 113, 113, 113, 113, 107, 107, 107, 100, 100, 100,  94,  94,  94,
         94,  94,  82,  82,  69,  63,  63,  63,  63,  57,  57,  57,  50,  50,
         44,  44])
2020-11-19 21:51:05,323 (ctc:92) INFO: CTC input lengths:  tensor([119, 113, 113, 113, 113, 107, 107, 107, 100, 100, 100,  94,  94,  94,         94,  94,  82,  82,  69,  63,  63,  63,  63,  57,  57,  57,  50,  50,         44,  44], dtype=torch.int32)
2020-11-19 21:51:05,323 (ctc:97) INFO: CTC output lengths: tensor([20, 16, 15, 19, 19, 18, 19, 32, 24, 17,  9, 10,  9, 11,  9, 21,  5, 16,        13,  3,  2, 12,  7,  3,  3,  4,  2,  2,  2,  4], dtype=torch.int32)
2020-11-19 21:51:05,325 (ctc:119) INFO: ctc loss:35.64677047729492
2020-11-19 21:51:05,443 (e2e_asr:56) INFO: mtl loss:35.64677047729492
[J# Accounting: time=53 threads=1
# Ended (code 0) at Thu Nov 19 21:51:06 GMT 2020, elapsed time 53 seconds
