++ train_set=train_nodev
++ train_dev=train_dev
++ lm_test=test
++ recog_set='train_dev test'
++ '[' 3 -le -1 ']'
++ '[' 3 -le 0 ']'
++ feat_tr_dir=dump/train_nodev/deltafalse
++ mkdir -p dump/train_nodev/deltafalse
++ feat_dt_dir=dump/train_dev/deltafalse
++ mkdir -p dump/train_dev/deltafalse
++ '[' 3 -le 1 ']'
++ dict=data/lang_1char/train_nodev_units.txt
++ echo 'dictionary: data/lang_1char/train_nodev_units.txt'
dictionary: data/lang_1char/train_nodev_units.txt
++ '[' 3 -le 2 ']'
++ '[' -z ']'
+++ basename conf/lm
++ lmtag=lm
++ '[' true = true ']'
++ lmtag=lm_word100
++ lmexpname=train_rnnlm_pytorch_lm_word100
++ lmexpdir=exp/train_rnnlm_pytorch_lm_word100
++ mkdir -p exp/train_rnnlm_pytorch_lm_word100
++ '[' 3 -le 3 ']'
++ '[' 5 -ge 3 ']'
++ echo 'stage 3: LM Preparation'
stage 3: LM Preparation
++ '[' true = true ']'
++ lmdatadir=data/local/wordlm_train
++ lmdict=data/local/wordlm_train/wordlist_100.txt
++ mkdir -p data/local/wordlm_train
++ cut -f 2- '-d ' data/train_nodev/text
++ cut -f 2- '-d ' data/train_dev/text
++ cut -f 2- '-d ' data/test/text
++ text2vocabulary.py -s 100 -o data/local/wordlm_train/wordlist_100.txt data/local/wordlm_train/train.txt
WARNING:root:OOV rate = 0.00 %
++ run.pl --gpu 1 exp/train_rnnlm_pytorch_lm_word100/train.log lm_train.py --config conf/lm.yaml --ngpu 1 --backend pytorch --verbose 1 --outdir exp/train_rnnlm_pytorch_lm_word100 --tensorboard-dir tensorboard/train_rnnlm_pytorch_lm_word100 --train-label data/local/wordlm_train/train.txt --valid-label data/local/wordlm_train/valid.txt --test-label data/local/wordlm_train/test.txt --resume --dict data/local/wordlm_train/wordlist_100.txt
++ '[' -z ']'
+++ basename conf/train_mtlalpha1.0
++ expname=train_nodev_pytorch_train_mtlalpha1.0
++ false
++ expdir=exp/train_nodev_pytorch_train_mtlalpha1.0
++ mkdir -p exp/train_nodev_pytorch_train_mtlalpha1.0
++ '[' 3 -le 4 ']'
++ '[' 5 -ge 4 ']'
++ echo 'stage 4: Network Training'
stage 4: Network Training
++ run.pl --gpu 1 exp/train_nodev_pytorch_train_mtlalpha1.0/train.log asr_train.py --config conf/train_mtlalpha1.0.yaml --ngpu 1 --backend pytorch --outdir exp/train_nodev_pytorch_train_mtlalpha1.0/results --tensorboard-dir tensorboard/train_nodev_pytorch_train_mtlalpha1.0 --debugmode 1 --dict data/lang_1char/train_nodev_units.txt --debugdir exp/train_nodev_pytorch_train_mtlalpha1.0 --minibatches 0 --verbose 1 --resume --train-json dump/train_nodev/deltafalse/data.json --valid-json dump/train_dev/deltafalse/data.json
++ '[' 3 -le 5 ']'
++ '[' 5 -ge 5 ']'
++ echo 'stage 5: Decoding'
stage 5: Decoding
++ nj=8
++ pids=()
++ for rtask in '${recog_set}'
++ pids+=($!)
++ for rtask in '${recog_set}'
++ pids+=($!)
++ i=0
++ for pid in '"${pids[@]}"'
++ wait 7358
+++ basename conf/decode_ctcweight1.0
+++ basename conf/decode_ctcweight1.0
++ decode_dir=decode_train_dev_decode_ctcweight1.0_lm_word100
++ decode_dir=decode_test_decode_ctcweight1.0_lm_word100
++ '[' true = true ']'
++ '[' true = true ']'
++ recog_opts='--word-rnnlm exp/train_rnnlm_pytorch_lm_word100/rnnlm.model.best'
++ recog_opts='--word-rnnlm exp/train_rnnlm_pytorch_lm_word100/rnnlm.model.best'
++ feat_recog_dir=dump/test/deltafalse
++ feat_recog_dir=dump/train_dev/deltafalse
++ splitjson.py --parts 8 dump/test/deltafalse/data.json
++ splitjson.py --parts 8 dump/train_dev/deltafalse/data.json
2020-09-03 07:00:16,454 (splitjson:43) INFO: /home/john/anaconda3/bin/python3 /home/john/src/python/espnet/egs/an4/asr1/../../../utils/splitjson.py --parts 8 dump/train_dev/deltafalse/data.json
2020-09-03 07:00:16,454 (splitjson:43) INFO: /home/john/anaconda3/bin/python3 /home/john/src/python/espnet/egs/an4/asr1/../../../utils/splitjson.py --parts 8 dump/test/deltafalse/data.json
2020-09-03 07:00:16,458 (splitjson:55) INFO: number of utterances = 100
2020-09-03 07:00:16,557 (splitjson:55) INFO: number of utterances = 130
++ ngpu=0
++ run.pl JOB=1:8 exp/train_nodev_pytorch_train_mtlalpha1.0/decode_train_dev_decode_ctcweight1.0_lm_word100/log/decode.JOB.log asr_recog.py --config conf/decode_ctcweight1.0.yaml --ngpu 0 --backend pytorch --debugmode 1 --verbose 1 --recog-json dump/train_dev/deltafalse/split8utt/data.JOB.json --result-label exp/train_nodev_pytorch_train_mtlalpha1.0/decode_train_dev_decode_ctcweight1.0_lm_word100/data.JOB.json --model exp/train_nodev_pytorch_train_mtlalpha1.0/results/model.loss.best --word-rnnlm exp/train_rnnlm_pytorch_lm_word100/rnnlm.model.best
++ ngpu=0
++ run.pl JOB=1:8 exp/train_nodev_pytorch_train_mtlalpha1.0/decode_test_decode_ctcweight1.0_lm_word100/log/decode.JOB.log asr_recog.py --config conf/decode_ctcweight1.0.yaml --ngpu 0 --backend pytorch --debugmode 1 --verbose 1 --recog-json dump/test/deltafalse/split8utt/data.JOB.json --result-label exp/train_nodev_pytorch_train_mtlalpha1.0/decode_test_decode_ctcweight1.0_lm_word100/data.JOB.json --model exp/train_nodev_pytorch_train_mtlalpha1.0/results/model.loss.best --word-rnnlm exp/train_rnnlm_pytorch_lm_word100/rnnlm.model.best
run.pl: 8 / 8 failed, log is in exp/train_nodev_pytorch_train_mtlalpha1.0/decode_test_decode_ctcweight1.0_lm_word100/log/decode.*.log
run.pl: 8 / 8 failed, log is in exp/train_nodev_pytorch_train_mtlalpha1.0/decode_train_dev_decode_ctcweight1.0_lm_word100/log/decode.*.log
++ (( ++i ))
++ for pid in '"${pids[@]}"'
++ wait 7360
++ (( ++i ))
++ '[' 2 -gt 0 ']'
++ echo 'bash: 2 background jobs are failed.'
bash: 2 background jobs are failed.
++ false
++ train_set=train_nodev
++ train_dev=train_dev
++ lm_test=test
++ recog_set='train_dev test'
++ '[' 2 -le -1 ']'
++ '[' 2 -le 0 ']'
++ feat_tr_dir=dump/train_nodev/deltafalse
++ mkdir -p dump/train_nodev/deltafalse
++ feat_dt_dir=dump/train_dev/deltafalse
++ mkdir -p dump/train_dev/deltafalse
++ '[' 2 -le 1 ']'
++ dict=data/lang_1char/train_nodev_units.txt
++ echo 'dictionary: data/lang_1char/train_nodev_units.txt'
dictionary: data/lang_1char/train_nodev_units.txt
++ '[' 2 -le 2 ']'
++ '[' 5 -ge 2 ']'
++ echo 'stage 2: Dictionary and Json Data Preparation'
stage 2: Dictionary and Json Data Preparation
++ mkdir -p data/lang_1char/
++ echo '<unk> 1'
++ text2token.py -s 1 -n 1 data/train_nodev/text
++ cut -f 2- '-d '
++ uniq
++ grep -v -e '^\s*$'
++ awk '{print $0 " " NR+1}'
++ tr ' ' '\n'
++ sort
++ wc -l data/lang_1char/train_nodev_units.txt
28 data/lang_1char/train_nodev_units.txt
++ data2json.sh --feat dump/train_nodev/deltafalse/feats.scp data/train_nodev data/lang_1char/train_nodev_units.txt
/home/john/src/python/espnet/egs/an4/asr1/../../../utils/data2json.sh --feat dump/train_nodev/deltafalse/feats.scp data/train_nodev data/lang_1char/train_nodev_units.txt
/home/john/src/python/espnet/egs/an4/asr1/../../../utils/feat_to_shape.sh --cmd run.pl --nj 1 --filetype  --preprocess-conf  --verbose 0 dump/train_nodev/deltafalse/feats.scp data/train_nodev/tmp-NYcnM/input_1/shape.scp
++ data2json.sh --feat dump/train_dev/deltafalse/feats.scp data/train_dev data/lang_1char/train_nodev_units.txt
/home/john/src/python/espnet/egs/an4/asr1/../../../utils/data2json.sh --feat dump/train_dev/deltafalse/feats.scp data/train_dev data/lang_1char/train_nodev_units.txt
/home/john/src/python/espnet/egs/an4/asr1/../../../utils/feat_to_shape.sh --cmd run.pl --nj 1 --filetype  --preprocess-conf  --verbose 0 dump/train_dev/deltafalse/feats.scp data/train_dev/tmp-dOJSh/input_1/shape.scp
++ for rtask in '${recog_set}'
++ feat_recog_dir=dump/train_dev/deltafalse
++ data2json.sh --feat dump/train_dev/deltafalse/feats.scp data/train_dev data/lang_1char/train_nodev_units.txt
/home/john/src/python/espnet/egs/an4/asr1/../../../utils/data2json.sh --feat dump/train_dev/deltafalse/feats.scp data/train_dev data/lang_1char/train_nodev_units.txt
/home/john/src/python/espnet/egs/an4/asr1/../../../utils/feat_to_shape.sh --cmd run.pl --nj 1 --filetype  --preprocess-conf  --verbose 0 dump/train_dev/deltafalse/feats.scp data/train_dev/tmp-sARGk/input_1/shape.scp
++ for rtask in '${recog_set}'
++ feat_recog_dir=dump/test/deltafalse
++ data2json.sh --feat dump/test/deltafalse/feats.scp data/test data/lang_1char/train_nodev_units.txt
/home/john/src/python/espnet/egs/an4/asr1/../../../utils/data2json.sh --feat dump/test/deltafalse/feats.scp data/test data/lang_1char/train_nodev_units.txt
/home/john/src/python/espnet/egs/an4/asr1/../../../utils/feat_to_shape.sh --cmd run.pl --nj 1 --filetype  --preprocess-conf  --verbose 0 dump/test/deltafalse/feats.scp data/test/tmp-v6WVP/input_1/shape.scp
++ '[' -z ']'
+++ basename conf/lm
++ lmtag=lm
++ '[' true = true ']'
++ lmtag=lm_word100
++ lmexpname=train_rnnlm_pytorch_lm_word100
++ lmexpdir=exp/train_rnnlm_pytorch_lm_word100
++ mkdir -p exp/train_rnnlm_pytorch_lm_word100
++ '[' 2 -le 3 ']'
++ '[' 5 -ge 3 ']'
++ echo 'stage 3: LM Preparation'
stage 3: LM Preparation
++ '[' true = true ']'
++ lmdatadir=data/local/wordlm_train
++ lmdict=data/local/wordlm_train/wordlist_100.txt
++ mkdir -p data/local/wordlm_train
++ cut -f 2- '-d ' data/train_nodev/text
++ cut -f 2- '-d ' data/train_dev/text
++ cut -f 2- '-d ' data/test/text
++ text2vocabulary.py -s 100 -o data/local/wordlm_train/wordlist_100.txt data/local/wordlm_train/train.txt
WARNING:root:OOV rate = 0.00 %
++ run.pl --gpu 1 exp/train_rnnlm_pytorch_lm_word100/train.log lm_train.py --config conf/lm.yaml --ngpu 1 --backend pytorch --verbose 1 --outdir exp/train_rnnlm_pytorch_lm_word100 --tensorboard-dir tensorboard/train_rnnlm_pytorch_lm_word100 --train-label data/local/wordlm_train/train.txt --valid-label data/local/wordlm_train/valid.txt --test-label data/local/wordlm_train/test.txt --resume --dict data/local/wordlm_train/wordlist_100.txt
++ '[' -z ']'
+++ basename conf/train_mtlalpha1.0
++ expname=train_nodev_pytorch_train_mtlalpha1.0
++ false
++ expdir=exp/train_nodev_pytorch_train_mtlalpha1.0
++ mkdir -p exp/train_nodev_pytorch_train_mtlalpha1.0
++ '[' 2 -le 4 ']'
++ '[' 5 -ge 4 ']'
++ echo 'stage 4: Network Training'
stage 4: Network Training
++ run.pl --gpu 1 exp/train_nodev_pytorch_train_mtlalpha1.0/train.log asr_train.py --config conf/train_mtlalpha1.0.yaml --ngpu 1 --backend pytorch --outdir exp/train_nodev_pytorch_train_mtlalpha1.0/results --tensorboard-dir tensorboard/train_nodev_pytorch_train_mtlalpha1.0 --debugmode 1 --dict data/lang_1char/train_nodev_units.txt --debugdir exp/train_nodev_pytorch_train_mtlalpha1.0 --minibatches 0 --verbose 1 --resume --train-json dump/train_nodev/deltafalse/data.json --valid-json dump/train_dev/deltafalse/data.json
++ '[' 2 -le 5 ']'
++ '[' 5 -ge 5 ']'
++ echo 'stage 5: Decoding'
stage 5: Decoding
++ nj=8
++ pids=()
++ for rtask in '${recog_set}'
++ pids+=($!)
++ for rtask in '${recog_set}'
++ pids+=($!)
++ i=0
++ for pid in '"${pids[@]}"'
++ wait 8168
+++ basename conf/decode_ctcweight1.0
+++ basename conf/decode_ctcweight1.0
++ decode_dir=decode_test_decode_ctcweight1.0_lm_word100
++ decode_dir=decode_train_dev_decode_ctcweight1.0_lm_word100
++ '[' true = true ']'
++ '[' true = true ']'
++ recog_opts='--word-rnnlm exp/train_rnnlm_pytorch_lm_word100/rnnlm.model.best'
++ recog_opts='--word-rnnlm exp/train_rnnlm_pytorch_lm_word100/rnnlm.model.best'
++ feat_recog_dir=dump/test/deltafalse
++ feat_recog_dir=dump/train_dev/deltafalse
++ splitjson.py --parts 8 dump/test/deltafalse/data.json
++ splitjson.py --parts 8 dump/train_dev/deltafalse/data.json
2020-09-03 07:19:37,061 (splitjson:43) INFO: /home/john/anaconda3/bin/python3 /home/john/src/python/espnet/egs/an4/asr1/../../../utils/splitjson.py --parts 8 dump/train_dev/deltafalse/data.json
2020-09-03 07:19:37,061 (splitjson:43) INFO: /home/john/anaconda3/bin/python3 /home/john/src/python/espnet/egs/an4/asr1/../../../utils/splitjson.py --parts 8 dump/test/deltafalse/data.json
2020-09-03 07:19:37,064 (splitjson:55) INFO: number of utterances = 100
2020-09-03 07:19:37,087 (splitjson:55) INFO: number of utterances = 130
++ ngpu=0
++ run.pl JOB=1:8 exp/train_nodev_pytorch_train_mtlalpha1.0/decode_train_dev_decode_ctcweight1.0_lm_word100/log/decode.JOB.log asr_recog.py --config conf/decode_ctcweight1.0.yaml --ngpu 0 --backend pytorch --debugmode 1 --verbose 1 --recog-json dump/train_dev/deltafalse/split8utt/data.JOB.json --result-label exp/train_nodev_pytorch_train_mtlalpha1.0/decode_train_dev_decode_ctcweight1.0_lm_word100/data.JOB.json --model exp/train_nodev_pytorch_train_mtlalpha1.0/results/model.loss.best --word-rnnlm exp/train_rnnlm_pytorch_lm_word100/rnnlm.model.best
++ ngpu=0
++ run.pl JOB=1:8 exp/train_nodev_pytorch_train_mtlalpha1.0/decode_test_decode_ctcweight1.0_lm_word100/log/decode.JOB.log asr_recog.py --config conf/decode_ctcweight1.0.yaml --ngpu 0 --backend pytorch --debugmode 1 --verbose 1 --recog-json dump/test/deltafalse/split8utt/data.JOB.json --result-label exp/train_nodev_pytorch_train_mtlalpha1.0/decode_test_decode_ctcweight1.0_lm_word100/data.JOB.json --model exp/train_nodev_pytorch_train_mtlalpha1.0/results/model.loss.best --word-rnnlm exp/train_rnnlm_pytorch_lm_word100/rnnlm.model.best
run.pl: 8 / 8 failed, log is in exp/train_nodev_pytorch_train_mtlalpha1.0/decode_test_decode_ctcweight1.0_lm_word100/log/decode.*.log
run.pl: 8 / 8 failed, log is in exp/train_nodev_pytorch_train_mtlalpha1.0/decode_train_dev_decode_ctcweight1.0_lm_word100/log/decode.*.log
++ (( ++i ))
++ for pid in '"${pids[@]}"'
++ wait 8169
++ (( ++i ))
++ '[' 2 -gt 0 ']'
++ echo 'bash: 2 background jobs are failed.'
bash: 2 background jobs are failed.
++ false
